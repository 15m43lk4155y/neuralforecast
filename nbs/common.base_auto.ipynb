{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524620c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp common._base_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15392f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa25a4",
   "metadata": {},
   "source": [
    "# Base AutoModel class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2508f7a9-1433-4ad8-8f2f-0078c6ed6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_eq\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44065066-e72a-431f-938f-1528adef9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from copy import deepcopy\n",
    "from os import cpu_count\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "from ray import air, tune\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "from ray.tune.search.basic_variant import BasicVariantGenerator\n",
    "\n",
    "from neuralforecast.losses.pytorch import MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693faaae-5429-4046-99ba-ec771b1ce29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def train_tune(config_step, cls_model, dataset, val_size, test_size):\n",
    "    metrics = {\"loss\": \"ptl/val_loss\"}\n",
    "    callbacks = [TQDMProgressBar(), TuneReportCallback(metrics, on=\"validation_end\")]\n",
    "    if 'callbacks' in config_step.keys():\n",
    "        callbacks += config_step['callbacks']\n",
    "    config_step = {**config_step, **{'callbacks': callbacks}}\n",
    "    model = cls_model(**config_step)\n",
    "    model.fit(\n",
    "        dataset,\n",
    "        val_size=val_size, \n",
    "        test_size=test_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbb29ee-882c-46cc-b919-e3a7661f9744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def tune_model(\n",
    "        cls_model, \n",
    "        dataset, \n",
    "        val_size, \n",
    "        test_size,\n",
    "        cpus,\n",
    "        gpus,\n",
    "        verbose,\n",
    "        num_samples, \n",
    "        search_alg, \n",
    "        config\n",
    "    ):\n",
    "    train_fn_with_parameters = tune.with_parameters(\n",
    "        train_tune,\n",
    "        cls_model=cls_model,\n",
    "        dataset=dataset,\n",
    "        val_size=val_size,\n",
    "        test_size=test_size,\n",
    "    )\n",
    "\n",
    "    # Device\n",
    "    if gpus > 0:\n",
    "        device_dict = {'gpu':gpus}\n",
    "    else:\n",
    "        device_dict = {'cpu':cpus}\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_fn_with_parameters, device_dict),\n",
    "        run_config=air.RunConfig(\n",
    "            verbose=verbose,\n",
    "            #checkpoint_config=air.CheckpointConfig(\n",
    "                #num_to_keep=0,\n",
    "                #keep_checkpoints_num=None\n",
    "            #)\n",
    "        ),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"loss\",\n",
    "            mode=\"min\",\n",
    "            num_samples=num_samples, \n",
    "            search_alg=search_alg\n",
    "        ),\n",
    "        param_space=config,\n",
    "    )\n",
    "    results = tuner.fit()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06182c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# If None overwrite with default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c253583-8239-4abe-8a04-0c0ba635d8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseAuto:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 cls_model,\n",
    "                 h,\n",
    "                 config, \n",
    "                 search_alg=BasicVariantGenerator(random_state=1),\n",
    "                 num_samples=10,\n",
    "                 cpus=cpu_count(),\n",
    "                 gpus=torch.cuda.device_count(),\n",
    "                 refit_wo_val=False,\n",
    "                 verbose=False):\n",
    "        \n",
    "        config['h'] = h\n",
    "        self.cls_model = cls_model\n",
    "        self.h = h\n",
    "        self.config = config\n",
    "        self.num_samples = num_samples\n",
    "        self.search_alg = search_alg\n",
    "        self.cpus = cpus\n",
    "        self.gpus = gpus\n",
    "        self.refit_wo_val = refit_wo_val\n",
    "        self.verbose = verbose\n",
    "        self.loss = self.config.get('loss', MAE())\n",
    "        \n",
    "    def fit(self, dataset, val_size=0, test_size=0):\n",
    "        #we need val_size > 0 to perform\n",
    "        #hyperparameter selection.\n",
    "        search_alg = deepcopy(self.search_alg)\n",
    "        val_size = val_size if val_size > 0 else self.h\n",
    "        results = tune_model(\n",
    "            cls_model=self.cls_model,\n",
    "            dataset=dataset,\n",
    "            val_size=val_size, \n",
    "            test_size=test_size, \n",
    "            cpus=self.cpus,\n",
    "            gpus=self.gpus,\n",
    "            verbose=self.verbose,\n",
    "            num_samples=self.num_samples, \n",
    "            search_alg=search_alg, \n",
    "            config=self.config\n",
    "        )\n",
    "        best_config = results.get_best_result().config\n",
    "        self.model = self.cls_model(**best_config)\n",
    "        self.model.fit(\n",
    "            dataset=dataset, \n",
    "            val_size=val_size * (1 - self.refit_wo_val), \n",
    "            test_size=test_size,\n",
    "        )\n",
    "        self.results = results\n",
    "        \n",
    "    def predict(self, dataset, step_size=1, **data_kwargs):\n",
    "        return self.model.predict(dataset=dataset, \n",
    "                                  step_size=step_size, **data_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfd4e8f-2565-4f85-b615-7329a1ae3f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349627f9-d2c7-40dc-8ebd-99ee1d9e9d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import pandas as pd\n",
    "from neuralforecast.models.mlp import MLP\n",
    "from neuralforecast.utils import AirPassengersDF as Y_df\n",
    "from neuralforecast.tsdataset import TimeSeriesDataset\n",
    "\n",
    "Y_train_df = Y_df[Y_df.ds<='1959-12-31'] # 132 train\n",
    "Y_test_df = Y_df[Y_df.ds>'1959-12-31']   # 12 test\n",
    "\n",
    "dataset, *_ = TimeSeriesDataset.from_df(Y_train_df)\n",
    "config = {\n",
    "    \"hidden_size\": tune.choice([512]),\n",
    "    \"num_layers\": tune.choice([3, 4]),\n",
    "    \"input_size\": 12,\n",
    "    \"h\": 12,\n",
    "    \"max_epochs\": 10\n",
    "}\n",
    "auto = BaseAuto(h=12, cls_model=MLP, config=config, num_samples=2, cpus=1, gpus=0)\n",
    "auto.fit(dataset=dataset)\n",
    "y_hat = auto.predict(dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ad2eec-dd93-4bc4-ae19-5df4199577be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "Y_test_df['AutoMLP'] = y_hat\n",
    "\n",
    "pd.concat([Y_train_df, Y_test_df]).drop('unique_id', axis=1).set_index('ds').plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
