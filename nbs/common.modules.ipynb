{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp common._modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "ACTIVATIONS = ['ReLU','Softplus','Tanh','SELU','LeakyReLU','PReLU','Sigmoid']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Concentrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Concentrator(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_series: int,\n",
    "                 type: str, \n",
    "                 treatment_var_name: str,\n",
    "                 input_size: int,\n",
    "                 h: int,\n",
    "                 freq: int,\n",
    "                 mask_future: bool = True,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert type in ['subcutaneous_injection'], \"treatment type not available.\"\n",
    "\n",
    "        self.n_series = n_series\n",
    "        self.type = type\n",
    "        self.treatment_var_name = treatment_var_name\n",
    "        self.freq = freq\n",
    "\n",
    "        # K parameter for each time-series\n",
    "        self.k_a = nn.Embedding(self.n_series, 1)\n",
    "        # Initialize k_a\n",
    "        init_k = torch.zeros((self.n_series, 1))\n",
    "        self.k_a.weight.data.copy_(init_k)\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.h = h\n",
    "        self.mask_future = mask_future\n",
    "        \n",
    "    def treatment_concentration(self, t, k_a, sigma=1):\n",
    "        t = torch.div(t, 60) #60 minutes --> hours # TODO: make more adaptable to different data freq\n",
    "            \n",
    "        conc = torch.exp(torch.negative(torch.pow((torch.log(t + 1e-5) - k_a), 2)) /\\\n",
    "               (2 * sigma**2)) / \\\n",
    "               (t * sigma * torch.sqrt(torch.tensor(2) * torch.pi) + 1e-5) \n",
    "               # Add small increment (1e-5) or else k_a --> [nan]\n",
    "\n",
    "        return conc\n",
    "\n",
    "    def forward(self,\n",
    "                treatment_exog: torch.Tensor,\n",
    "                stat_exog: torch.Tensor,\n",
    "                idx: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        treatment_var = treatment_exog[:, :, -1] # [B,L,C] -> [B,L]\n",
    "\n",
    "        # Set treatment in forecasting window to 0\n",
    "        if self.mask_future:\n",
    "            treatment_var[:, -self.h:] = 0\n",
    "\n",
    "        b = treatment_var.shape[0]\n",
    "        l = treatment_var.shape[1]\n",
    "        \n",
    "        idx = idx.long()\n",
    "        # Constrain k_a with sigmoid\n",
    "        k_a = torch.sigmoid(self.k_a(idx)) # [B, 1, 1] for static k_a      \n",
    "        \n",
    "        # Create [B,L,L] matrix\n",
    "        lt = torch.tensor(range(l))\n",
    "        ltr = lt.repeat((l, 1)) - lt.reshape(-1, 1)\n",
    "        ltr[ltr<0]=0\n",
    "\n",
    "        ltr_batch = torch.zeros((b, l, l)).to(treatment_exog.device)\n",
    "        ltr_batch[:] = ltr\n",
    "        \n",
    "        # Apply frequency\n",
    "        ltrf_batch = ltr_batch * self.freq\n",
    "        \n",
    "        # Multiple concentration by treatement_var (dose)\n",
    "        conc = self.treatment_concentration(ltrf_batch, k_a)\n",
    "        scaled_conc = conc*(treatment_var.reshape(b, l, 1))\n",
    "        treatment = scaled_conc.nansum(dim=1) #[B, L]\n",
    "\n",
    "        # Replace treatment variable with concentration\n",
    "        treatment_exog_out = torch.zeros(treatment_exog.shape).to(treatment_exog.device)\n",
    "        treatment_exog_out[:, :, :-1] += treatment_exog[:, :, :-1]\n",
    "        treatment_exog_out[:, :, -1] += treatment\n",
    "\n",
    "        return treatment_exog_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MLP\n",
    "\n",
    "Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Multi-Layer Perceptron Class\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `in_features`: int, dimension of input.<br>\n",
    "    `out_features`: int, dimension of output.<br>\n",
    "    `activation`: str, activation function to use.<br>\n",
    "    `hidden_size`: int, dimension of hidden layers.<br>\n",
    "    `num_layers`: int, number of hidden layers.<br>\n",
    "    `dropout`: float, dropout rate.<br>\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features, activation, hidden_size, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        assert activation in ACTIVATIONS, f'{activation} is not in {ACTIVATIONS}'\n",
    "        \n",
    "        self.activation = getattr(nn, activation)()\n",
    "\n",
    "        # MultiLayer Perceptron\n",
    "        # Input layer\n",
    "        layers = [nn.Linear(in_features=in_features, out_features=hidden_size),\n",
    "                  self.activation,\n",
    "                  nn.Dropout(dropout)]\n",
    "        # Hidden layers\n",
    "        for i in range(num_layers - 2):\n",
    "            layers += [nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "                       self.activation,\n",
    "                       nn.Dropout(dropout)]\n",
    "        # Output layer\n",
    "        layers += [nn.Linear(in_features=hidden_size, out_features=out_features)]\n",
    "\n",
    "        # Store in layers as ModuleList\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Temporal Convolutions\n",
    "\n",
    "For long time in deep learning, sequence modelling was synonymous with recurrent networks, yet several papers have shown that simple convolutional architectures can outperform canonical recurrent networks like LSTMs by demonstrating longer effective memory.\n",
    "\n",
    "**References**<br>\n",
    "-[van den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., Kalchbrenner, N., Senior, A. W., & Kavukcuoglu, K. (2016). Wavenet: A generative model for raw audio. Computing Research Repository, abs/1609.03499. URL: http://arxiv.org/abs/1609.03499. arXiv:1609.03499.](https://arxiv.org/abs/1609.03499)<br>\n",
    "-[Shaojie Bai, Zico Kolter, Vladlen Koltun. (2018). An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling. Computing Research Repository, abs/1803.01271. URL: https://arxiv.org/abs/1803.01271.](https://arxiv.org/abs/1803.01271)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Chomp1d(nn.Module):\n",
    "    \"\"\" Chomp1d\n",
    "\n",
    "    Receives `x` input of dim [N,C,T], and trims it so that only\n",
    "    'time available' information is used. \n",
    "    Used by one dimensional causal convolutions `CausalConv1d`.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `horizon`: int, length of outsample values to skip.\n",
    "    \"\"\"\n",
    "    def __init__(self, horizon):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.horizon = horizon\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.horizon].contiguous()\n",
    "\n",
    "\n",
    "class CausalConv1d(nn.Module):\n",
    "    \"\"\" Causal Convolution 1d\n",
    "\n",
    "    Receives `x` input of dim [N,C_in,T], and computes a causal convolution\n",
    "    in the time dimension. Skipping the H steps of the forecast horizon, through\n",
    "    its dilation.\n",
    "    Consider a batch of one element, the dilated convolution operation on the\n",
    "    $t$ time step is defined:\n",
    "\n",
    "    $\\mathrm{Conv1D}(\\mathbf{x},\\mathbf{w})(t) = (\\mathbf{x}_{[*d]} \\mathbf{w})(t) = \\sum^{K}_{k=1} w_{k} \\mathbf{x}_{t-dk}$\n",
    "\n",
    "    where $d$ is the dilation factor, $K$ is the kernel size, $t-dk$ is the index of\n",
    "    the considered past observation. The dilation effectively applies a filter with skip\n",
    "    connections. If $d=1$ one recovers a normal convolution.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `in_channels`: int, dimension of `x` input's initial channels.<br> \n",
    "    `out_channels`: int, dimension of `x` outputs's channels.<br> \n",
    "    `activation`: str, identifying activations from PyTorch activations.\n",
    "        select from 'ReLU','Softplus','Tanh','SELU', 'LeakyReLU','PReLU','Sigmoid'.<br>\n",
    "    `padding`: int, number of zero padding used to the left.<br>\n",
    "    `kernel_size`: int, convolution's kernel size.<br>\n",
    "    `dilation`: int, dilation skip connections.<br>\n",
    "    \n",
    "    **Returns:**<br>\n",
    "    `x`: tensor, torch tensor of dim [N,C_out,T] activation(conv1d(inputs, kernel) + bias). <br>\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 padding, dilation, activation, stride:int=1):\n",
    "        super(CausalConv1d, self).__init__()\n",
    "        assert activation in ACTIVATIONS, f'{activation} is not in {ACTIVATIONS}'\n",
    "        \n",
    "        self.conv       = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, \n",
    "                                    kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                    dilation=dilation)\n",
    "        \n",
    "        self.chomp      = Chomp1d(padding)\n",
    "        self.activation = getattr(nn, activation)()\n",
    "        self.causalconv = nn.Sequential(self.conv, self.chomp, self.activation)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.causalconv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CausalConv1d, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TemporalConvolutionEncoder(nn.Module):\n",
    "    \"\"\" Temporal Convolution Encoder\n",
    "\n",
    "    Receives `x` input of dim [N,T,C_in], permutes it to  [N,C_in,T]\n",
    "    applies a deep stack of exponentially dilated causal convolutions.\n",
    "    The exponentially increasing dilations of the convolutions allow for \n",
    "    the creation of weighted averages of exponentially large long-term memory.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `in_channels`: int, dimension of `x` input's initial channels.<br> \n",
    "    `out_channels`: int, dimension of `x` outputs's channels.<br>\n",
    "    `kernel_size`: int, size of the convolving kernel.<br>\n",
    "    `dilations`: int list, controls the temporal spacing between the kernel points.<br>\n",
    "    `activation`: str, identifying activations from PyTorch activations.\n",
    "        select from 'ReLU','Softplus','Tanh','SELU', 'LeakyReLU','PReLU','Sigmoid'.<br>\n",
    "\n",
    "    **Returns:**<br>\n",
    "    `x`: tensor, torch tensor of dim [N,T,C_out].<br>\n",
    "    \"\"\"\n",
    "    # TODO: Add dilations parameter and change layers declaration to for loop\n",
    "    def __init__(self, in_channels, out_channels, \n",
    "                 kernel_size, dilations,\n",
    "                 activation:str='ReLU'):\n",
    "        super(TemporalConvolutionEncoder, self).__init__()\n",
    "        layers = []\n",
    "        for dilation in dilations:\n",
    "            layers.append(CausalConv1d(in_channels=in_channels, out_channels=out_channels, \n",
    "                                        kernel_size=kernel_size, padding=(kernel_size-1)*dilation, \n",
    "                                        activation=activation, dilation=dilation))\n",
    "            in_channels = out_channels\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # [N,T,C_in] -> [N,C_in,T] -> [N,T,C_out]\n",
    "        x = x.permute(0, 2, 1).contiguous()\n",
    "        x = self.tcn(x)\n",
    "        x = x.permute(0, 2, 1).contiguous()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TemporalConvolutionEncoder, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
