{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.tsdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Dataset\n",
    "> Transforms pandas DataFrame into a TimeSeriesDataset for the Dataloder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import gc\n",
    "import logging\n",
    "import random\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from typing import Collection, Dict, Iterable, List, Optional, Tuple\n",
    "from typing_extensions import Literal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as t\n",
    "from fastcore.foundation import patch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A class used to store Time Series data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 Y_df: pd.DataFrame,\n",
    "                 X_df: Optional[pd.DataFrame] = None,\n",
    "                 S_df: Optional[pd.DataFrame] = None,\n",
    "                 f_cols: Optional[List] = None,\n",
    "                 mask_df: Optional[pd.DataFrame] = None,\n",
    "                 ds_in_test: int = 0,\n",
    "                 is_test: bool = False, \n",
    "                 input_size: int = 15,\n",
    "                 output_size: int = 1,\n",
    "                 window_sampling_limit: int = 20,\n",
    "                 idx_to_sample_freq: int = 1,\n",
    "                 complete_inputs: bool = False,\n",
    "                 complete_outputs: bool = True,\n",
    "                 len_sample_chunks: Optional[int] = None,\n",
    "                 mode: Literal['simple', 'full'] = 'simple',\n",
    "                 verbose: bool = False) -> 'TimeSeriesDataset':\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        Y_df: pd.DataFrame\n",
    "            Target time series with columns ['unique_id', 'ds', 'y'].\n",
    "        X_df: pd.DataFrame\n",
    "            Exogenous time series with columns ['unique_id', 'ds', 'y'].\n",
    "        S_df: pd.DataFrame\n",
    "            Static exogenous variables with columns ['unique_id', 'ds'] \n",
    "            and static variables.\n",
    "        f_cols: list\n",
    "            List of exogenous variables of the future.\n",
    "        mask_df: pd.DataFrame\n",
    "            Outsample mask with columns ['unique_id', 'ds', 'sample_mask']\n",
    "            and optionally 'available_mask'.\n",
    "            Default None: constructs default mask based on ds_in_test.\n",
    "        ds_in_test: int\n",
    "            Only used when mask_df = None.\n",
    "            Numer of datestamps to use as outsample.\n",
    "        is_test: bool\n",
    "            Only used when mask_df = None.\n",
    "            Wheter target time series belongs to test set.\n",
    "        input_size: int\n",
    "            Size of the training sets.\n",
    "        output_size: int\n",
    "            Forecast horizon.\n",
    "        window_sampling_limit: int\n",
    "            Max size of observations to consider, including output_size.\n",
    "        idx_to_sample_freq: int\n",
    "            Step size to construct windows.\n",
    "            Ej. if idx_to_sample_freq=7, each 7 timestamps\n",
    "            a window will be constructed.\n",
    "        complete_inputs: bool\n",
    "            Whether consider only windows with available window_size.\n",
    "            Default False.\n",
    "        complete_outputs: bool\n",
    "            Whether consider only windows with available output_size + 1.\n",
    "            Default True.\n",
    "        len_sample_chunks: Optional[int] = None\n",
    "            Size of complete windows.\n",
    "            Only used for mode = 'full'!\n",
    "            Default None, equals to input_size + ouput_size.\n",
    "        mode: str\n",
    "            Mode to be used.\n",
    "            One of ['simple', 'full'].\n",
    "            If 'simple', windows of size input_size + output_size\n",
    "            will be constrcuted. If 'full', windows of size\n",
    "            len_sample_chunks will be constructed.\n",
    "        verbose: bool\n",
    "            Wheter or not log outputs.\n",
    "        \"\"\"        \n",
    "        assert type(Y_df) == pd.core.frame.DataFrame\n",
    "        assert all([(col in Y_df) for col in ['unique_id', 'ds', 'y']])\n",
    "        self.verbose = verbose\n",
    "\n",
    "        if X_df is not None:\n",
    "            assert type(X_df) == pd.core.frame.DataFrame\n",
    "            assert all([(col in X_df) for col in ['unique_id', 'ds']])\n",
    "            assert len(Y_df)==len(X_df), 'The dimensions of Y_df and X_df are not the same'\n",
    "\n",
    "        if mask_df is not None:\n",
    "            assert len(Y_df)==len(mask_df), 'The dimensions of Y_df and mask_df are not the same'\n",
    "            assert all([(col in mask_df) for col in ['unique_id', 'ds', 'sample_mask']])\n",
    "            if 'available_mask' not in mask_df.columns:\n",
    "                if self.verbose: \n",
    "                    logging.info('Available mask not provided, defaulted with 1s.')\n",
    "                mask_df['available_mask'] = 1\n",
    "            assert np.sum(np.isnan(mask_df.available_mask.values)) == 0\n",
    "            assert np.sum(np.isnan(mask_df.sample_mask.values)) == 0\n",
    "        else:\n",
    "            mask_df = get_default_mask_df(Y_df=Y_df, \n",
    "                                          is_test=is_test,\n",
    "                                          ds_in_test=ds_in_test)\n",
    "        \n",
    "        n_ds  = len(mask_df)\n",
    "        n_avl = mask_df.available_mask.sum()        \n",
    "        n_ins = mask_df.sample_mask.sum()\n",
    "        n_out = len(mask_df) - mask_df.sample_mask.sum()\n",
    "\n",
    "        avl_prc = np.round((100 * n_avl) / n_ds, 2)\n",
    "        ins_prc = np.round((100 * n_ins) / n_ds, 2)\n",
    "        out_prc = np.round((100 * n_out) / n_ds, 2)\n",
    "        if self.verbose:\n",
    "            logging.info('Train Validation splits\\n')\n",
    "            if len(mask_df.unique_id.unique()) < 10:\n",
    "                logging.info(mask_df.groupby(['unique_id', 'sample_mask']).agg({'ds': ['min', 'max']}))\n",
    "            else:\n",
    "                logging.info(mask_df.groupby(['sample_mask']).agg({'ds': ['min', 'max']}))\n",
    "            dataset_info  = f'\\nTotal data \\t\\t\\t{n_ds} time stamps \\n'\n",
    "            dataset_info += f'Available percentage={avl_prc}, \\t{n_avl} time stamps \\n'\n",
    "            dataset_info += f'Insample  percentage={ins_prc}, \\t{n_ins} time stamps \\n'\n",
    "            dataset_info += f'Outsample percentage={out_prc}, \\t{n_out} time stamps \\n'\n",
    "            logging.info(dataset_info)\n",
    " \n",
    "        self.ts_data, self.s_data, self.meta_data, self.t_cols, self.s_cols \\\n",
    "                         = self._df_to_lists(Y_df=Y_df, S_df=S_df, X_df=X_df, mask_df=mask_df)\n",
    "\n",
    "        # Dataset attributes\n",
    "        self.n_series = len(self.ts_data)\n",
    "        self.max_len = max([len(ts) for ts in self.ts_data])\n",
    "        self.n_channels = len(self.t_cols) # t_cols insample_mask and outsample_mask\n",
    "        self.frequency = pd.infer_freq(Y_df.head()['ds'])\n",
    "        self.f_cols = f_cols\n",
    "        self.f_idxs = self._get_f_idxs(f_cols) if f_cols else []\n",
    "        self.window_sampling_limit = window_sampling_limit\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.complete_inputs = complete_inputs\n",
    "        self.complete_outputs = complete_outputs\n",
    "        self.idx_to_sample_freq = idx_to_sample_freq\n",
    "        self.mode = mode\n",
    "        if len_sample_chunks is not None:\n",
    "            if len_sample_chunks < self.input_size + self.output_size:\n",
    "                raise Exception(f'Insufficient len of sample chunks {len_sample_chunks}')\n",
    "            self.len_sample_chunks = len_sample_chunks\n",
    "        else:\n",
    "            self.len_sample_chunks = input_size + output_size\n",
    "        self.first_ds = max(self.max_len - self.window_sampling_limit, 0)\n",
    "\n",
    "        # Number of X and S features\n",
    "        self.n_x = 0 if X_df is None else X_df.shape[1] - 2 # -2 for unique_id and ds\n",
    "        self.n_s = 0 if S_df is None else S_df.shape[1] - 1 # -1 for unique_id\n",
    "\n",
    "        # Balances panel and creates \n",
    "        # numpy  s_matrix of shape (n_series, n_s)\n",
    "        # numpy ts_tensor of shape (n_series, n_channels, max_len) n_channels = t_cols + masks\n",
    "        self.ts_tensor, self.s_matrix, self.len_series = self._create_tensor(self.ts_data, self.s_data)\n",
    "        \n",
    "        # Defining windows attributes by model\n",
    "        self.windows_size: int\n",
    "        self.padding: Tuple[int, int]\n",
    "            \n",
    "        self._define_attributes_by_mode()\n",
    "        \n",
    "        # Defining sampleable time series\n",
    "        self.ts_idxs = np.arange(self.n_series)\n",
    "        self.sampleable_ts_idxs: np.ndarray\n",
    "        self.n_sampleable_ts: int\n",
    "            \n",
    "        self._define_sampleable_ts_idxs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def _df_to_lists(self: TimeSeriesDataset, \n",
    "                 S_df: pd.DataFrame,\n",
    "                 Y_df: pd.DataFrame,\n",
    "                 X_df: pd.DataFrame, \n",
    "                 mask_df: pd.DataFrame) -> Tuple[List[np.ndarray], \n",
    "                                                 List[np.ndarray],\n",
    "                                                 List[np.ndarray], \n",
    "                                                 List[str],\n",
    "                                                 List[str]]:\n",
    "    \"\"\"Transforms input dataframes to lists.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    S_df: pd.DataFrame\n",
    "        Static exogenous variables with columns ['unique_id', 'ds'] \n",
    "        and static variables.    \n",
    "    Y_df: pd.DataFrame\n",
    "        Target time series with columns ['unique_id', 'ds', 'y'].\n",
    "    X_df: pd.DataFrame\n",
    "        Exogenous time series with columns ['unique_id', 'ds', 'y'].\n",
    "    mask_df: pd.DataFrame\n",
    "        Outsample mask with columns ['unique_id', 'ds', 'sample_mask']\n",
    "        and optionally 'available_mask'.\n",
    "        Default None: constructs default mask based on ds_in_test.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple of five lists:\n",
    "        - List of time series. Each element of the list is a \n",
    "          numpy array of shape (length of the time series, n_channels),\n",
    "          where n_channels = t_cols + masks.\n",
    "        - List of static variables. Each element of the list is a \n",
    "          numpy array of shape (1, n_s).\n",
    "          where n_channels = t_cols + masks.\n",
    "        - List of meta data. Each element of the list is a \n",
    "          numpy array of shape (lenght of the time series, 2) \n",
    "          and corresponds to unique_id, ds.\n",
    "        - List of temporal variables (including target and masks). \n",
    "        - List of statitc variables.\n",
    "    \"\"\"\n",
    "    # None protections\n",
    "    if X_df is None:\n",
    "        X_df = Y_df[['unique_id', 'ds']]\n",
    "    \n",
    "    if S_df is None:\n",
    "        S_df = Y_df[['unique_id']].drop_duplicates()\n",
    "    \n",
    "    # Protect order of data\n",
    "    Y = Y_df.sort_values(by=['unique_id', 'ds'], ignore_index=True).copy()\n",
    "    X = X_df.sort_values(by=['unique_id', 'ds'], ignore_index=True).copy()\n",
    "    M = mask_df.sort_values(by=['unique_id', 'ds'], ignore_index=True).copy()\n",
    "    \n",
    "    assert np.array_equal(X.unique_id.values, Y.unique_id.values), f'Mismatch in X, Y unique_ids'\n",
    "    assert np.array_equal(X.ds.values, Y.ds.values), f'Mismatch in X, Y ds'\n",
    "    assert np.array_equal(M.unique_id.values, Y.unique_id.values), f'Mismatch in M, Y unique_ids'\n",
    "    assert np.array_equal(M.ds.values, Y.ds.values), f'Mismatch in M, Y ds'\n",
    "    \n",
    "    # Create bigger grouped by dataframe G to parse\n",
    "    M = M[['available_mask', 'sample_mask']]\n",
    "    X.drop(['unique_id', 'ds'], 1, inplace=True)\n",
    "    G = Y.join(X).join(M)\n",
    "    \n",
    "    S = S_df.sort_values(by=['unique_id']).copy()\n",
    "    \n",
    "    # time columns and static columns for future indexing\n",
    "    t_cols = list(G.columns[2:]) # avoid unique_id and ds\n",
    "    s_cols = list(S.columns[1:]) # avoid unique_id\n",
    "    \n",
    "    G = G.groupby(['unique_id'])\n",
    "    S = S.groupby(['unique_id'])\n",
    "    \n",
    "    ts_data = []\n",
    "    meta_data = []\n",
    "    for idx, group in G:\n",
    "        group = group.reset_index(drop=True)\n",
    "        meta_data.append(group.values[:, :2]) # save unique_id and ds\n",
    "        ts_data.append(group.values[:, 2:]) # avoid unique_id and ds\n",
    "        \n",
    "    s_data = []\n",
    "    for idx, group in S:\n",
    "        s_data.append(group.iloc[:, 1:].values) # avoid unique_id\n",
    "        assert len(s_data[-1])==1, 'Check repetitions of unique_ids'\n",
    "    \n",
    "    del S, Y, X, M, G\n",
    "    gc.collect()\n",
    "    \n",
    "    return ts_data, s_data, meta_data, t_cols, s_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def _create_tensor(self: TimeSeriesDataset, \n",
    "                   ts_data: List[Dict[str, np.ndarray]], \n",
    "                   s_data: List[Dict[str, np.ndarray]]) -> Tuple[np.ndarray, \n",
    "                                                                 np.ndarray,\n",
    "                                                                 np.ndarray]:\n",
    "    \"\"\"Transforms outputs from self._df_to_lists to numpy arrays.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ts_data: List[Dict[str, np.ndarray]]\n",
    "        Each element of the list is a dictionary with target, exogenous\n",
    "        and mask values.\n",
    "    s_data: List[Dict[str, np.ndarray]]\n",
    "        Each element of the list is a dictionary with static variables.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple of three elements:\n",
    "        - ts_tensor of shape (n_series, n_channels, max_len) n_channels = t_cols + masks\n",
    "        - s_matrix of shape (n_series, n_s)\n",
    "        - len_series: numpy array with series lenghts.\n",
    "    \"\"\"\n",
    "    ts_tensor = np.zeros((self.n_series, self.n_channels, self.max_len))\n",
    "\n",
    "    len_series = []\n",
    "    for idx, ts_idx in enumerate(ts_data):\n",
    "        # Left padded time series tensor\n",
    "        ts_tensor[idx, :, -ts_idx.shape[0]:] = ts_idx.T\n",
    "        len_series.append(ts_idx.shape[0])\n",
    "    \n",
    "    s_matrix = np.vstack(s_data)\n",
    "    len_series = np.array(len_series)\n",
    "    \n",
    "    return ts_tensor, s_matrix, len_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def _define_attributes_by_mode(self: TimeSeriesDataset):\n",
    "    if self.mode in ['simple']:\n",
    "        self.windows_size = self.input_size + self.output_size\n",
    "        self.padding = (self.input_size, self.output_size)\n",
    "    elif self.mode in ['full']:\n",
    "        self.windows_size = self.len_sample_chunks\n",
    "        self.padding = (0, 0)\n",
    "    else:\n",
    "        raise Exception(f'There is no batch strategy for {self.mode}')\n",
    "    \n",
    "    assert self.windows_size <= self.window_sampling_limit, (\n",
    "        'Window sampling limit should be at least input_size + output_size '\n",
    "        'for simple mode or at least len_sample_chunks for full mode.'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def _define_sampleable_ts_idxs(self: TimeSeriesDataset):\n",
    "    sum_sample_mask = self.ts_tensor[:, self.t_cols.index('sample_mask')] \\\n",
    "                          .sum(axis=1)\n",
    "    if self.complete_inputs:\n",
    "        min_mask = self.windows_size\n",
    "    else:\n",
    "        min_mask = self.output_size\n",
    "    self.sampleable_ts_idxs = np.argwhere(sum_sample_mask > min_mask).reshape(1, -1)[0]\n",
    "    self.n_sampleable_ts = self.sampleable_ts_idxs.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def _get_f_idxs(self: TimeSeriesDataset, \n",
    "               cols: List[str]) -> List:\n",
    "    \"\"\"Gets indexes of exogenous variables.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cols: List[str]\n",
    "        Interest exogenous variables.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Indexes of cols variables.\n",
    "    \"\"\"\n",
    "    # Check if cols are available f_cols and return the idxs\n",
    "    if not all(col in self.f_cols for col in cols):\n",
    "        str_cols = ', '.join(cols)\n",
    "        raise Exception(f'Some variables in {str_cols} are not available in f_cols.')\n",
    "    \n",
    "    f_idxs = [self.t_cols.index(col) for col in cols]\n",
    "\n",
    "    return f_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def _create_windows_tensor(self: TimeSeriesDataset, \n",
    "                           idx: slice) -> Tuple[t.Tensor, t.Tensor, t.Tensor]:\n",
    "    \"\"\"Creates windows of size windows_size from\n",
    "    the ts_tensor of the TimeSeriesDataset filtered by\n",
    "    window_sampling_limit and ts_idxs. The step of each window\n",
    "    is defined by idx_to_sample_freq.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    index: slice\n",
    "        Indexes of time series to consider.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple of three elements:\n",
    "        - Windows tensor of shape (windows, channels, input_size + output_size)\n",
    "        - Static variables tensor of shape (windows * series, n_static)\n",
    "        - Time Series indexes for each window.\n",
    "    \"\"\"\n",
    "    # Default ts_idxs=ts_idxs sends all the data, otherwise filters series   \n",
    "    tensor = self.ts_tensor[idx, :, self.first_ds:]\n",
    "    tensor = t.Tensor(tensor)\n",
    "\n",
    "    padder = t.nn.ConstantPad1d(padding=self.padding, value=0)\n",
    "    tensor = padder(tensor)\n",
    "\n",
    "    # Creating rolling windows and 'flattens' them\n",
    "    windows = tensor.unfold(dimension=-1, \n",
    "                            size=self.windows_size, \n",
    "                            step=self.idx_to_sample_freq)\n",
    "    # n_serie, n_channel, n_time, window_size -> n_serie, n_time, n_channel, window_size\n",
    "    windows = windows.permute(0, 2, 1, 3)\n",
    "    windows = windows.reshape(-1, self.n_channels, self.windows_size)\n",
    "    \n",
    "    # Broadcast s_matrix: This works because unfold in windows_tensor, orders: serie, time\n",
    "    \n",
    "    ts_idxs = self.ts_idxs[idx]\n",
    "    n_ts = len(ts_idxs)\n",
    "    windows_per_serie = len(windows) / n_ts\n",
    "    \n",
    "    ts_idxs = ts_idxs.repeat(repeats=windows_per_serie)\n",
    "    s_matrix = self.s_matrix[idx]\n",
    "    s_matrix = s_matrix.repeat(repeats=windows_per_serie, axis=0)\n",
    "    \n",
    "    s_matrix = t.Tensor(s_matrix)\n",
    "    ts_idxs = t.as_tensor(ts_idxs, dtype=t.long)\n",
    "\n",
    "    return windows, s_matrix, ts_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def _get_sampleable_windows_idxs(self: TimeSeriesDataset, \n",
    "                                 ts_windows_flatten: t.Tensor) -> np.ndarray:\n",
    "    \"\"\"Gets indexes of windows that fulfills conditions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ts_windows_flatten: t.Tensor\n",
    "        Tensor of shape (windows, n_channels, windows_size)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Numpy array of indexes of ts_windows_flatten that \n",
    "    fulfills conditions.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    [1] If complete_inputs=True\n",
    "        return all windows which its ouput_size \n",
    "        has complete sample_mask and its input_size\n",
    "        has complete available_mask.\n",
    "    [2] If complete_inputs=False\n",
    "        returns all windows which its\n",
    "        output_size has complete sample_mask. \n",
    "        This avoids leakage.\n",
    "    [3] If complete_outputs=False\n",
    "        returns all windows which its\n",
    "        output_size has complete sample_mask. \n",
    "        This avoids leakage.\n",
    "    [4] If complete_outputs=True\n",
    "        return all windows which its ouput_size \n",
    "        has complete sample_mask and its output_size\n",
    "        has complete available_mask.\n",
    "    \"\"\"\n",
    "    sample_condition = ts_windows_flatten[:, self.t_cols.index('sample_mask'), -self.output_size:]\n",
    "    sample_condition = t.sum(sample_condition, axis=1)\n",
    "    sample_condition = (sample_condition == self.output_size) * 1\n",
    "    if self.complete_inputs:\n",
    "        av_condition_in = ts_windows_flatten[:, self.t_cols.index('available_mask'), \n",
    "                                                 :-self.output_size]\n",
    "        av_condition_in = t.sum(av_condition_in, axis=1)\n",
    "        av_condition_in = (av_condition_in == self.windows_size - self.output_size) * 1\n",
    "    else:\n",
    "        av_condition_in = sample_condition\n",
    "        \n",
    "    if self.complete_outputs:\n",
    "        av_condition_out = ts_windows_flatten[:, self.t_cols.index('available_mask'), \n",
    "                                              -(self.output_size + 1):]\n",
    "        av_condition_out = t.sum(av_condition_out, axis=1)\n",
    "        av_condition_out = (av_condition_out == self.output_size + 1) * 1\n",
    "    else:\n",
    "        av_condition_out = sample_condition\n",
    "        \n",
    "    sampling_idx = t.nonzero(av_condition_in * av_condition_out * sample_condition > 0)\n",
    "\n",
    "    sampling_idx = sampling_idx.flatten().numpy()\n",
    "    assert sampling_idx.size > 0, (\n",
    "        'Check the data and masks as sample_idxs are empty, '\n",
    "        'check window_sampling_limit, input_size, output_size, masks'\n",
    "    )\n",
    "    \n",
    "    return sampling_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def __getitem__(self: TimeSeriesDataset, \n",
    "                idx: Union[slice, int]) -> Dict[str, t.Tensor]:\n",
    "    \"\"\"Creates batch based on index.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    index: np.ndarray\n",
    "        Indexes of time series to consider.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary with keys:\n",
    "        - S\n",
    "        - Y\n",
    "        - X\n",
    "        - available_mask\n",
    "        - sample_mask\n",
    "        - idxs\n",
    "    \"\"\"\n",
    "    # Checks for idx\n",
    "    if isinstance(idx, int):\n",
    "        idx = [idx]\n",
    "    elif isinstance(idx, slice):\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception('Use slices for getitem.')\n",
    "    \n",
    "\n",
    "    # Create windows for each sampled ts and sample random unmasked windows from each ts\n",
    "    windows, s_matrix, ts_idxs = self._create_windows_tensor(idx=idx)\n",
    "    windows_idxs = self._get_sampleable_windows_idxs(ts_windows_flatten=windows)\n",
    "\n",
    "    # Index the windows and s_matrix tensors of batch\n",
    "    windows = windows[windows_idxs]\n",
    "    S = s_matrix[windows_idxs]\n",
    "    ts_idxs = ts_idxs[windows_idxs]\n",
    "\n",
    "    # Parse windows to elements of batch\n",
    "    Y = windows[:, self.t_cols.index('y'), :]\n",
    "    X = windows[:, (self.t_cols.index('y') + 1):self.t_cols.index('available_mask'), :]\n",
    "    available_mask = windows[:, self.t_cols.index('available_mask'), :]\n",
    "    sample_mask = windows[:, self.t_cols.index('sample_mask'), :]\n",
    "\n",
    "    batch = {'S': S, 'Y': Y, 'X': X,\n",
    "             'available_mask': available_mask,\n",
    "             'sample_mask': sample_mask,\n",
    "             'idxs': ts_idxs}\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def __len__(self: TimeSeriesDataset):\n",
    "    return self.n_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_default_mask_df(Y_df: pd.DataFrame, \n",
    "                        ds_in_test: int, \n",
    "                        is_test: bool) -> pd.DataFrame:\n",
    "    \"\"\"Constructs default mask df.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Y_df: pd.DataFrame\n",
    "        Target time series with columns ['unique_id', 'ds', 'y'].\n",
    "    ds_in_test: int\n",
    "        Numer of datestamps to use as outsample.\n",
    "    is_test: bool\n",
    "        Wheter target time series belongs to test set.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Mask DataFrame with columns \n",
    "    ['unique_id', 'ds', 'available_mask', 'sample_mask'].\n",
    "    \"\"\"\n",
    "    mask_df = Y_df[['unique_id', 'ds']].copy()\n",
    "    mask_df['available_mask'] = 1\n",
    "    mask_df['sample_mask'] = 1\n",
    "    mask_df = mask_df.set_index(['unique_id', 'ds'])\n",
    "    \n",
    "    mask_df_s = mask_df.sort_values(by=['unique_id', 'ds'])\n",
    "    zero_idx = mask_df_s.groupby('unique_id').tail(ds_in_test).index\n",
    "    mask_df.loc[zero_idx, 'sample_mask'] = 0\n",
    "    mask_df = mask_df.reset_index()\n",
    "    mask_df.index = Y_df.index\n",
    "\n",
    "    assert len(mask_df)==len(Y_df), \\\n",
    "        f'The mask_df length {len(mask_df)} is not equal to Y_df length {len(Y_df)}'\n",
    "\n",
    "    if is_test:\n",
    "        mask_df['sample_mask'] = 1 - mask_df['sample_mask']\n",
    "\n",
    "    return mask_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default mask example and tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_default_mask(Y_df, ds_in_test, is_test):\n",
    "    mask_df = get_default_mask_df(Y_df, ds_in_test, is_test)\n",
    "    assert Y_df.index.equals(mask_df.index), 'Unmatching index bewteen Y_df and mask_df'\n",
    "    \n",
    "    for uid, df in mask_df.groupby('unique_id'):\n",
    "        len_ts = df.shape[0]\n",
    "        expected_sample_mask = np.ones(len_ts)\n",
    "        expected_sample_mask[-ds_in_test:] = 0\n",
    "        if is_test: \n",
    "            expected_sample_mask = 1 - expected_sample_mask\n",
    "        expected_available_mask = np.ones(len_ts)\n",
    "        \n",
    "        sample_mask = df['sample_mask'].values\n",
    "        available_mask = df['available_mask'].values\n",
    "        \n",
    "        assert np.array_equal(sample_mask, expected_sample_mask), (\n",
    "            f'Error for sample mask for time series {uid}'\n",
    "        )\n",
    "        \n",
    "        assert np.array_equal(available_mask, expected_available_mask), (\n",
    "            f'Error for available mask for time series {uid}'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for synthtetic time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nixtla.data.utils import create_synthetic_tsdata\n",
    "\n",
    "Y_df, X_df, S_df = create_synthetic_tsdata()\n",
    "ds_in_test = 2\n",
    "is_test = False\n",
    "test_default_mask(Y_df, ds_in_test, is_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example and test for datasets with two time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f09154b1810>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nixtla.data.datasets.epf import EPF, EPFInfo\n",
    "\n",
    "Y_df, X_df, S_df = EPF.load_groups(directory='data', groups=['NP', 'PJM'])\n",
    "test_default_mask(Y_df, ds_in_test=728 * 24, is_test=False)\n",
    "mask_df = get_default_mask_df(Y_df=Y_df, ds_in_test=728 * 24, is_test=False)\n",
    "\n",
    "plt.plot(mask_df.sample_mask.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for datasets with more than two time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nixtla.data.datasets.tourism import Tourism, TourismInfo\n",
    "\n",
    "meta = TourismInfo['Yearly']\n",
    "Y_df, *_ = Tourism.load(directory='data', group=meta.name)\n",
    "test_default_mask(Y_df, ds_in_test=meta.horizon, is_test=False)\n",
    "test_default_mask(Y_df, ds_in_test=meta.horizon, is_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_dataset(Y_df, S_df, X_df, f_cols = None, ds_in_test = 0, is_test = False,\n",
    "                        window_sampling_limit = 1):\n",
    "    mask_df = get_default_mask_df(Y_df=Y_df, ds_in_test=ds_in_test, is_test=is_test)\n",
    "    dataset = TimeSeriesDataset(Y_df=Y_df, S_df=S_df, X_df=X_df, f_cols=f_cols, \n",
    "                                mask_df=mask_df, \n",
    "                                window_sampling_limit=window_sampling_limit)\n",
    "    \n",
    "    return dataset, mask_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataset_attrs(Y_df, S_df, X_df, f_cols, ds_in_test, is_test):\n",
    "    # This set catches mistmaches between Y_df and ts_tensor\n",
    "    dataset, mask_df = instantiate_dataset(Y_df=Y_df, S_df=S_df, X_df=X_df, \n",
    "                                           f_cols=f_cols, ds_in_test=ds_in_test, \n",
    "                                           is_test=is_test)\n",
    "    \n",
    "    dfs = [Y_df, X_df, mask_df]\n",
    "    dfs = [df.set_index(['unique_id', 'ds']) for df in dfs]\n",
    "    dfs = dfs[0].join(dfs[1:])\n",
    "    \n",
    "    #Temporal variables\n",
    "    for idx_ts, (uid, df) in enumerate(dfs.groupby('unique_id')):\n",
    "        len_ts = dataset.len_series[idx_ts]\n",
    "        \n",
    "        for col in dataset.t_cols:\n",
    "            ts = df[col].values\n",
    "            idx_tensor = dataset.t_cols.index(col)\n",
    "            ts_tensor = dataset.ts_tensor[idx_ts, idx_tensor, -len_ts:]\n",
    "            \n",
    "            assert np.array_equal(ts, ts_tensor), (\n",
    "                f'Error with time series {uid} and col {col} (idx={idx_ts}).'\n",
    "            )\n",
    "            \n",
    "    #Static variables\n",
    "    for idx_ts, (uid, df) in enumerate(S_df.groupby('unique_id')):\n",
    "        len_ts = dataset.len_series[idx_ts]\n",
    "        \n",
    "        s = df[dataset.s_cols].values\n",
    "        s_matrix = dataset.s_matrix[[idx_ts]]\n",
    "\n",
    "        assert np.array_equal(s, s_matrix), (\n",
    "            f'Error with static variables for time series {uid} (idx={idx_ts})'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_f_idxs(Y_df, S_df, X_df, f_cols, ds_in_test, is_test, expected_f_idxs):\n",
    "    dataset, mask_df = instantiate_dataset(Y_df=Y_df, S_df=S_df, X_df=X_df, \n",
    "                                           f_cols=f_cols, ds_in_test=ds_in_test, \n",
    "                                           is_test=is_test)\n",
    "    \n",
    "    assert dataset._get_f_idxs(f_cols) == expected_f_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ts_tensor(Y_df, S_df, X_df, f_cols, ds_in_test, is_test, \n",
    "                   window_sampling_limit, ts_idxs, output_size):\n",
    "    dataset, mask_df = instantiate_dataset(Y_df=Y_df, S_df=S_df, X_df=X_df, \n",
    "                                           f_cols=f_cols, ds_in_test=ds_in_test, \n",
    "                                           is_test=is_test,\n",
    "                                           window_sampling_limit=window_sampling_limit)\n",
    "    \n",
    "    min_len = min(dataset.len_series)\n",
    "    wsl = window_sampling_limit\n",
    "    if wsl > min_len:\n",
    "        raise Exception('This test only works for window_sampling_limit '\n",
    "                        'lower than the size of the shortest time series.')\n",
    "    \n",
    "    dfs = [Y_df, X_df, mask_df]\n",
    "    dfs = [df.set_index(['unique_id', 'ds']) for df in dfs]\n",
    "    dfs = dfs[0].join(dfs[1:])\n",
    "    dfs = dfs.groupby('unique_id').tail(wsl)\n",
    "    # This process only works for balanced datasets.\n",
    "\n",
    "    n_ts = Y_df['unique_id'].unique().shape[0]\n",
    "    n_x = dfs.columns.shape[0]\n",
    "    idxs = range(n_ts) if ts_idxs is None else ts_idxs\n",
    "\n",
    "    e_filtered_tensor = dfs.values.reshape((n_ts, wsl, n_x))[idxs]\n",
    "    e_filtered_tensor = np.swapaxes(e_filtered_tensor, 2, 1)\n",
    "    filtered_tensor = dataset.ts_tensor[ts_idxs, :, dataset.first_ds:]\n",
    "    \n",
    "    assert np.array_equal(e_filtered_tensor, filtered_tensor), (\n",
    "        \"Expected and dataset filtered_tensor are different. Check.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for not sorted datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nixtla.data.utils import create_synthetic_tsdata\n",
    "\n",
    "Y_df, X_df, S_df = create_synthetic_tsdata()\n",
    "ds_in_test = 2\n",
    "is_test = False\n",
    "f_cols = ['future_1']\n",
    "expected_f_idxs = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_attrs(Y_df, S_df, X_df, f_cols=f_cols, ds_in_test=ds_in_test, is_test=is_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_get_f_idxs(Y_df, S_df, X_df, f_cols=f_cols, ds_in_test=ds_in_test, is_test=is_test, \n",
    "                expected_f_idxs=expected_f_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected error for non-sorted datasets \n",
    "\n",
    "For the `ts_tensor` attribute from the `dataset` and `Y_df` to have the same order it is necessary that `Y_df` is sorted by `unique_id` and `ds`. This test (expected error) proves that for unordered data the order is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fail_non_sorted(): \n",
    "    test_ts_tensor(Y_df, S_df, X_df, f_cols=f_cols, \n",
    "                   ds_in_test=ds_in_test, \n",
    "                   is_test=is_test,\n",
    "                   window_sampling_limit=1, \n",
    "                   ts_idxs=[1, 0], \n",
    "                   output_size=ds_in_test)\n",
    "test_fail(_fail_non_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for already sorted datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nixtla.data.datasets.epf import EPF, EPFInfo\n",
    "\n",
    "Y_df, X_df, S_df = EPF.load_groups(directory='data', groups=['NP', 'PJM'])\n",
    "f_cols = ['Exogenous1', 'Exogenous2']\n",
    "ds_in_test = 728 * 24\n",
    "is_test = True\n",
    "expected_f_idxs = [1, 2] #after y column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_attrs(Y_df, S_df, X_df, f_cols=f_cols, ds_in_test=ds_in_test, is_test=is_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ts_tensor(Y_df, S_df, X_df, f_cols=f_cols, ds_in_test=ds_in_test, is_test=is_test,\n",
    "               window_sampling_limit=2_000, ts_idxs=[1, 0], \n",
    "               output_size=ds_in_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_get_f_idxs(Y_df, S_df, X_df, f_cols=f_cols, ds_in_test=ds_in_test, is_test=is_test, \n",
    "                expected_f_idxs=expected_f_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for datasets with more than two time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nixtla.data.datasets.tourism import Tourism, TourismInfo\n",
    "\n",
    "meta = TourismInfo['Yearly']\n",
    "df, *_ = Tourism.load(directory='./data', group=meta.name)\n",
    "df['day_of_week'] = df['ds'].dt.day_of_week\n",
    "df['id_ts'] = df['unique_id'].astype('category').cat.codes\n",
    "\n",
    "Y_df = df.filter(items=['unique_id', 'ds', 'y'])\n",
    "X_df = df.filter(items=['unique_id', 'ds', 'day_of_week'])\n",
    "S_df = df.filter(items=['unique_id', 'id_ts']).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y1</td>\n",
       "      <td>1979-12-31</td>\n",
       "      <td>25092.2284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y1</td>\n",
       "      <td>1980-12-31</td>\n",
       "      <td>24271.5134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y1</td>\n",
       "      <td>1981-12-31</td>\n",
       "      <td>25828.9883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y1</td>\n",
       "      <td>1982-12-31</td>\n",
       "      <td>27697.5047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y1</td>\n",
       "      <td>1983-12-31</td>\n",
       "      <td>27956.2276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Y1</td>\n",
       "      <td>1984-12-31</td>\n",
       "      <td>29924.4321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Y1</td>\n",
       "      <td>1985-12-31</td>\n",
       "      <td>30216.8321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Y1</td>\n",
       "      <td>1986-12-31</td>\n",
       "      <td>32613.4968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Y1</td>\n",
       "      <td>1987-12-31</td>\n",
       "      <td>36053.1674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Y1</td>\n",
       "      <td>1988-12-31</td>\n",
       "      <td>38472.7532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Y1</td>\n",
       "      <td>1989-12-31</td>\n",
       "      <td>38420.8940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Y1</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>36555.6156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Y1</td>\n",
       "      <td>1991-12-31</td>\n",
       "      <td>37385.6371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Y1</td>\n",
       "      <td>1992-12-31</td>\n",
       "      <td>38431.9699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Y1</td>\n",
       "      <td>1993-12-31</td>\n",
       "      <td>40345.3300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id         ds           y\n",
       "0         Y1 1979-12-31  25092.2284\n",
       "1         Y1 1980-12-31  24271.5134\n",
       "2         Y1 1981-12-31  25828.9883\n",
       "3         Y1 1982-12-31  27697.5047\n",
       "4         Y1 1983-12-31  27956.2276\n",
       "5         Y1 1984-12-31  29924.4321\n",
       "6         Y1 1985-12-31  30216.8321\n",
       "7         Y1 1986-12-31  32613.4968\n",
       "8         Y1 1987-12-31  36053.1674\n",
       "9         Y1 1988-12-31  38472.7532\n",
       "10        Y1 1989-12-31  38420.8940\n",
       "11        Y1 1990-12-31  36555.6156\n",
       "12        Y1 1991-12-31  37385.6371\n",
       "13        Y1 1992-12-31  38431.9699\n",
       "14        Y1 1993-12-31  40345.3300"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_df.query('unique_id==\"Y1\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    r\"\"\"Puts each data field into a tensor with outer dimension batch size\"\"\"\n",
    "\n",
    "    elem = batch[0]\n",
    "    elem_type = type(elem)\n",
    "    if isinstance(elem, t.Tensor):\n",
    "        out = None\n",
    "        if t.utils.data.get_worker_info() is not None:\n",
    "            # If we're in a background process, concatenate directly into a\n",
    "            # shared memory tensor to avoid an extra copy\n",
    "            numel = sum([x.numel() for x in batch])\n",
    "            storage = elem.storage()._new_shared(numel)\n",
    "            out = elem.new(storage)\n",
    "        return t.cat(batch, out=out)\n",
    "    elif isinstance(elem, collections.abc.Mapping):\n",
    "        return {key: collate_fn([d[key] for d in batch]) for key in elem}\n",
    "    \n",
    "    raise TypeError(default_collate_err_msg_format.format(elem_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TimeSeriesDataset(Y_df, input_size=3)\n",
    "loader = DataLoader(dataset, batch_size=12, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,\n",
      "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,\n",
      "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11])\n",
      "tensor([12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "        12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "        13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "        15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "        17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "        18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "        19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "        20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22,\n",
      "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23])\n",
      "tensor([24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n",
      "        24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "        25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
      "        26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
      "        27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
      "        28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
      "        29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
      "        30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31,\n",
      "        31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 34, 34,\n",
      "        34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35,\n",
      "        35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35])\n",
      "tensor([36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
      "        36, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
      "        37, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38,\n",
      "        38, 38, 38, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
      "        39, 39, 39, 39, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41,\n",
      "        41, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,\n",
      "        42, 42, 42, 42, 42, 42, 42, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
      "        43, 43, 43, 43, 43, 43, 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44,\n",
      "        44, 44, 44, 44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45, 45, 45,\n",
      "        45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46,\n",
      "        46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47, 47, 47,\n",
      "        47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47])\n",
      "tensor([48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n",
      "        48, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49,\n",
      "        49, 49, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
      "        50, 50, 50, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51,\n",
      "        51, 51, 51, 51, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52,\n",
      "        52, 52, 52, 52, 52, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
      "        53, 53, 53, 53, 53, 53, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54,\n",
      "        54, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55,\n",
      "        55, 55, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
      "        56, 56, 56, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 58, 58,\n",
      "        58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 59, 59, 59, 59, 59, 59, 59,\n",
      "        59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59])\n",
      "tensor([60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60,\n",
      "        60, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62,\n",
      "        62, 62, 62, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63,\n",
      "        63, 63, 63, 63, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64,\n",
      "        64, 64, 64, 64, 64, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66,\n",
      "        66, 66, 66, 66, 66, 66, 66, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67,\n",
      "        67, 67, 67, 67, 67, 67, 67, 67, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68,\n",
      "        68, 68, 68, 68, 68, 68, 68, 68, 68, 69, 69, 69, 69, 69, 69, 69, 69, 69,\n",
      "        69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 71, 71, 71, 71, 71, 71, 71,\n",
      "        71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71])\n",
      "tensor([72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72,\n",
      "        72, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73,\n",
      "        73, 73, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74,\n",
      "        74, 74, 74, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75,\n",
      "        75, 75, 75, 75, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76,\n",
      "        76, 76, 76, 76, 76, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77,\n",
      "        77, 77, 77, 77, 77, 77, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78,\n",
      "        78, 78, 78, 78, 78, 78, 78, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79,\n",
      "        79, 79, 79, 79, 79, 79, 79, 79, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
      "        80, 80, 80, 80, 80, 80, 80, 80, 80, 81, 81, 81, 81, 81, 81, 81, 81, 81,\n",
      "        81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 82, 82, 82, 82, 82, 82, 82, 82,\n",
      "        82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 83, 83, 83, 83, 83, 83, 83,\n",
      "        83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83])\n",
      "tensor([84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84,\n",
      "        84, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85,\n",
      "        85, 85, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86,\n",
      "        86, 86, 86, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87,\n",
      "        87, 87, 87, 87, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88,\n",
      "        88, 88, 88, 88, 88, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89,\n",
      "        89, 89, 89, 89, 89, 89, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90,\n",
      "        90, 90, 90, 90, 90, 90, 90, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91,\n",
      "        91, 91, 91, 91, 91, 91, 91, 91, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92,\n",
      "        92, 92, 92, 92, 92, 92, 92, 92, 92, 93, 93, 93, 93, 93, 93, 93, 93, 93,\n",
      "        93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 94, 94, 94, 94, 94, 94, 94, 94,\n",
      "        94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 95, 95, 95, 95, 95, 95, 95,\n",
      "        95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95])\n",
      "tensor([ 96,  96,  96,  96,  96,  96,  96,  96,  96,  96,  96,  96,  96,  96,\n",
      "         96,  96,  96,  96,  96,  97,  97,  97,  97,  97,  97,  97,  97,  97,\n",
      "         97,  97,  97,  97,  97,  97,  97,  97,  97,  97,  98,  98,  98,  98,\n",
      "         98,  98,  98,  98,  98,  98,  98,  98,  98,  98,  98,  98,  98,  98,\n",
      "         98,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,\n",
      "         99,  99,  99,  99,  99,  99, 100, 100, 100, 100, 100, 100, 100, 100,\n",
      "        100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 101, 101, 101,\n",
      "        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
      "        101, 101, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102,\n",
      "        102, 102, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 103, 103,\n",
      "        103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 104, 104,\n",
      "        104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104,\n",
      "        104, 104, 104, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,\n",
      "        105, 105, 105, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 106,\n",
      "        106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 107,\n",
      "        107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
      "        107, 107, 107, 107])\n",
      "tensor([108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
      "        108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 109, 109, 109, 109,\n",
      "        109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 110, 110, 110, 110,\n",
      "        110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110,\n",
      "        110, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111,\n",
      "        111, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112,\n",
      "        112, 112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 114, 114, 114,\n",
      "        114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114,\n",
      "        114, 114, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,\n",
      "        115, 115, 115, 115, 115, 115, 115, 116, 116, 116, 116, 116, 116, 116,\n",
      "        116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 117, 117,\n",
      "        117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117,\n",
      "        117, 117, 117, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 119, 119, 119, 119, 119, 119,\n",
      "        119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119])\n",
      "tensor([120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n",
      "        120, 120, 120, 120, 120, 121, 121, 121, 121, 121, 121, 121, 121, 121,\n",
      "        121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 122, 122, 122, 122,\n",
      "        122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122,\n",
      "        122, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,\n",
      "        123, 123, 123, 123, 123, 123, 124, 124, 124, 124, 124, 124, 124, 124,\n",
      "        124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 125, 125, 125,\n",
      "        125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125,\n",
      "        125, 125, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126,\n",
      "        126, 126, 126, 126, 126, 126, 126, 127, 127, 127, 127, 127, 127, 127,\n",
      "        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 130, 130, 130, 130, 130, 130,\n",
      "        130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 131,\n",
      "        131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131,\n",
      "        131, 131, 131, 131])\n",
      "tensor([132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 133, 133, 133, 133, 133, 133, 133, 133, 133,\n",
      "        133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135,\n",
      "        135, 135, 135, 135, 135, 135, 136, 136, 136, 136, 136, 136, 136, 136,\n",
      "        136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 137, 137, 137,\n",
      "        137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,\n",
      "        137, 137, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,\n",
      "        138, 138, 138, 138, 138, 138, 138, 139, 139, 139, 139, 139, 139, 139,\n",
      "        139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 140, 140,\n",
      "        140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,\n",
      "        140, 140, 140, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,\n",
      "        141, 141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142, 142, 142,\n",
      "        142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 143,\n",
      "        143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,\n",
      "        143, 143, 143, 143])\n",
      "tensor([144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,\n",
      "        144, 144, 144, 144, 144, 145, 145, 145, 145, 145, 145, 145, 145, 145,\n",
      "        145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 146, 146, 146, 146,\n",
      "        146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,\n",
      "        146, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 148, 148, 148, 148, 148, 148, 148, 148,\n",
      "        148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 149, 149, 149,\n",
      "        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,\n",
      "        149, 149, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,\n",
      "        150, 150, 150, 150, 150, 150, 150, 151, 151, 151, 151, 151, 151, 151,\n",
      "        151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 152, 152,\n",
      "        152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,\n",
      "        152, 152, 152, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,\n",
      "        153, 153, 153, 153, 153, 153, 153, 153, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 155,\n",
      "        155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,\n",
      "        155, 155, 155, 155])\n",
      "tensor([156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 157, 157, 157, 157, 157, 157, 157, 157, 157,\n",
      "        157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 158, 158, 158, 158,\n",
      "        158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,\n",
      "        158, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,\n",
      "        159, 159, 159, 159, 159, 159, 160, 160, 160, 160, 160, 160, 160, 160,\n",
      "        160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,\n",
      "        162, 162, 162, 162, 162, 162, 162, 163, 163, 163, 163, 163, 163, 163,\n",
      "        163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 164, 164,\n",
      "        164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164,\n",
      "        164, 164, 164, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 167, 167, 167, 167, 167, 167, 167, 167, 167,\n",
      "        167, 167, 167, 167, 167, 167, 167, 167, 167, 167])\n",
      "tensor([168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168,\n",
      "        168, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169,\n",
      "        169, 169, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170,\n",
      "        170, 170, 170, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171,\n",
      "        171, 171, 171, 171, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172,\n",
      "        172, 172, 172, 172, 172, 173, 173, 173, 173, 173, 173, 173, 173, 173,\n",
      "        173, 173, 173, 173, 173, 173, 174, 174, 174, 174, 174, 174, 174, 174,\n",
      "        174, 174, 174, 174, 174, 174, 174, 175, 175, 175, 175, 175, 175, 175,\n",
      "        175, 175, 175, 175, 175, 175, 175, 175, 176, 176, 176, 176, 176, 176,\n",
      "        176, 176, 176, 176, 176, 176, 176, 176, 176, 177, 177, 177, 177, 177,\n",
      "        177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 178, 178, 178, 178,\n",
      "        178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178,\n",
      "        178, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179,\n",
      "        179, 179])\n",
      "tensor([180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180,\n",
      "        180, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181,\n",
      "        181, 181, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182,\n",
      "        182, 182, 182, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183,\n",
      "        183, 183, 183, 183, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184,\n",
      "        184, 184, 184, 184, 184, 185, 185, 185, 185, 185, 185, 185, 185, 185,\n",
      "        185, 185, 185, 185, 185, 185, 186, 186, 186, 186, 186, 186, 186, 186,\n",
      "        186, 186, 186, 186, 186, 186, 186, 187, 187, 187, 187, 187, 187, 187,\n",
      "        187, 187, 187, 187, 187, 187, 187, 187, 188, 188, 188, 188, 188, 188,\n",
      "        188, 188, 188, 188, 188, 188, 188, 188, 188, 189, 189, 189, 189, 189,\n",
      "        189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189,\n",
      "        190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 191,\n",
      "        191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191])\n",
      "tensor([192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192,\n",
      "        192, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193,\n",
      "        193, 193, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194,\n",
      "        194, 194, 194, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195,\n",
      "        195, 195, 195, 195, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 197, 197, 197, 197, 197, 197, 197, 197, 197,\n",
      "        197, 197, 197, 197, 197, 197, 198, 198, 198, 198, 198, 198, 198, 198,\n",
      "        198, 198, 198, 198, 198, 198, 198, 199, 199, 199, 199, 199, 199, 199,\n",
      "        199, 199, 199, 199, 199, 199, 199, 199, 200, 200, 200, 200, 200, 200,\n",
      "        200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 201,\n",
      "        201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
      "        202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202,\n",
      "        202, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203,\n",
      "        203])\n",
      "tensor([204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204,\n",
      "        204, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205,\n",
      "        205, 205, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206,\n",
      "        206, 206, 206, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207,\n",
      "        207, 207, 207, 207, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208,\n",
      "        208, 208, 208, 208, 208, 209, 209, 209, 209, 209, 209, 209, 209, 209,\n",
      "        209, 209, 209, 209, 209, 209, 210, 210, 210, 210, 210, 210, 210, 210,\n",
      "        210, 210, 210, 210, 210, 210, 210, 211, 211, 211, 211, 211, 211, 211,\n",
      "        211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 213,\n",
      "        213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213,\n",
      "        214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214,\n",
      "        214, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215,\n",
      "        215, 215])\n",
      "tensor([216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216,\n",
      "        216, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217,\n",
      "        217, 217, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218,\n",
      "        218, 218, 218, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219,\n",
      "        219, 219, 219, 219, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220,\n",
      "        220, 220, 220, 220, 220, 221, 221, 221, 221, 221, 221, 221, 221, 221,\n",
      "        221, 221, 221, 221, 221, 222, 222, 222, 222, 222, 222, 222, 222, 222,\n",
      "        222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 223, 223, 223, 223,\n",
      "        223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223,\n",
      "        223, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224,\n",
      "        224, 224, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225,\n",
      "        225, 225, 225, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226,\n",
      "        226, 226, 226, 226, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227,\n",
      "        227, 227, 227, 227, 227])\n",
      "tensor([228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228,\n",
      "        228, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229,\n",
      "        229, 229, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230,\n",
      "        230, 230, 230, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231,\n",
      "        231, 231, 231, 231, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232,\n",
      "        232, 232, 232, 232, 232, 233, 233, 233, 233, 233, 233, 233, 233, 233,\n",
      "        233, 233, 233, 233, 233, 233, 234, 234, 234, 234, 234, 234, 234, 234,\n",
      "        234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 235, 235, 235,\n",
      "        235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 236, 236,\n",
      "        236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 237,\n",
      "        237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237,\n",
      "        238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238,\n",
      "        238, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239,\n",
      "        239, 239])\n",
      "tensor([240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240,\n",
      "        240, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241,\n",
      "        241, 241, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242,\n",
      "        242, 242, 242, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243,\n",
      "        243, 243, 243, 243, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244,\n",
      "        244, 244, 244, 244, 244, 245, 245, 245, 245, 245, 245, 245, 245, 245,\n",
      "        245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 246, 246, 246, 246,\n",
      "        246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 247, 247, 247,\n",
      "        247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247,\n",
      "        247, 247, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248,\n",
      "        248, 248, 248, 248, 248, 248, 248, 249, 249, 249, 249, 249, 249, 249,\n",
      "        249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 250, 250,\n",
      "        250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250,\n",
      "        250, 250, 250, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
      "        251, 251, 251, 251, 251, 251, 251, 251])\n",
      "tensor([252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252,\n",
      "        252, 252, 252, 252, 252, 253, 253, 253, 253, 253, 253, 253, 253, 253,\n",
      "        253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 254, 254, 254, 254,\n",
      "        254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254,\n",
      "        254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
      "        255, 255, 255, 255, 255, 255, 256, 256, 256, 256, 256, 256, 256, 256,\n",
      "        256, 256, 256, 256, 256, 256, 257, 257, 257, 257, 257, 257, 257, 257,\n",
      "        257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 258, 258, 258,\n",
      "        258, 258, 258, 258, 258, 258, 258, 258, 258, 258, 258, 258, 258, 258,\n",
      "        258, 258, 259, 259, 259, 259, 259, 259, 259, 259, 259, 259, 259, 259,\n",
      "        259, 259, 259, 259, 259, 259, 259, 260, 260, 260, 260, 260, 260, 260,\n",
      "        260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 261, 261,\n",
      "        261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "        261, 261, 261, 262, 262, 262, 262, 262, 262, 262, 262, 262, 262, 262,\n",
      "        262, 262, 262, 262, 262, 262, 262, 262, 263, 263, 263, 263, 263, 263,\n",
      "        263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263])\n",
      "tensor([264, 264, 264, 264, 264, 264, 264, 264, 264, 264, 264, 264, 264, 264,\n",
      "        264, 264, 264, 264, 264, 265, 265, 265, 265, 265, 265, 265, 265, 265,\n",
      "        265, 265, 265, 265, 265, 265, 265, 265, 265, 265, 266, 266, 266, 266,\n",
      "        266, 266, 266, 266, 266, 266, 266, 266, 266, 266, 266, 266, 266, 266,\n",
      "        266, 267, 267, 267, 267, 267, 267, 267, 267, 267, 267, 267, 267, 267,\n",
      "        267, 267, 267, 267, 267, 267, 268, 268, 268, 268, 268, 268, 268, 268,\n",
      "        268, 268, 268, 268, 268, 268, 268, 268, 268, 268, 268, 269, 269, 269,\n",
      "        269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 269,\n",
      "        269, 269, 270, 270, 270, 270, 270, 270, 270, 270, 270, 270, 270, 270,\n",
      "        270, 270, 270, 270, 270, 270, 270, 271, 271, 271, 271, 271, 271, 271,\n",
      "        271, 271, 271, 271, 271, 271, 271, 271, 271, 271, 271, 271, 272, 272,\n",
      "        272, 272, 272, 272, 272, 272, 272, 272, 272, 272, 272, 272, 272, 272,\n",
      "        272, 272, 272, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273,\n",
      "        273, 273, 273, 273, 273, 273, 273, 273, 274, 274, 274, 274, 274, 274,\n",
      "        274, 274, 274, 274, 274, 274, 274, 274, 274, 274, 274, 274, 274, 275,\n",
      "        275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275,\n",
      "        275, 275, 275, 275])\n",
      "tensor([276, 276, 276, 276, 276, 276, 276, 276, 276, 276, 276, 276, 276, 276,\n",
      "        276, 276, 276, 276, 276, 277, 277, 277, 277, 277, 277, 277, 277, 277,\n",
      "        277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 278, 278, 278, 278,\n",
      "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
      "        278, 279, 279, 279, 279, 279, 279, 279, 279, 279, 279, 279, 279, 279,\n",
      "        279, 279, 279, 279, 279, 279, 280, 280, 280, 280, 280, 280, 280, 280,\n",
      "        280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 281, 281, 281,\n",
      "        281, 281, 281, 281, 281, 281, 281, 281, 281, 281, 281, 281, 281, 281,\n",
      "        281, 281, 282, 282, 282, 282, 282, 282, 282, 282, 282, 282, 282, 282,\n",
      "        282, 282, 282, 282, 282, 282, 282, 283, 283, 283, 283, 283, 283, 283,\n",
      "        283, 283, 283, 283, 283, 283, 283, 283, 283, 283, 283, 283, 284, 284,\n",
      "        284, 284, 284, 284, 284, 284, 284, 284, 284, 284, 284, 284, 284, 284,\n",
      "        284, 284, 284, 285, 285, 285, 285, 285, 285, 285, 285, 285, 285, 285,\n",
      "        285, 285, 285, 285, 285, 285, 285, 285, 286, 286, 286, 286, 286, 286,\n",
      "        286, 286, 286, 286, 286, 286, 286, 286, 286, 286, 286, 286, 286, 287,\n",
      "        287, 287, 287, 287, 287, 287, 287, 287, 287, 287, 287, 287, 287, 287,\n",
      "        287, 287, 287, 287])\n",
      "tensor([288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288,\n",
      "        288, 288, 288, 288, 288, 289, 289, 289, 289, 289, 289, 289, 289, 289,\n",
      "        289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 290, 290, 290, 290,\n",
      "        290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290,\n",
      "        290, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291,\n",
      "        291, 291, 291, 291, 291, 291, 292, 292, 292, 292, 292, 292, 292, 292,\n",
      "        292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 293, 293, 293,\n",
      "        293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293,\n",
      "        293, 293, 294, 294, 294, 294, 294, 294, 294, 294, 294, 294, 294, 294,\n",
      "        294, 294, 294, 294, 294, 294, 294, 295, 295, 295, 295, 295, 295, 295,\n",
      "        295, 295, 295, 295, 295, 295, 295, 295, 295, 295, 295, 295, 296, 296,\n",
      "        296, 296, 296, 296, 296, 296, 296, 296, 296, 296, 296, 296, 296, 296,\n",
      "        296, 296, 296, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297,\n",
      "        297, 297, 297, 297, 297, 297, 297, 297, 298, 298, 298, 298, 298, 298,\n",
      "        298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 299,\n",
      "        299, 299, 299, 299, 299, 299, 299, 299, 299, 299, 299, 299, 299, 299,\n",
      "        299, 299, 299, 299])\n",
      "tensor([300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "        300, 300, 300, 300, 300, 301, 301, 301, 301, 301, 301, 301, 301, 301,\n",
      "        301, 301, 301, 301, 301, 301, 301, 301, 301, 301, 302, 302, 302, 302,\n",
      "        302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
      "        302, 303, 303, 303, 303, 303, 303, 303, 303, 303, 303, 303, 303, 303,\n",
      "        303, 303, 303, 303, 303, 303, 304, 304, 304, 304, 304, 304, 304, 304,\n",
      "        304, 304, 304, 304, 304, 304, 304, 304, 304, 304, 304, 305, 305, 305,\n",
      "        305, 305, 305, 305, 305, 305, 305, 305, 305, 305, 305, 305, 305, 305,\n",
      "        305, 305, 306, 306, 306, 306, 306, 306, 306, 306, 306, 306, 306, 306,\n",
      "        306, 306, 306, 306, 306, 306, 306, 307, 307, 307, 307, 307, 307, 307,\n",
      "        307, 307, 307, 307, 307, 307, 307, 307, 307, 307, 307, 307, 308, 308,\n",
      "        308, 308, 308, 308, 308, 308, 308, 308, 308, 308, 308, 308, 308, 308,\n",
      "        308, 308, 308, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309,\n",
      "        309, 309, 309, 309, 309, 309, 309, 309, 310, 310, 310, 310, 310, 310,\n",
      "        310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 311,\n",
      "        311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311,\n",
      "        311, 311, 311, 311])\n",
      "tensor([312, 312, 312, 312, 312, 312, 312, 312, 312, 312, 312, 312, 312, 312,\n",
      "        312, 312, 312, 312, 312, 313, 313, 313, 313, 313, 313, 313, 313, 313,\n",
      "        313, 313, 313, 313, 313, 313, 313, 313, 313, 313, 314, 314, 314, 314,\n",
      "        314, 314, 314, 314, 314, 314, 314, 314, 314, 314, 314, 314, 314, 314,\n",
      "        314, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315,\n",
      "        315, 315, 315, 315, 315, 315, 316, 316, 316, 316, 316, 316, 316, 316,\n",
      "        316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 318, 318, 318, 318, 318, 318, 318, 318, 318, 318, 318, 318,\n",
      "        318, 318, 318, 318, 318, 318, 318, 319, 319, 319, 319, 319, 319, 319,\n",
      "        319, 319, 319, 319, 319, 319, 319, 319, 319, 319, 319, 319, 320, 320,\n",
      "        320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320,\n",
      "        320, 320, 320, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321,\n",
      "        321, 321, 321, 321, 321, 321, 321, 321, 322, 322, 322, 322, 322, 322,\n",
      "        322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 323,\n",
      "        323, 323, 323, 323, 323, 323, 323, 323, 323, 323, 323, 323, 323, 323,\n",
      "        323, 323, 323, 323])\n",
      "tensor([324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324,\n",
      "        324, 324, 324, 324, 324, 325, 325, 325, 325, 325, 325, 325, 325, 325,\n",
      "        325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 326, 326, 326, 326,\n",
      "        326, 326, 326, 326, 326, 326, 326, 326, 326, 326, 326, 326, 326, 326,\n",
      "        326, 327, 327, 327, 327, 327, 327, 327, 327, 327, 327, 327, 327, 327,\n",
      "        327, 327, 327, 327, 327, 327, 328, 328, 328, 328, 328, 328, 328, 328,\n",
      "        328, 328, 328, 328, 328, 328, 328, 328, 328, 328, 328, 329, 329, 329,\n",
      "        329, 329, 329, 329, 329, 329, 329, 329, 329, 329, 329, 329, 329, 329,\n",
      "        329, 329, 330, 330, 330, 330, 330, 330, 330, 330, 330, 330, 330, 330,\n",
      "        330, 330, 330, 330, 330, 330, 330, 331, 331, 331, 331, 331, 331, 331,\n",
      "        331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 332, 332,\n",
      "        332, 332, 332, 332, 332, 332, 332, 332, 332, 332, 332, 332, 332, 332,\n",
      "        332, 332, 332, 333, 333, 333, 333, 333, 333, 333, 333, 333, 333, 333,\n",
      "        333, 333, 333, 333, 333, 333, 333, 333, 334, 334, 334, 334, 334, 334,\n",
      "        334, 334, 334, 334, 334, 334, 334, 334, 334, 334, 334, 334, 334, 335,\n",
      "        335, 335, 335, 335, 335, 335, 335, 335, 335, 335, 335, 335, 335, 335,\n",
      "        335, 335, 335, 335])\n",
      "tensor([336, 336, 336, 336, 336, 336, 336, 336, 336, 336, 336, 336, 336, 336,\n",
      "        336, 336, 336, 336, 336, 337, 337, 337, 337, 337, 337, 337, 337, 337,\n",
      "        337, 337, 337, 337, 337, 337, 337, 337, 337, 337, 338, 338, 338, 338,\n",
      "        338, 338, 338, 338, 338, 338, 338, 338, 338, 338, 338, 338, 338, 338,\n",
      "        338, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339,\n",
      "        339, 339, 339, 339, 339, 339, 340, 340, 340, 340, 340, 340, 340, 340,\n",
      "        340, 340, 340, 340, 340, 340, 340, 340, 340, 340, 340, 341, 341, 341,\n",
      "        341, 341, 341, 341, 341, 341, 341, 341, 341, 341, 341, 341, 341, 341,\n",
      "        341, 341, 342, 342, 342, 342, 342, 342, 342, 342, 342, 342, 342, 342,\n",
      "        342, 342, 342, 342, 342, 342, 342, 343, 343, 343, 343, 343, 343, 343,\n",
      "        343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 344, 344,\n",
      "        344, 344, 344, 344, 344, 344, 344, 344, 344, 344, 344, 344, 344, 344,\n",
      "        344, 344, 344, 345, 345, 345, 345, 345, 345, 345, 345, 345, 345, 345,\n",
      "        345, 345, 345, 345, 345, 345, 345, 345, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 347,\n",
      "        347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347,\n",
      "        347, 347, 347, 347])\n",
      "tensor([348, 348, 348, 348, 348, 348, 348, 348, 348, 348, 348, 348, 348, 348,\n",
      "        348, 348, 348, 348, 348, 349, 349, 349, 349, 349, 349, 349, 349, 349,\n",
      "        349, 349, 349, 349, 349, 349, 349, 349, 349, 349, 350, 350, 350, 350,\n",
      "        350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350,\n",
      "        350, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351,\n",
      "        351, 351, 351, 351, 351, 351, 352, 352, 352, 352, 352, 352, 352, 352,\n",
      "        352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 353, 353, 353,\n",
      "        353, 353, 353, 353, 353, 353, 353, 353, 353, 353, 353, 353, 353, 353,\n",
      "        353, 353, 354, 354, 354, 354, 354, 354, 354, 354, 354, 354, 354, 354,\n",
      "        354, 354, 354, 354, 354, 354, 354, 355, 355, 355, 355, 355, 355, 355,\n",
      "        355, 355, 355, 355, 355, 355, 355, 355, 355, 355, 355, 355, 356, 356,\n",
      "        356, 356, 356, 356, 356, 356, 356, 356, 356, 356, 356, 356, 356, 356,\n",
      "        356, 356, 356, 357, 357, 357, 357, 357, 357, 357, 357, 357, 357, 357,\n",
      "        357, 357, 357, 357, 357, 357, 357, 357, 358, 358, 358, 358, 358, 358,\n",
      "        358, 358, 358, 358, 358, 358, 358, 358, 358, 358, 358, 358, 358, 359,\n",
      "        359, 359, 359, 359, 359, 359, 359, 359, 359, 359, 359, 359, 359, 359,\n",
      "        359, 359, 359, 359])\n",
      "tensor([360, 360, 360, 360, 360, 360, 360, 360, 360, 360, 360, 360, 360, 360,\n",
      "        360, 360, 360, 360, 360, 361, 361, 361, 361, 361, 361, 361, 361, 361,\n",
      "        361, 361, 361, 361, 361, 361, 361, 361, 361, 361, 362, 362, 362, 362,\n",
      "        362, 362, 362, 362, 362, 362, 362, 362, 362, 362, 362, 362, 362, 362,\n",
      "        362, 363, 363, 363, 363, 363, 363, 363, 363, 363, 363, 363, 363, 363,\n",
      "        363, 363, 363, 363, 363, 363, 364, 364, 364, 364, 364, 364, 364, 364,\n",
      "        364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 365, 365, 365,\n",
      "        365, 365, 365, 365, 365, 365, 365, 365, 365, 365, 365, 365, 365, 365,\n",
      "        365, 365, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366,\n",
      "        366, 366, 366, 366, 366, 366, 366, 367, 367, 367, 367, 367, 367, 367,\n",
      "        367, 367, 367, 367, 367, 367, 367, 367, 367, 367, 367, 367, 368, 368,\n",
      "        368, 368, 368, 368, 368, 368, 368, 368, 368, 368, 368, 368, 368, 368,\n",
      "        368, 368, 368, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369,\n",
      "        369, 369, 369, 369, 369, 369, 369, 369, 370, 370, 370, 370, 370, 370,\n",
      "        370, 370, 370, 370, 370, 370, 370, 370, 370, 370, 370, 370, 370, 371,\n",
      "        371, 371, 371, 371, 371, 371, 371, 371, 371, 371, 371, 371, 371, 371,\n",
      "        371, 371, 371, 371])\n",
      "tensor([372, 372, 372, 372, 372, 372, 372, 372, 372, 372, 372, 372, 372, 372,\n",
      "        372, 372, 372, 372, 372, 373, 373, 373, 373, 373, 373, 373, 373, 373,\n",
      "        373, 373, 373, 373, 373, 373, 373, 373, 373, 373, 374, 374, 374, 374,\n",
      "        374, 374, 374, 374, 374, 374, 374, 374, 374, 374, 374, 374, 374, 374,\n",
      "        374, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375,\n",
      "        375, 375, 375, 375, 375, 375, 376, 376, 376, 376, 376, 376, 376, 376,\n",
      "        376, 376, 376, 376, 376, 376, 376, 376, 376, 376, 376, 377, 377, 377,\n",
      "        377, 377, 377, 377, 377, 377, 377, 377, 377, 377, 377, 377, 377, 377,\n",
      "        377, 377, 378, 378, 378, 378, 378, 378, 378, 378, 378, 378, 378, 378,\n",
      "        378, 378, 378, 378, 378, 378, 378, 379, 379, 379, 379, 379, 379, 379,\n",
      "        379, 379, 379, 379, 379, 379, 379, 379, 379, 379, 379, 379, 380, 380,\n",
      "        380, 380, 380, 380, 380, 380, 380, 380, 380, 380, 380, 380, 380, 380,\n",
      "        380, 380, 380, 381, 381, 381, 381, 381, 381, 381, 381, 381, 381, 381,\n",
      "        381, 381, 381, 381, 381, 381, 381, 381, 382, 382, 382, 382, 382, 382,\n",
      "        382, 382, 382, 382, 382, 382, 382, 382, 382, 382, 382, 382, 382, 383,\n",
      "        383, 383, 383, 383, 383, 383, 383, 383, 383, 383, 383, 383, 383, 383,\n",
      "        383, 383, 383, 383])\n",
      "tensor([384, 384, 384, 384, 384, 384, 384, 384, 384, 384, 384, 384, 384, 384,\n",
      "        384, 384, 384, 384, 384, 385, 385, 385, 385, 385, 385, 385, 385, 385,\n",
      "        385, 385, 385, 385, 385, 385, 385, 385, 385, 385, 386, 386, 386, 386,\n",
      "        386, 386, 386, 386, 386, 386, 386, 386, 386, 386, 386, 386, 386, 386,\n",
      "        386, 387, 387, 387, 387, 387, 387, 387, 387, 387, 387, 387, 387, 387,\n",
      "        387, 387, 387, 387, 387, 387, 388, 388, 388, 388, 388, 388, 388, 388,\n",
      "        388, 388, 388, 388, 388, 388, 388, 388, 388, 388, 388, 389, 389, 389,\n",
      "        389, 389, 389, 389, 389, 389, 389, 389, 389, 389, 389, 389, 389, 389,\n",
      "        389, 389, 390, 390, 390, 390, 390, 390, 390, 390, 390, 390, 390, 390,\n",
      "        390, 390, 390, 390, 390, 390, 390, 391, 391, 391, 391, 391, 391, 391,\n",
      "        391, 391, 391, 391, 391, 391, 391, 391, 391, 391, 391, 391, 392, 392,\n",
      "        392, 392, 392, 392, 392, 392, 392, 392, 392, 392, 392, 392, 392, 392,\n",
      "        392, 392, 392, 393, 393, 393, 393, 393, 393, 393, 393, 393, 393, 393,\n",
      "        393, 393, 393, 393, 393, 393, 393, 393, 394, 394, 394, 394, 394, 394,\n",
      "        394, 394, 394, 394, 394, 394, 394, 394, 394, 394, 394, 394, 394, 395,\n",
      "        395, 395, 395, 395, 395, 395, 395, 395, 395, 395, 395, 395, 395, 395,\n",
      "        395, 395, 395, 395])\n",
      "tensor([396, 396, 396, 396, 396, 396, 396, 396, 396, 396, 396, 396, 396, 396,\n",
      "        396, 396, 396, 396, 396, 397, 397, 397, 397, 397, 397, 397, 397, 397,\n",
      "        397, 397, 397, 397, 397, 397, 397, 397, 397, 397, 398, 398, 398, 398,\n",
      "        398, 398, 398, 398, 398, 398, 398, 398, 398, 398, 398, 398, 398, 398,\n",
      "        398, 399, 399, 399, 399, 399, 399, 399, 399, 399, 399, 399, 399, 399,\n",
      "        399, 399, 399, 399, 399, 399, 400, 400, 400, 400, 400, 400, 400, 400,\n",
      "        400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 401, 401, 401,\n",
      "        401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401,\n",
      "        401, 401, 402, 402, 402, 402, 402, 402, 402, 402, 402, 402, 402, 402,\n",
      "        402, 402, 402, 402, 402, 402, 402, 403, 403, 403, 403, 403, 403, 403,\n",
      "        403, 403, 403, 403, 403, 403, 403, 403, 403, 403, 403, 403, 404, 404,\n",
      "        404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404,\n",
      "        404, 404, 404, 405, 405, 405, 405, 405, 405, 405, 405, 405, 405, 405,\n",
      "        405, 405, 405, 405, 405, 405, 405, 405, 406, 406, 406, 406, 406, 406,\n",
      "        406, 406, 406, 406, 406, 406, 406, 406, 406, 406, 406, 406, 406, 407,\n",
      "        407, 407, 407, 407, 407, 407, 407, 407, 407, 407, 407, 407, 407, 407,\n",
      "        407, 407, 407, 407])\n",
      "tensor([408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408,\n",
      "        408, 408, 408, 408, 408, 409, 409, 409, 409, 409, 409, 409, 409, 409,\n",
      "        409, 409, 409, 409, 409, 409, 409, 409, 409, 409, 410, 410, 410, 410,\n",
      "        410, 410, 410, 410, 410, 410, 410, 410, 410, 410, 410, 410, 410, 410,\n",
      "        410, 411, 411, 411, 411, 411, 411, 411, 411, 411, 411, 411, 411, 411,\n",
      "        411, 411, 411, 411, 411, 411, 412, 412, 412, 412, 412, 412, 412, 412,\n",
      "        412, 412, 412, 412, 412, 412, 412, 412, 412, 412, 412, 413, 413, 413,\n",
      "        413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413,\n",
      "        413, 413, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414,\n",
      "        414, 414, 414, 414, 414, 414, 414, 415, 415, 415, 415, 415, 415, 415,\n",
      "        415, 415, 415, 415, 415, 415, 415, 415, 415, 415, 415, 415, 416, 416,\n",
      "        416, 416, 416, 416, 416, 416, 416, 416, 416, 416, 416, 416, 416, 416,\n",
      "        416, 416, 416, 417, 417, 417, 417, 417, 417, 417, 417, 417, 417, 417,\n",
      "        417, 417, 417, 417, 417, 417, 417, 417, 418, 418, 418, 418, 418, 418,\n",
      "        418, 418, 418, 418, 418, 418, 418, 418, 418, 418, 418, 418, 418, 419,\n",
      "        419, 419, 419, 419, 419, 419, 419, 419, 419, 419, 419, 419, 419, 419,\n",
      "        419, 419, 419, 419])\n",
      "tensor([420, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420,\n",
      "        420, 420, 420, 420, 420, 421, 421, 421, 421, 421, 421, 421, 421, 421,\n",
      "        421, 421, 421, 421, 421, 421, 421, 421, 421, 421, 422, 422, 422, 422,\n",
      "        422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422,\n",
      "        422, 423, 423, 423, 423, 423, 423, 423, 423, 423, 423, 423, 423, 423,\n",
      "        423, 423, 423, 423, 423, 423, 424, 424, 424, 424, 424, 424, 424, 424,\n",
      "        424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 425, 425, 425,\n",
      "        425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425,\n",
      "        425, 425, 426, 426, 426, 426, 426, 426, 426, 426, 426, 426, 426, 426,\n",
      "        426, 426, 426, 426, 426, 426, 426, 427, 427, 427, 427, 427, 427, 427,\n",
      "        427, 427, 427, 427, 427, 427, 427, 427, 427, 427, 427, 427, 428, 428,\n",
      "        428, 428, 428, 428, 428, 428, 428, 428, 428, 428, 428, 428, 428, 428,\n",
      "        428, 428, 428, 429, 429, 429, 429, 429, 429, 429, 429, 429, 429, 429,\n",
      "        429, 429, 429, 429, 429, 429, 429, 429, 430, 430, 430, 430, 430, 430,\n",
      "        430, 430, 430, 430, 430, 430, 430, 430, 430, 430, 430, 430, 430, 431,\n",
      "        431, 431, 431, 431, 431, 431, 431, 431, 431, 431, 431, 431, 431, 431,\n",
      "        431, 431, 431, 431])\n",
      "tensor([432, 432, 432, 432, 432, 432, 432, 432, 432, 432, 432, 432, 432, 432,\n",
      "        432, 432, 432, 432, 432, 433, 433, 433, 433, 433, 433, 433, 433, 433,\n",
      "        433, 433, 433, 433, 433, 433, 433, 433, 433, 433, 434, 434, 434, 434,\n",
      "        434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434,\n",
      "        434, 435, 435, 435, 435, 435, 435, 435, 435, 435, 435, 435, 435, 435,\n",
      "        435, 435, 435, 435, 435, 435, 436, 436, 436, 436, 436, 436, 436, 436,\n",
      "        436, 436, 436, 436, 436, 436, 436, 436, 436, 436, 436, 437, 437, 437,\n",
      "        437, 437, 437, 437, 437, 437, 437, 437, 437, 437, 437, 437, 437, 437,\n",
      "        437, 437, 438, 438, 438, 438, 438, 438, 438, 438, 438, 438, 438, 438,\n",
      "        438, 438, 438, 438, 438, 438, 438, 439, 439, 439, 439, 439, 439, 439,\n",
      "        439, 439, 439, 439, 439, 439, 439, 439, 439, 439, 439, 439, 440, 440,\n",
      "        440, 440, 440, 440, 440, 440, 440, 440, 440, 440, 440, 440, 440, 440,\n",
      "        440, 440, 440, 441, 441, 441, 441, 441, 441, 441, 441, 441, 441, 441,\n",
      "        441, 441, 441, 441, 441, 441, 441, 441, 442, 442, 442, 442, 442, 442,\n",
      "        442, 442, 442, 442, 442, 442, 442, 442, 442, 442, 442, 442, 442, 443,\n",
      "        443, 443, 443, 443, 443, 443, 443, 443, 443, 443, 443, 443, 443, 443,\n",
      "        443, 443, 443, 443])\n",
      "tensor([444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444,\n",
      "        444, 444, 444, 444, 444, 445, 445, 445, 445, 445, 445, 445, 445, 445,\n",
      "        445, 446, 446, 446, 446, 446, 446, 446, 446, 446, 446, 446, 446, 446,\n",
      "        446, 446, 446, 446, 446, 446, 447, 447, 447, 447, 447, 447, 447, 447,\n",
      "        447, 447, 447, 447, 447, 447, 447, 447, 447, 447, 447, 448, 448, 448,\n",
      "        448, 448, 448, 448, 448, 448, 448, 448, 448, 448, 448, 448, 448, 448,\n",
      "        448, 448, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449,\n",
      "        449, 449, 449, 449, 449, 449, 449, 450, 450, 450, 450, 450, 450, 450,\n",
      "        450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 451, 451,\n",
      "        451, 451, 451, 451, 451, 451, 451, 451, 451, 451, 451, 451, 451, 451,\n",
      "        451, 451, 451, 452, 452, 452, 452, 452, 452, 452, 452, 452, 452, 452,\n",
      "        452, 452, 452, 452, 452, 452, 452, 452, 453, 453, 453, 453, 453, 453,\n",
      "        453, 453, 453, 453, 453, 453, 453, 453, 453, 453, 453, 453, 453, 454,\n",
      "        454, 454, 454, 454, 454, 454, 454, 454, 454, 454, 454, 454, 454, 454,\n",
      "        454, 454, 454, 454, 455, 455, 455, 455, 455, 455, 455, 455, 455, 455,\n",
      "        455, 455, 455, 455, 455, 455, 455, 455, 455])\n",
      "tensor([456, 456, 456, 456, 456, 456, 456, 456, 456, 456, 457, 457, 457, 457,\n",
      "        457, 457, 457, 457, 457, 457, 457, 457, 457, 457, 457, 457, 457, 457,\n",
      "        457, 458, 458, 458, 458, 458, 458, 458, 458, 458, 458, 458, 458, 458,\n",
      "        458, 458, 458, 458, 458, 458, 459, 459, 459, 459, 459, 459, 459, 459,\n",
      "        459, 459, 459, 459, 459, 459, 459, 459, 459, 459, 459, 460, 460, 460,\n",
      "        460, 460, 460, 460, 460, 460, 460, 460, 460, 460, 460, 460, 460, 460,\n",
      "        460, 460, 461, 461, 461, 461, 461, 461, 461, 461, 461, 461, 461, 461,\n",
      "        461, 461, 461, 461, 461, 461, 461, 462, 462, 462, 462, 462, 462, 462,\n",
      "        462, 462, 462, 462, 462, 462, 462, 462, 462, 462, 462, 462, 463, 463,\n",
      "        463, 463, 463, 463, 463, 463, 463, 463, 463, 463, 463, 463, 463, 463,\n",
      "        463, 463, 463, 464, 464, 464, 464, 464, 464, 464, 464, 464, 464, 464,\n",
      "        464, 464, 464, 464, 464, 464, 464, 464, 465, 465, 465, 465, 465, 465,\n",
      "        465, 465, 465, 465, 465, 465, 465, 465, 465, 465, 465, 465, 465, 466,\n",
      "        466, 466, 466, 466, 466, 466, 466, 466, 466, 467, 467, 467, 467, 467,\n",
      "        467, 467, 467, 467, 467])\n",
      "tensor([468, 468, 468, 468, 468, 468, 468, 468, 468, 468, 469, 469, 469, 469,\n",
      "        469, 469, 469, 469, 469, 469, 470, 470, 470, 470, 470, 470, 470, 470,\n",
      "        470, 470, 471, 471, 471, 471, 471, 471, 471, 471, 471, 471, 472, 472,\n",
      "        472, 472, 472, 472, 472, 472, 472, 472, 472, 472, 472, 472, 472, 472,\n",
      "        472, 472, 472, 473, 473, 473, 473, 473, 473, 473, 473, 473, 473, 473,\n",
      "        473, 473, 473, 473, 473, 473, 473, 473, 474, 474, 474, 474, 474, 474,\n",
      "        474, 474, 474, 474, 474, 474, 474, 474, 474, 474, 474, 474, 474, 475,\n",
      "        475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475,\n",
      "        475, 475, 475, 475, 476, 476, 476, 476, 476, 476, 476, 476, 476, 476,\n",
      "        476, 476, 476, 476, 476, 476, 476, 476, 476, 477, 477, 477, 477, 477,\n",
      "        477, 477, 477, 477, 477, 477, 477, 477, 477, 477, 477, 477, 477, 477,\n",
      "        478, 478, 478, 478, 478, 478, 478, 478, 478, 478, 478, 478, 478, 478,\n",
      "        478, 478, 478, 478, 478, 479, 479, 479, 479, 479, 479, 479, 479, 479,\n",
      "        479, 479, 479, 479, 479, 479, 479, 479, 479, 479])\n",
      "tensor([480, 480, 480, 480, 480, 480, 480, 480, 480, 480, 480, 480, 480, 480,\n",
      "        480, 480, 480, 480, 480, 481, 481, 481, 481, 481, 481, 481, 481, 481,\n",
      "        481, 481, 481, 481, 481, 481, 481, 481, 481, 481, 482, 482, 482, 482,\n",
      "        482, 482, 482, 482, 482, 482, 482, 482, 482, 482, 482, 482, 482, 482,\n",
      "        482, 483, 483, 483, 483, 483, 483, 483, 483, 483, 483, 483, 483, 483,\n",
      "        483, 483, 483, 483, 483, 483, 484, 484, 484, 484, 484, 484, 484, 484,\n",
      "        484, 484, 484, 484, 484, 484, 484, 484, 484, 484, 484, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486,\n",
      "        486, 486, 486, 486, 486, 486, 486, 487, 487, 487, 487, 487, 487, 487,\n",
      "        487, 487, 487, 487, 487, 487, 487, 487, 487, 487, 487, 487, 488, 488,\n",
      "        488, 488, 488, 488, 488, 488, 488, 488, 488, 488, 488, 488, 488, 488,\n",
      "        488, 488, 488, 489, 489, 489, 489, 489, 489, 489, 489, 489, 489, 489,\n",
      "        489, 489, 489, 489, 489, 489, 489, 489, 490, 490, 490, 490, 490, 490,\n",
      "        490, 490, 490, 490, 490, 490, 490, 490, 490, 490, 490, 490, 490, 491,\n",
      "        491, 491, 491, 491, 491, 491, 491, 491, 491, 491, 491, 491, 491, 491,\n",
      "        491, 491, 491, 491])\n",
      "tensor([492, 492, 492, 492, 492, 492, 492, 492, 492, 492, 492, 492, 492, 492,\n",
      "        492, 492, 492, 492, 492, 493, 493, 493, 493, 493, 493, 493, 493, 493,\n",
      "        493, 493, 493, 493, 493, 493, 493, 493, 493, 493, 494, 494, 494, 494,\n",
      "        494, 494, 494, 494, 494, 494, 494, 494, 494, 494, 494, 494, 494, 494,\n",
      "        494, 495, 495, 495, 495, 495, 495, 495, 495, 495, 495, 496, 496, 496,\n",
      "        496, 496, 496, 496, 496, 496, 496, 496, 496, 496, 496, 496, 496, 496,\n",
      "        496, 496, 497, 497, 497, 497, 497, 497, 497, 497, 497, 497, 498, 498,\n",
      "        498, 498, 498, 498, 498, 498, 498, 498, 499, 499, 499, 499, 499, 499,\n",
      "        499, 499, 499, 499, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
      "        501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 502, 502, 502, 502,\n",
      "        502, 502, 502, 502, 502, 502, 503, 503, 503, 503, 503, 503, 503, 503,\n",
      "        503, 503, 503, 503, 503, 503, 503, 503, 503, 503, 503])\n",
      "tensor([504, 504, 504, 504, 504, 504, 504, 504, 504, 504, 504, 504, 504, 504,\n",
      "        504, 504, 504, 504, 504, 505, 505, 505, 505, 505, 505, 505, 505, 505,\n",
      "        505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 506, 506, 506, 506,\n",
      "        506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506,\n",
      "        506, 507, 507, 507, 507, 507, 507, 507, 507, 507, 507, 507, 507, 507,\n",
      "        507, 507, 507, 507, 507, 507, 508, 508, 508, 508, 508, 508, 508, 508,\n",
      "        508, 508, 508, 508, 508, 508, 508, 508, 508, 508, 508, 509, 509, 509,\n",
      "        509, 509, 509, 509, 509, 509, 509, 509, 509, 509, 509, 509, 509, 509,\n",
      "        509, 509, 510, 510, 510, 510, 510, 510, 510, 510, 510, 510, 510, 510,\n",
      "        510, 510, 510, 510, 510, 510, 510, 511, 511, 511, 511, 511, 511, 511,\n",
      "        511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 512, 512,\n",
      "        512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512,\n",
      "        512, 512, 512, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513,\n",
      "        513, 513, 513, 513, 513, 513, 513, 513, 514, 514, 514, 514, 514, 514,\n",
      "        514, 514, 514, 514, 514, 514, 514, 514, 514, 514, 514, 514, 514, 515,\n",
      "        515, 515, 515, 515, 515, 515, 515, 515, 515, 515, 515, 515, 515, 515,\n",
      "        515, 515, 515, 515])\n",
      "tensor([516, 516, 516, 516, 516, 516, 516, 516, 516, 516, 516, 516, 516, 516,\n",
      "        516, 516, 516, 516, 516, 517, 517, 517, 517, 517, 517, 517, 517, 517,\n",
      "        517, 517, 517, 517])\n"
     ]
    }
   ],
   "source": [
    "for batch in loader:\n",
    "    print(batch['idxs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, _ = instantiate_dataset(Y_df, S_df, X_df, window_sampling_limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S': tensor([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]),\n",
       " 'Y': tensor([[    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "              0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "              0.0000,     0.0000,     0.0000, 25092.2285],\n",
       "         [    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "              0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "              0.0000,     0.0000, 25092.2285, 24271.5137],\n",
       "         [    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "              0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "              0.0000, 25092.2285, 24271.5137, 25828.9883],\n",
       "         [    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "              0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "          25092.2285, 24271.5137, 25828.9883, 27697.5039],\n",
       "         [    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "              0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 25092.2285,\n",
       "          24271.5137, 25828.9883, 27697.5039, 27956.2285],\n",
       "         [    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "              0.0000,     0.0000,     0.0000,     0.0000, 25092.2285, 24271.5137,\n",
       "          25828.9883, 27697.5039, 27956.2285, 29924.4316],\n",
       "         [    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "              0.0000,     0.0000,     0.0000, 25092.2285, 24271.5137, 25828.9883,\n",
       "          27697.5039, 27956.2285, 29924.4316, 30216.8320],\n",
       "         [    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "              0.0000,     0.0000, 25092.2285, 24271.5137, 25828.9883, 27697.5039,\n",
       "          27956.2285, 29924.4316, 30216.8320, 32613.4961],\n",
       "         [    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "              0.0000, 25092.2285, 24271.5137, 25828.9883, 27697.5039, 27956.2285,\n",
       "          29924.4316, 30216.8320, 32613.4961, 36053.1680],\n",
       "         [    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "          25092.2285, 24271.5137, 25828.9883, 27697.5039, 27956.2285, 29924.4316,\n",
       "          30216.8320, 32613.4961, 36053.1680, 38472.7539],\n",
       "         [    0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 25092.2285,\n",
       "          24271.5137, 25828.9883, 27697.5039, 27956.2285, 29924.4316, 30216.8320,\n",
       "          32613.4961, 36053.1680, 38472.7539, 38420.8945],\n",
       "         [    0.0000,     0.0000,     0.0000,     0.0000, 25092.2285, 24271.5137,\n",
       "          25828.9883, 27697.5039, 27956.2285, 29924.4316, 30216.8320, 32613.4961,\n",
       "          36053.1680, 38472.7539, 38420.8945, 36555.6172],\n",
       "         [    0.0000,     0.0000,     0.0000, 25092.2285, 24271.5137, 25828.9883,\n",
       "          27697.5039, 27956.2285, 29924.4316, 30216.8320, 32613.4961, 36053.1680,\n",
       "          38472.7539, 38420.8945, 36555.6172, 37385.6367],\n",
       "         [    0.0000,     0.0000, 25092.2285, 24271.5137, 25828.9883, 27697.5039,\n",
       "          27956.2285, 29924.4316, 30216.8320, 32613.4961, 36053.1680, 38472.7539,\n",
       "          38420.8945, 36555.6172, 37385.6367, 38431.9688],\n",
       "         [    0.0000, 25092.2285, 24271.5137, 25828.9883, 27697.5039, 27956.2285,\n",
       "          29924.4316, 30216.8320, 32613.4961, 36053.1680, 38472.7539, 38420.8945,\n",
       "          36555.6172, 37385.6367, 38431.9688, 40345.3281]]),\n",
       " 'X': tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 3.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 3., 4.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 3., 4., 5.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 3., 4., 5., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 3., 4., 5., 0., 1.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 3., 4., 5., 0., 1., 2.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 2., 3., 4., 5., 0., 1., 2., 3.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 2., 3., 4., 5., 0., 1., 2., 3., 5.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 2., 3., 4., 5., 0., 1., 2., 3., 5., 6.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 2., 3., 4., 5., 0., 1., 2., 3., 5., 6., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 2., 3., 4., 5., 0., 1., 2., 3., 5., 6., 0., 1.]],\n",
       " \n",
       "         [[0., 0., 0., 2., 3., 4., 5., 0., 1., 2., 3., 5., 6., 0., 1., 3.]],\n",
       " \n",
       "         [[0., 0., 2., 3., 4., 5., 0., 1., 2., 3., 5., 6., 0., 1., 3., 4.]]]),\n",
       " 'available_mask': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]),\n",
       " 'sample_mask': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]),\n",
       " 'idxs': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset._windows_batch(np.array([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_attrs(Y_df, S_df, X_df, f_cols=[], ds_in_test=meta.horizon, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ts_tensor(Y_df, S_df, X_df, f_cols=[], ds_in_test=meta.horizon, is_test=False,\n",
    "               window_sampling_limit=10, ts_idxs=[1, 7, 10, 15], output_size=meta.horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_get_f_idxs(Y_df, S_df, X_df, f_cols=[], ds_in_test=ds_in_test, is_test=is_test, \n",
    "                expected_f_idxs=[])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nixtla",
   "language": "python",
   "name": "nixtla"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
