{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.datasets.epf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPF dataset\n",
    "\n",
    "> Donwload the EDF dataset.\n",
    "\n",
    "The EPF dataset was made available as part of the [EPFToolbox](https://github.com/jeslago/epftoolbox/).\n",
    "\n",
    "The benchmark task is to provide one day ahead hourly forecasts for electricity prices of five markets. The dataset contains:\n",
    "- Y: Hourly price history for the five markets extending each for six years.\n",
    "- X: Two covariate factor per market usually electricity load forecasts and renewable sources production.\n",
    "\n",
    "[Lago, J., Marcjasz, G., De Schutter, B., & Weron, R. (2021). Forecasting day-ahead electricity prices: A review of state-of-the-art algorithms, best practices and an open-access bench-mark. Applied Energy, 293, 116983.](https://www.sciencedirect.com/science/article/pii/S0306261921004529?via%3Dihub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from neuralforecast.data.datasets.utils import download_file, Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">EPF meta information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class NP:\n",
    "    test_date: str = '2016-12-27'\n",
    "    name: str = 'NP'\n",
    "\n",
    "@dataclass\n",
    "class PJM:\n",
    "    test_date: str = '2016-12-27'\n",
    "    name: str = 'PJM'\n",
    "\n",
    "@dataclass\n",
    "class BE:\n",
    "    test_date: str = '2015-01-04'\n",
    "    name: str = 'BE'\n",
    "\n",
    "@dataclass\n",
    "class FR:\n",
    "    test_date: str = '2015-01-04'\n",
    "    name: str = 'FR'\n",
    "\n",
    "@dataclass\n",
    "class DE:\n",
    "    test_date: str = '2016-01-04'\n",
    "    name: str = 'DE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "EPFInfo = Info(groups=('NP', 'PJM', 'BE', 'FR', 'DE'),\n",
    "               class_groups=(NP, PJM, BE, FR, DE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EPF:\n",
    "    \n",
    "    source_url = 'https://sandbox.zenodo.org/api/files/da5b2c6f-8418-4550-a7d0-7f2497b40f1b/'\n",
    "\n",
    "    @staticmethod\n",
    "    def load(directory: str,\n",
    "             group: str) -> Tuple[pd.DataFrame, \n",
    "                                  Optional[pd.DataFrame], \n",
    "                                  Optional[pd.DataFrame]]:\n",
    "        \"\"\"\n",
    "        Downloads and loads EPF data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'NP', 'PJM', 'BE', 'FR', 'DE'.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Y: pd.DataFrame\n",
    "            Target time series with columns ['unique_id', 'ds', 'y'].\n",
    "        X: pd.DataFrame\n",
    "            Exogenous time series with columns ['unique_id', 'ds', 'y'].\n",
    "        \"\"\"\n",
    "        EPF.download(directory)\n",
    "        class_group = EPFInfo.get_group(group)        \n",
    "        \n",
    "        path = f'{directory}/epf/datasets'\n",
    "        file = f'{path}/{group}.csv'\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        df.columns = ['ds', 'y'] + \\\n",
    "                     [f'Exogenous{i}' for i in range(1, len(df.columns) - 1)]\n",
    "\n",
    "        df['unique_id'] = group\n",
    "        df['ds'] = pd.to_datetime(df['ds'])\n",
    "        df['week_day'] = df['ds'].dt.dayofweek\n",
    "\n",
    "        dummies = pd.get_dummies(df['week_day'], prefix='day')\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "        dummies_cols = [col for col in df if col.startswith('day')]\n",
    "\n",
    "        Y = df.filter(items=['unique_id', 'ds', 'y'])\n",
    "        X = df.filter(items=['unique_id', 'ds', 'Exogenous1', 'Exogenous2', 'week_day'] + \\\n",
    "                      dummies_cols)\n",
    "        \n",
    "        return Y, X, None\n",
    "\n",
    "    @staticmethod\n",
    "    def load_groups(directory: str,\n",
    "                    groups: List[str]) -> Tuple[pd.DataFrame, \n",
    "                                                Optional[pd.DataFrame], \n",
    "                                                Optional[pd.DataFrame]]:\n",
    "        \"\"\"\n",
    "        Downloads and loads panel of EPF data\n",
    "        according of groups.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        groups: List[str]\n",
    "            Group names.\n",
    "            Allowed groups: 'NP', 'PJM', 'BE', 'FR', 'DE'.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Y: pd.DataFrame\n",
    "            Target time series with columns ['unique_id', 'ds', 'y'].\n",
    "        X: pd.DataFrame\n",
    "            Exogenous time series with columns ['unique_id', 'ds', 'y'].\n",
    "        S: pd.DataFrame\n",
    "            Static exogenous variables with columns ['unique_id', 'ds']. \n",
    "            and static variables. \n",
    "        \"\"\"\n",
    "        Y = []\n",
    "        X = []\n",
    "        for group in groups:\n",
    "            Y_df, X_df, S_df = EPF.load(directory=directory, group=group)\n",
    "            Y.append(Y_df)\n",
    "            X.append(X_df)\n",
    "            \n",
    "        Y = pd.concat(Y).sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "        X = pd.concat(X).sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "\n",
    "        S = Y[['unique_id']].drop_duplicates().reset_index(drop=True)\n",
    "        dummies = pd.get_dummies(S['unique_id'], prefix='static')\n",
    "        S = pd.concat([S, dummies], axis=1)\n",
    "        \n",
    "        return Y, X, S\n",
    "    \n",
    "    @staticmethod\n",
    "    def download(directory: str) -> None:\n",
    "        \"\"\"\n",
    "        Downloads EPF Dataset.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory path to download dataset.\n",
    "        \"\"\"\n",
    "        path = f'{directory}/epf/datasets'\n",
    "        if not os.path.exists(path):\n",
    "            for group in EPFInfo.groups:\n",
    "                download_file(path, EPF.source_url + f'{group}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# TODO: extend this to group_by unique_id application\n",
    "def epf_naive_forecast(Y_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Function to build the naive forecast for electricity price forecasting\n",
    "    \n",
    "    The function is used to compute the accuracy metrics MASE and RMAE, the function\n",
    "    assumes that the number of prices per day is 24. And computes naive forecast for\n",
    "    days of the week and seasonal Naive forecast for weekends.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    Y_df : pandas.DataFrame\n",
    "        Dataframe containing the real prices in long format\n",
    "        that contains variables ['ds', 'unique_id', 'y']\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Y_hat_df : pandas.DataFrame\n",
    "        Dataframe containing the predictions of the epf naive forecast.\n",
    "    \"\"\"\n",
    "    assert type(Y_df) == pd.core.frame.DataFrame\n",
    "    assert all([(col in Y_df) for col in ['unique_id', 'ds', 'y']])    \n",
    "\n",
    "    # Init the naive forecast\n",
    "    Y_hat_df = Y_df[24 * 7:].copy()\n",
    "    Y_hat_df['dayofweek'] = Y_df['ds'].dt.dayofweek\n",
    "    \n",
    "    # Monday, Saturday and Sunday \n",
    "    # we have a naive forecast using weekly seasonality\n",
    "    weekend_indicator = Y_hat_df['dayofweek'].isin([0,5,6])\n",
    "    \n",
    "    # Tuesday, Wednesday, Thursday, Friday \n",
    "    # we have a naive forecast using daily seasonality\n",
    "    week_indicator = Y_hat_df['dayofweek'].isin([1,2,3,4])\n",
    "\n",
    "    naive = Y_df['y'].shift(24).values[24 * 7:]\n",
    "    seasonal_naive = Y_df['y'].shift(24*7).values[24 * 7:]\n",
    "    \n",
    "    Y_hat_df['y_hat'] = naive * week_indicator + seasonal_naive * weekend_indicator\n",
    "    return Y_hat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load specific group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = pd.Series({'dataset': 'NP'})\n",
    "\n",
    "Y_df, Xt_df, _ = EPF.load(directory='data', group=args.dataset)\n",
    "\n",
    "# train_mask: 1 to keep, 0 to mask\n",
    "offset = 365 * 24 * 2\n",
    "train_outsample_mask = np.ones(len(Y_df))\n",
    "train_outsample_mask[-offset:] = 0\n",
    "\n",
    "print(f'Dataset: {args.dataset}')\n",
    "#print(\"Xt_df.columns\", Xt_df.columns)\n",
    "print(f'Train mask percentage: {np.round(np.sum(train_outsample_mask)/len(train_outsample_mask),2)}')\n",
    "print('X: time series features, of shape (#hours, #times,#features): \\t' + str(Xt_df.shape))\n",
    "print('Y: target series (in X), of shape (#hours, #times): \\t \\t' + str(Y_df.shape))\n",
    "print(f'Last ds {Y_df.ds.max()}')\n",
    "print(f'Train {sum(1-train_outsample_mask)} hours = {np.round(sum(1-train_outsample_mask)/(24*365),2)} years')\n",
    "print(f'Validation {sum(train_outsample_mask)} hours = {np.round(sum(train_outsample_mask)/(24*365),2)} years')\n",
    "# print('S: static features, of shape (#series,#features): \\t \\t' + str(S.shape))\n",
    "#Y_df.head()\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pylab as plt\n",
    "from pylab import rcParams\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "from matplotlib import rcParams\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "FONTSIZE = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast.data.datasets.epf import EPF, EPFInfo\n",
    "if not os.path.exists('./results/'):\n",
    "    os.makedirs('./results/')\n",
    "\n",
    "dataset = ['NP', 'PJM', 'BE', 'FR', 'DE']\n",
    "Y_df, X_df, S_df = EPF.load_groups(directory='data', groups=dataset)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "fig.tight_layout()\n",
    "plt.ylim(-200, 800)\n",
    "rcParams['figure.figsize'] = 15, 15\n",
    "ax0 = plt.subplot2grid((3,2),(0, 0))\n",
    "ax1 = plt.subplot2grid((3,2),(0, 1))\n",
    "ax2 = plt.subplot2grid((3,2),(1, 0))\n",
    "ax3 = plt.subplot2grid((3,2),(1, 1))\n",
    "ax4 = plt.subplot2grid((3,2),(2, 0))\n",
    "axs = [ax0, ax1, ax2, ax3, ax4]\n",
    "\n",
    "for idx, market in enumerate(dataset):\n",
    "    currency   = 'USD' if market == 'PJM' else 'EUR'\n",
    "    title_str  = 'EPEX-' if not (market in ['PJM', 'NP']) else ''\n",
    "    title_str += f'{market} market'\n",
    "    y_axis_str = f'Price [{currency}/MWh]'\n",
    "\n",
    "    x_plot = Y_df[Y_df.unique_id==market].ds.values\n",
    "    y_plot = Y_df[Y_df.unique_id==market].y.values\n",
    "    \n",
    "    x_axis_str = f'Hours [{str(x_plot.min())[:10]}  to {str(x_plot.max())[:10]}]'\n",
    "\n",
    "\n",
    "    axs[idx].plot(x_plot, y_plot, color='#628793', linewidth=0.4)\n",
    "    axs[idx].tick_params(labelsize=FONTSIZE-2)\n",
    "    axs[idx].set_xlabel(x_axis_str, fontsize=FONTSIZE)\n",
    "    axs[idx].vlines(x_plot[-728*24],-200,800, linestyle=(0, (5, 10)), \n",
    "                    color='black', linewidth=1.)\n",
    "    axs[idx].set_ylabel(y_axis_str, fontsize=FONTSIZE)\n",
    "    axs[idx].set_title(title_str)\n",
    "    axs[idx].set_ylim(-200,800)\n",
    "\n",
    "plt.subplots_adjust(left=0.125, bottom=0.1, right=0.9, top=1.2, wspace=0.2, hspace=0.2)\n",
    "plt.savefig('./results/market_plots.pdf', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast.data.datasets.epf import EPF, EPFInfo\n",
    "\n",
    "EXOGENOUS_NAMES = {'NP': ['Load [GW]', 'Wind Generation [GW]'],\n",
    "                   'PJM': ['Load [GW]', 'COMED Load [GW]'],\n",
    "                   'BE': ['Load [GW]', 'Total France Generation [GW]'],\n",
    "                   'FR': ['Load [GW]', 'Total France Generation [GW]'],\n",
    "                   'DE': ['TSO Zonal Load [GW]', 'DE Wind Generation [GW]']}\n",
    "\n",
    "# dataset = ['NP', 'PJM', 'BE', 'FR', 'DE']\n",
    "dataset = ['NP']\n",
    "# dataset = ['DE']\n",
    "Y_df, X_df, S_df = EPF.load_groups(directory='data', groups=dataset)\n",
    "\n",
    "fig = plt.figure(figsize=(34, 12))\n",
    "fig.tight_layout()\n",
    "plt.ylim(-200, 800)\n",
    "# rcParams['figure.figsize'] = 15, 15\n",
    "ax0 = plt.subplot2grid((3,2),(0, 0))\n",
    "ax1 = plt.subplot2grid((3,2),(1, 0))\n",
    "ax2 = plt.subplot2grid((3,2),(2, 0))\n",
    "axs = [ax0, ax1, ax2]\n",
    "\n",
    "# for idx, market in enumerate(dataset):\n",
    "market = dataset[0]\n",
    "currency   = 'USD' if market == 'PJM' else 'EUR'\n",
    "title_str  = 'EPEX-' if not (market in ['PJM', 'NP']) else ''\n",
    "title_str += f'{market} market'\n",
    "y_axis_str = f'Price [{currency}/MWh]'\n",
    "\n",
    "x_plot = Y_df.ds.values\n",
    "x_plot_min = pd.to_datetime(x_plot.min()).strftime('%B %d, %Y')\n",
    "x_plot_max = pd.to_datetime(x_plot.max()).strftime('%B %d, %Y')\n",
    "x_axis_str = f'Hours [{x_plot_min}  to  {x_plot_max}]'\n",
    "\n",
    "y_plot = Y_df.y.values\n",
    "x1_plot = X_df.Exogenous1.values\n",
    "x2_plot = X_df.Exogenous2.values\n",
    "\n",
    "axs[0].plot(x_plot, y_plot, color='#628793', linewidth=0.4, alpha=1.)\n",
    "axs[0].vlines(x_plot[-728*24],0,200, linestyle=(0, (5, 10)), \n",
    "              color='black', linewidth=1.9)\n",
    "axs[0].tick_params(labelsize=FONTSIZE-2)\n",
    "axs[0].set_xlabel(x_axis_str, fontsize=FONTSIZE)\n",
    "axs[0].set_ylabel(y_axis_str, fontsize=FONTSIZE)\n",
    "#axs[0].vlines(x_plot[-728*24],-250,280, linestyle=(0, (5, 10)), \n",
    "#              color='black', linewidth=1.)\n",
    "#axs[0].vlines(x_plot[-728*24],0,210, linestyle=(0, (5, 10)), \n",
    "#                color='black', linewidth=1.)\n",
    "\n",
    "axs[1].plot(x_plot, x1_plot/1000, color='#628793', linewidth=0.37, alpha=0.8)\n",
    "axs[1].vlines(x_plot[-728*24],25,72, linestyle=(0, (5, 10)), \n",
    "              color='black', linewidth=1.9)\n",
    "axs[1].tick_params(labelsize=FONTSIZE-2)\n",
    "axs[1].set_xlabel(x_axis_str, fontsize=FONTSIZE)\n",
    "axs[1].set_ylabel(EXOGENOUS_NAMES[market][0], fontsize=FONTSIZE)\n",
    "\n",
    "x2_plot[-728*24-60:-728*24+60] = [np.nan] * 60 * 2 # mini hack\n",
    "axs[2].plot(x_plot, x2_plot/1000, color='#628793', linewidth=0.37, alpha=0.8)\n",
    "axs[2].vlines(x_plot[-728*24],-.2,5.2, linestyle=(0, (5, 10)), \n",
    "              color='black', linewidth=1.9)\n",
    "axs[2].tick_params(labelsize=FONTSIZE-2)\n",
    "axs[2].set_xlabel(x_axis_str, fontsize=FONTSIZE)\n",
    "axs[2].set_ylabel(EXOGENOUS_NAMES[market][1], fontsize=FONTSIZE)\n",
    "\n",
    "# # axs[idx].set_title(title_str)\n",
    "# axs[idx].set_ylim(-200,800)\n",
    "# # print(\\x_plot[-728*24]\\, x_plot[-728*24])\n",
    "\n",
    "plt.subplots_adjust(left=0.125, bottom=0.1, right=0.9, top=1.5, wspace=0.2, hspace=0.2)\n",
    "plt.savefig('./results/NP.pdf', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# dataset = ['NP', 'PJM', 'BE', 'FR', 'DE']\n",
    "dataset = ['NP']\n",
    "# dataset = ['DE']\n",
    "Y_df, X_df, S_df = EPF.load_groups(directory='data', groups=dataset)\n",
    "\n",
    "fig = plt.figure(figsize=(15.5, 5))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.ylim(-200, 800)\n",
    "ax0 = plt.subplot2grid((1,1),(0, 0))\n",
    "axs = [ax0]\n",
    "\n",
    "# for idx, market in enumerate(dataset):\n",
    "market = dataset[0]\n",
    "currency = 'USD' if market == 'PJM' else 'EUR'\n",
    "title_str  = 'EPEX-' if not (market in ['PJM', 'NP']) else ''\n",
    "title_str += f'{market} market'\n",
    "y_axis_str = f'Price [{currency}/MWh]'\n",
    "\n",
    "x_plot = Y_df.ds.values\n",
    "x_plot_min = pd.to_datetime(x_plot.min()).strftime('%B %d, %Y') #'%B %d, %Y, %r'\n",
    "x_plot_max = pd.to_datetime(x_plot.max()).strftime('%B %d, %Y') #'%B %d, %Y, %r'\n",
    "\n",
    "x_axis_str = f'Hours [{x_plot_min}  to {x_plot_max}]'\n",
    "\n",
    "y_plot = Y_df.y.values\n",
    "x1_plot = X_df.Exogenous1.values\n",
    "x2_plot = X_df.Exogenous2.values\n",
    "\n",
    "axs[0].plot(x_plot, y_plot, color='#628793', linewidth=0.4)\n",
    "axs[0].tick_params(labelsize=FONTSIZE-2)\n",
    "axs[0].set_xlabel(x_axis_str, fontsize=FONTSIZE)\n",
    "axs[0].set_ylabel(y_axis_str, fontsize=FONTSIZE)\n",
    "\n",
    "axs[0].vlines(x_plot[-(42*7*24)-(728*24)],0,200, linestyle=(0, (5, 10)), \n",
    "              color='black', linewidth=1.)\n",
    "axs[0].vlines(x_plot[-728*24],0,200, linestyle=(0, (5, 10)), \n",
    "              color='black', linewidth=1.)\n",
    "plt.savefig('./results/train_methodology.pdf', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALIDATION OF EPF SEASONAL NAIVE FORECASTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_df = epf_naive_forecast(Y_df)\n",
    "\n",
    "fig = plt.figure(figsize=(15.5, 5))\n",
    "plt.plot(Y_hat_df['y'][:24*7*3], label='true')\n",
    "plt.plot(Y_hat_df['y_hat'][:24*7*3], label='naive')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
