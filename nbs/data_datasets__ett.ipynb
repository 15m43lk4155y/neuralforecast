{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.datasets.ett"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electricity Transformer (ETT) dataset\n",
    "\n",
    "> Download the ETT dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nixtlats.data.datasets.utils import download_file, Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETT meta information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class ETTh1:\n",
    "    freq: str = 'H'\n",
    "    name: str = 'ETTh1'\n",
    "    n_ts: int = 1\n",
    "\n",
    "@dataclass\n",
    "class ETTh2:\n",
    "    freq: str = 'H'\n",
    "    name: str = 'ETTh2'\n",
    "    n_ts: int = 1\n",
    "\n",
    "@dataclass\n",
    "class ETTm1:\n",
    "    freq: str = '15T'\n",
    "    name: str = 'ETTm1'\n",
    "    n_ts: int = 7\n",
    "\n",
    "@dataclass\n",
    "class ETTm2:\n",
    "    freq: str = '15T'\n",
    "    name: str = 'ETTm2'\n",
    "    n_ts: int = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "ETTInfo = Info(groups=('ETTh1', 'ETTh2', 'ETTm1', 'ETTm2'),\n",
    "               class_groups=(ETTh1, ETTh2, ETTm1, ETTm2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class ETT:\n",
    "    \n",
    "    source_url: str = 'https://nhits-experiments.s3.amazonaws.com/datasets.zip'\n",
    "\n",
    "    @staticmethod\n",
    "    def load(directory: str,\n",
    "             group: str,\n",
    "             cache: bool = True) -> Tuple[pd.DataFrame, \n",
    "                                          Optional[pd.DataFrame], \n",
    "                                          Optional[pd.DataFrame]]:\n",
    "        \"\"\"Downloads and loads ETT data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'ETTh1', 'ETTh2', \n",
    "                            'ETTm1', 'ETTm2'.\n",
    "        cache: bool\n",
    "            If `True` saves and loads \n",
    "            \n",
    "        Notes\n",
    "        -----\n",
    "        [1] Returns train+val+test sets.\n",
    "        \"\"\"\n",
    "        path = f'{directory}/ett/datasets'\n",
    "        file_cache = f'{path}/{group}.p'\n",
    "        \n",
    "        if os.path.exists(file_cache) and cache:\n",
    "            df, X_df, S_df = pd.read_pickle(file_cache)\n",
    "            \n",
    "            return df, X_df, S_df\n",
    "        \n",
    "        ETT.download(directory)\n",
    "        path = f'{directory}/longhorizon/datasets'\n",
    "        \n",
    "        kind = 'M' if group not in ['ETTh1', 'ETTh2'] else 'S'\n",
    "        y_df = pd.read_csv(f'{path}/{group}/{kind}/df_y.csv')\n",
    "        y_df = y_df.sort_values(['unique_id', 'ds'], ignore_index=True)\n",
    "        y_df = y_df[['unique_id', 'ds', 'y']]\n",
    "        X_df = pd.read_csv(f'{path}/{group}/{kind}/df_x.csv')\n",
    "        X_df = y_df.drop('y', axis=1).merge(X_df, how='left', on=['ds'])\n",
    "       \n",
    "        S_df = None\n",
    "        if cache:\n",
    "            pd.to_pickle((y_df, X_df, S_df), file_cache)\n",
    "            \n",
    "        return y_df, X_df, S_df\n",
    "\n",
    "    @staticmethod\n",
    "    def download(directory: str) -> None:\n",
    "        \"\"\"Download ETT Dataset.\"\"\"\n",
    "        path = f'{directory}/longhorizon/datasets/'\n",
    "        if not os.path.exists(path):\n",
    "             download_file(path, ETT.source_url, decompress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: ETTh1 n_series: 1 ex_vars: ex_1, ex_2, ex_3, ex_4\n",
      "Group: ETTh2 n_series: 1 ex_vars: ex_1, ex_2, ex_3, ex_4\n",
      "Group: ETTm1 n_series: 7 ex_vars: ex_1, ex_2, ex_3, ex_4\n",
      "Group: ETTm2 n_series: 7 ex_vars: ex_1, ex_2, ex_3, ex_4\n"
     ]
    }
   ],
   "source": [
    "for group, meta in ETTInfo:\n",
    "    y_df, x_df, s_df = ETT.load(directory='data', group=group, cache=False)\n",
    "    n_series = len(np.unique(y_df.unique_id.values))\n",
    "    assert n_series == meta.n_ts\n",
    "    ex_vars = x_df.columns.to_list()\n",
    "    ex_vars.remove('unique_id')\n",
    "    ex_vars.remove('ds')\n",
    "\n",
    "    display_str  = f'Group: {group} '\n",
    "    display_str += f'n_series: {n_series} '\n",
    "    display_str += f'ex_vars: {\", \".join(ex_vars)}'\n",
    "\n",
    "    print(display_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
