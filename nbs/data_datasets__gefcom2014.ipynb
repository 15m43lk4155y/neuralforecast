{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.datasets.gefcom2014"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-parent",
   "metadata": {},
   "source": [
    "# GEFCom 2014 dataset\n",
    "\n",
    "> Download the GEFCom 2024 dataset.\n",
    "\n",
    "[Tao Hong, Pierre Pinson, Shu Fan, Hamidreza Zareipour, Alberto Troccoli and Rob J. Hyndman, \"Probabilistic energy forecasting: Global Energy Forecasting Competition 2014 and beyond\", International Journal of Forecasting, vol.32, no.3, pp 896-913, July-September, 2016.](https://www.sciencedirect.com/science/article/pii/S0169207016000133)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "import zipfile\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from neuralforecast.data.datasets.utils import (\n",
    "    download_file, \n",
    "    Info, \n",
    "    create_calendar_variables,\n",
    "    create_us_holiday_distance_variables,\n",
    ")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "FONTSIZE = 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-medicine",
   "metadata": {},
   "source": [
    ">GEFCom2014 meta inforamtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Extended:\n",
    "    test_date: str = '2016-12-27'\n",
    "    name: str = 'Extended'\n",
    "    freq: str = 'Y'\n",
    "\n",
    "@dataclass\n",
    "class Load:\n",
    "    test_date: str = '2016-12-27'\n",
    "    name: str = 'Load'\n",
    "    freq: str = 'H'\n",
    "\n",
    "@dataclass\n",
    "class Price:\n",
    "    test_date: str = '2015-01-04'\n",
    "    name: str = 'Price'\n",
    "    freq: str = 'H'\n",
    "\n",
    "@dataclass\n",
    "class Solar:\n",
    "    test_date: str = '2015-01-04'\n",
    "    name: str = 'Solar'\n",
    "    freq: str = 'H'\n",
    "\n",
    "@dataclass\n",
    "class Wind:\n",
    "    test_date: str = '2016-01-04'\n",
    "    name: str = 'Wind'\n",
    "    freq: str = 'H'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "GEFCom2014Info = Info(groups=('E_V2', 'L_V2', 'P_V2', 'S_V2', 'W_V2'),\n",
    "                      class_groups=(Extended, Load, Price, Solar, Wind))\n",
    "\n",
    "class GEFCom2014:\n",
    "    \n",
    "    source_url = 'https://www.dropbox.com/s/pqenrr2mcvl0hk9/GEFCom2014.zip?dl=1'\n",
    "    \n",
    "    @staticmethod\n",
    "    def unzip_wind(directory: str) -> None:\n",
    "        \"\"\"\n",
    "        Downloads wind data from GEFCom2014 Dataset.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory path where dataset is downloaded.\n",
    "        \"\"\"\n",
    "\n",
    "        path = f'{directory}/gefcom2014'\n",
    "        windpath = f'{path}/Wind'\n",
    "        for task_number in range(1, 16):\n",
    "            unzipdir = f'{windpath}/Task {task_number}'\n",
    "            ypath = f'{unzipdir}/Task{task_number}_W_Zone1_10.zip'\n",
    "            xpath = f'{unzipdir}/TaskExpVars{task_number}_W_Zone1_10.zip'\n",
    "            \n",
    "            with zipfile.ZipFile(ypath, 'r') as zip_ref:\n",
    "                zip_ref.extractall(path=unzipdir)\n",
    "            \n",
    "            with zipfile.ZipFile(xpath, 'r') as zip_ref:\n",
    "                zip_ref.extractall(path=unzipdir)\n",
    "        \n",
    "        logger.info(f'Successfully decompressed Wind tasks')\n",
    "    \n",
    "    @staticmethod\n",
    "    def unzip(path: str) -> None:\n",
    "        \"\"\"\n",
    "        Unzip compressed file.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        path: str\n",
    "            Path to file.\n",
    "        \"\"\"\n",
    "    \n",
    "        # Unzip Load, Price, Solar and Wind data\n",
    "        for group in GEFCom2014Info.groups:\n",
    "            filepath = f'{path}/GEFCom2014 Data/GEFCom2014-{group}.zip'\n",
    "            with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
    "                zip_ref.extractall(path)\n",
    "                logger.info(f'Successfully decompressed {filepath}')\n",
    "\n",
    "    @staticmethod\n",
    "    def download(directory: str) -> None:\n",
    "        \"\"\"\n",
    "        Downloads GEFCom2014 Dataset.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory path to download dataset.\n",
    "        \"\"\"\n",
    "        path = f'{directory}/gefcom2014'\n",
    "        if not os.path.exists(path):\n",
    "            download_file(directory=path, \n",
    "                          source_url=GEFCom2014.source_url,\n",
    "                          decompress=True)\n",
    "            \n",
    "            GEFCom2014.unzip(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-personal",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEFCom2014.download(f'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-private",
   "metadata": {},
   "source": [
    "# GEFCom2014-L: Original Electricity Load Task Datasets\n",
    "- Y: 5 years of hourly load data (augmented with tasks).\n",
    "- X: 11 years of 25 weather stations to be filtered (augmented with tasks).\n",
    "- Tasks: Fifteen one-month-ahead forecast quantiles of hourly loads on rolling basis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15b45d7",
   "metadata": {},
   "source": [
    ">GEFCom2014-L meta information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class LoadTask1:\n",
    "    test_start: str = '10/01/2010'\n",
    "    test_end: str = '11/01/2010'\n",
    "\n",
    "@dataclass\n",
    "class LoadTask2:\n",
    "    test_start: str = '11/01/2010'\n",
    "    test_end: str = '12/01/2010'\n",
    "\n",
    "@dataclass\n",
    "class LoadTask3:\n",
    "    test_start: str = '12/01/2010'\n",
    "    test_end: str = '01/01/2011'\n",
    "        \n",
    "@dataclass\n",
    "class LoadTask4:\n",
    "    test_start: str = '01/01/2011'\n",
    "    test_end: str = '02/01/2011'\n",
    "        \n",
    "@dataclass\n",
    "class LoadTask5:\n",
    "    test_start: str = '02/01/2011'\n",
    "    test_end: str = '03/01/2011'\n",
    "\n",
    "@dataclass\n",
    "class LoadTask6:\n",
    "    test_start: str = '03/01/2011'\n",
    "    test_end: str = '04/01/2011'\n",
    "        \n",
    "@dataclass\n",
    "class LoadTask7:\n",
    "    test_start: str = '04/01/2011'\n",
    "    test_end: str = '05/01/2011'\n",
    "    \n",
    "@dataclass\n",
    "class LoadTask8:\n",
    "    test_start: str = '05/01/2011'\n",
    "    test_end: str = '06/01/2011'\n",
    "        \n",
    "@dataclass\n",
    "class LoadTask9:\n",
    "    test_start: str = '06/01/2011'\n",
    "    test_end: str = '07/01/2011'\n",
    "        \n",
    "@dataclass\n",
    "class LoadTask10:\n",
    "    test_start: str = '07/01/2011'\n",
    "    test_end: str = '08/01/2011'\n",
    "        \n",
    "@dataclass\n",
    "class LoadTask11:\n",
    "    test_start: str = '08/01/2011'\n",
    "    test_end: str = '09/01/2011'\n",
    "        \n",
    "@dataclass\n",
    "class LoadTask12:\n",
    "    test_start: str = '09/01/2011'\n",
    "    test_end: str = '10/01/2011'\n",
    "        \n",
    "@dataclass\n",
    "class LoadTask13:\n",
    "    test_start: str = '10/01/2011'\n",
    "    test_end: str = '11/01/2011'\n",
    "        \n",
    "@dataclass\n",
    "class LoadTask14:\n",
    "    test_start: str = '11/01/2011'\n",
    "    test_end: str = '12/01/2011'\n",
    "        \n",
    "@dataclass\n",
    "class LoadTask15:\n",
    "    test_start: str = '12/01/2011'\n",
    "    test_end: str = '01/01/2012'\n",
    "        \n",
    "@dataclass\n",
    "class LoadTask16:\n",
    "    test_start: str = '01/01/2012'\n",
    "    test_end: str = '02/01/2012'\n",
    "\n",
    "\n",
    "LOAD_START = '01/01/2005'\n",
    "LOAD_TASKS = ['Task '+str(k) for k in range(1, 17)]\n",
    "GEFCom2014_L_Info = Info(groups=LOAD_TASKS,\n",
    "                         class_groups=[LoadTask1, LoadTask2, LoadTask3, LoadTask4,\n",
    "                                       LoadTask5, LoadTask6, LoadTask7, LoadTask8,\n",
    "                                       LoadTask9, LoadTask10, LoadTask11, LoadTask12,\n",
    "                                       LoadTask13, LoadTask14, LoadTask15, LoadTask16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GEFCom2014_L:\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_train_df(directory: str, group: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Load train dataset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'Task1', 'Task2', ..., 'Task14', 'Task15'.\n",
    " \n",
    "        Returns\n",
    "        -------\n",
    "        Y_df: pd.DataFrame\n",
    "            Target time series with columns ['unique_id', 'ds', 'y'].  \n",
    "        X_df: pd.DataFrame\n",
    "            Exogenous time series with columns ['unique_id', 'ds', 'y'].       \n",
    "        \"\"\"\n",
    "\n",
    "        # Meta data\n",
    "        path = f'{directory}/gefcom2014'\n",
    "        group_info = GEFCom2014_L_Info.get_group(group)\n",
    "        \n",
    "        # Cumulative data from previous tasks\n",
    "        previous_load_tasks = LOAD_TASKS[:LOAD_TASKS.index(group)+1]\n",
    "        train_dfs = []\n",
    "        for task in previous_load_tasks:\n",
    "            task_number = re.findall(\"\\d+\", task)[0]\n",
    "            \n",
    "            if task!='Task 16':\n",
    "                filepath = f'{path}/Load/Task {task_number}/L{task_number}-train.csv'\n",
    "                df = pd.read_csv(filepath, index_col=None, header=0)\n",
    "            else:\n",
    "                loadpath = f'{path}/Load/Solution to Task 15/solution15_L.csv'\n",
    "                load_df = pd.read_csv(loadpath, index_col=None, header=0)\n",
    "                weatherpath = f'{path}/Load/Solution to Task 15/solution15_L_temperature.csv'\n",
    "                df = pd.read_csv(weatherpath, index_col=None, header=0)\n",
    "                df['LOAD'] = load_df['LOAD']\n",
    "            train_dfs.append(df)\n",
    "        \n",
    "        # Train data\n",
    "        train_df = pd.concat(train_dfs, axis=0, ignore_index=True)\n",
    "        available = ~train_df['LOAD'].isnull()\n",
    "        train_df = train_df[available] # Filter load null values\n",
    "        train_df.reset_index(drop=True, inplace=True)\n",
    "        train_df = train_df.rename(columns={'ZONEID': 'unique_id', 'LOAD': 'y'})\n",
    "        train_df['ds'] = pd.date_range(start=LOAD_START,\n",
    "                                       end=group_info.test_start, freq='H', closed='right')\n",
    "        \n",
    "        Y_df = train_df[['unique_id', 'ds', 'y']].copy()\n",
    "        X_df = train_df.drop(['y', 'TIMESTAMP'], axis=1)\n",
    "        X_df = create_calendar_variables(X_df=X_df)\n",
    "        X_df = create_us_holiday_distance_variables(X_df=X_df)\n",
    "        return Y_df, X_df\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_benchmark_df(directory: str, group: str) -> pd.DataFrame:\n",
    "        \"\"\"Load benchmark time series.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'Task1', 'Task2', ..., 'Task14', 'Task15'.\n",
    " \n",
    "        Returns\n",
    "        -------\n",
    "        benchmark_df: pd.DataFrame\n",
    "            Benchmark time series form gefcom2012 dataset.   \n",
    "        \"\"\"\n",
    "\n",
    "        assert group!='Task 16', 'No available benchmark'\n",
    "        \n",
    "        # Meta data\n",
    "        path = f'{directory}/gefcom2014'\n",
    "        task_number = re.findall(\"\\d+\", group)[0]\n",
    "        group_info = GEFCom2014_L_Info.get_group(group)\n",
    "        \n",
    "        # Benchmark data\n",
    "        filepath = f'{path}/Load/Task {task_number}/L{task_number}-benchmark.csv'\n",
    "        benchmark_df = pd.read_csv(filepath, index_col=None, header=0)\n",
    "        benchmark_df['ds'] = pd.date_range(start=group_info.test_start,\n",
    "                                           end=group_info.test_end, freq='H', closed='right')\n",
    "        \n",
    "        benchmark_df = benchmark_df.drop('TIMESTAMP', axis=1)\n",
    "        benchmark_df = benchmark_df.rename(columns={'ZONEID': 'unique_id'})\n",
    "                \n",
    "        # complete benchmark data with the target variable for task evaluation\n",
    "        next_task_number = int(re.findall(\"\\d+\", group)[0])+1\n",
    "        next_group = 'Task ' + str(next_task_number)\n",
    "\n",
    "        Y_true_df, _ = GEFCom2014_L.read_train_df(directory, next_group)\n",
    "        ds_filter = (Y_true_df['ds'] >= benchmark_df.ds.min()) & (Y_true_df['ds'] <= benchmark_df.ds.max())\n",
    "        benchmark_df['y'] = Y_true_df[ds_filter].y.values\n",
    "        return benchmark_df\n",
    "\n",
    "    @staticmethod\n",
    "    def load(directory: str,\n",
    "             group: str) -> Tuple[pd.DataFrame, \n",
    "                                  pd.DataFrame, \n",
    "                                  pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Downloads and loads GEFCom2014-L data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'Task1', 'Task2', ..., 'Task14', 'Task15'.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Y_df: pd.DataFrame\n",
    "            Target time series with columns ['unique_id', 'ds', 'y']. \n",
    "        X_df: pd.DataFrame\n",
    "            Exogenous time series with columns ['unique_id', 'ds', 'y']. \n",
    "        benchmark_df: pd.DataFrame\n",
    "            Benchmark time series form gefcom2014 dataset.  \n",
    "        \"\"\"\n",
    "        path = f'{directory}/gefcom2014'\n",
    "        GEFCom2014.download(directory)\n",
    "        \n",
    "        Y_df, X_df = GEFCom2014_L.read_train_df(directory, group)\n",
    "        benchmark_df = GEFCom2014_L.read_benchmark_df(directory, group)\n",
    "        return Y_df, X_df, benchmark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df, X_df, benchmark_df = GEFCom2014_L.load(directory='data', group='Task 14')\n",
    "\n",
    "#ds = Y_df.ds.values[365*24:]\n",
    "#y_true = Y_df.y.values[365*24:]\n",
    "ds = Y_df.ds.values[-740:]\n",
    "y_true = Y_df.y.values[-740:]\n",
    "\n",
    "x_plot = Y_df.ds.values\n",
    "x_plot_min = pd.to_datetime(x_plot.min()).strftime('%B %d, %Y')\n",
    "x_plot_max = pd.to_datetime(x_plot.max()).strftime('%B %d, %Y')\n",
    "x_axis_str = f'Hours [{x_plot_min}  to  {x_plot_max}]'\n",
    "y_axis_str = 'Load (MW)'\n",
    "\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "fig.tight_layout()\n",
    "ax0 = plt.subplot2grid((1,1),(0, 0))\n",
    "axs = [ax0]\n",
    "\n",
    "axs[0].plot(ds, y_true, color='#628793', linewidth=0.4, label='true')\n",
    "axs[0].tick_params(labelsize=FONTSIZE-5)\n",
    "axs[0].set_xlabel(x_axis_str, fontsize=FONTSIZE)\n",
    "axs[0].set_ylabel(y_axis_str, fontsize=FONTSIZE)\n",
    "plt.ylim(50, 350)\n",
    "plt.title('GEFCom2014-L', fontsize=FONTSIZE)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-belly",
   "metadata": {},
   "source": [
    "# GEFCom2014-E: Extended 2015 Electricity Load Task Datasets\n",
    "- Y: Four years of hourly load data (augmented with tasks).\n",
    "- X: Six years of hourly temperature (augmented with tasks).\n",
    "- Task: Five one-year-ahead forecast quantiles of hourly loads on rolling basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GEFCom2014_E:\n",
    "    \n",
    "    @staticmethod\n",
    "    def load(directory: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Downloads and loads GEFCom2014-E data.\n",
    "        This dataset is an extension to the GEFCom2014-L data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Y_df: pd.DataFrame\n",
    "            Target time series with columns ['unique_id', 'ds', 'y']. \n",
    "        X_df: pd.DataFrame\n",
    "            Exogenous time series with columns ['unique_id', 'ds', 'y']. \n",
    "        \"\"\"\n",
    "        path = f'{directory}/gefcom2014'\n",
    "        GEFCom2014.download(directory)\n",
    "        \n",
    "        filepath = f'{path}/GEFCom2014-E.xlsx'\n",
    "        df = pd.read_excel(filepath)\n",
    "\n",
    "        # create timestamp variable from Date and Hour\n",
    "        df['ds'] = df['Date'].add(pd.to_timedelta(df.Hour - 1, unit='h'))\n",
    "        df['unique_id'] = 1\n",
    "        df = df.rename(columns={'T':'temp', 'load':'y'})\n",
    "\n",
    "        # create Y_df and X_df\n",
    "        df = df[df.ds >= '2006-01-01'] # remove time period with no load data\n",
    "        Y_df = df[['unique_id', 'ds', 'y']]\n",
    "\n",
    "        X_df = df.drop(['y', 'Date', 'Hour'], axis=1)\n",
    "        X_df = create_calendar_variables(X_df=X_df)\n",
    "        return Y_df, X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df, X_df = GEFCom2014_E.load(directory='data')\n",
    "\n",
    "ds = Y_df.ds.values\n",
    "y_true = Y_df.y.values\n",
    "\n",
    "x_plot = Y_df.ds.values\n",
    "x_plot_min = pd.to_datetime(x_plot.min()).strftime('%B %d, %Y')\n",
    "x_plot_max = pd.to_datetime(x_plot.max()).strftime('%B %d, %Y')\n",
    "x_axis_str = f'Hours [{x_plot_min}  to  {x_plot_max}]'\n",
    "y_axis_str = 'Load (MW)'\n",
    "\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "fig.tight_layout()\n",
    "ax0 = plt.subplot2grid((1,1),(0, 0))\n",
    "axs = [ax0]\n",
    "\n",
    "axs[0].plot(ds, y_true, color='#628793', linewidth=0.4, label='true')\n",
    "axs[0].tick_params(labelsize=FONTSIZE-5)\n",
    "axs[0].set_xlabel(x_axis_str, fontsize=FONTSIZE)\n",
    "axs[0].set_ylabel(y_axis_str, fontsize=FONTSIZE)\n",
    "plt.ylim(1800, 5800)\n",
    "plt.title('GEFCom2014-E', fontsize=FONTSIZE)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-issue",
   "metadata": {},
   "source": [
    "# GEFCOM2014-P: Electricity Price Task Datasets\n",
    "- Y: Hourly electricity price\n",
    "- X: Zonal and system load day-ahead forecasts\n",
    "- Tasks: Fifteen one-day-ahead forecast quantiles of hourly price on rolling basis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e982da",
   "metadata": {},
   "source": [
    ">GEFcom2014-P meta information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class PriceTask1:\n",
    "    test_start: str = '06/16/2013'\n",
    "    test_end: str = '06/17/2013'\n",
    "\n",
    "@dataclass\n",
    "class PriceTask2:\n",
    "    test_start: str = '06/17/2013'\n",
    "    test_end: str = '06/18/2013'\n",
    "\n",
    "@dataclass\n",
    "class PriceTask3:\n",
    "    test_start: str = '06/24/2013'\n",
    "    test_end: str = '06/25/2013'\n",
    "        \n",
    "@dataclass\n",
    "class PriceTask4:\n",
    "    test_start: str = '07/04/2013'\n",
    "    test_end: str = '07/05/2013'\n",
    "        \n",
    "@dataclass\n",
    "class PriceTask5:\n",
    "    test_start: str = '07/09/2013'\n",
    "    test_end: str = '07/10/2013'\n",
    "\n",
    "@dataclass\n",
    "class PriceTask6:\n",
    "    test_start: str = '07/13/2013'\n",
    "    test_end: str = '07/14/2013'\n",
    "        \n",
    "@dataclass\n",
    "class PriceTask7:\n",
    "    test_start: str = '07/16/2013'\n",
    "    test_end: str = '07/17/2013'\n",
    "    \n",
    "@dataclass\n",
    "class PriceTask8:\n",
    "    test_start: str = '07/18/2013'\n",
    "    test_end: str = '07/19/2013'\n",
    "\n",
    "@dataclass\n",
    "class PriceTask9:\n",
    "    test_start: str = '07/19/2013'\n",
    "    test_end: str = '07/20/2013'\n",
    "        \n",
    "@dataclass\n",
    "class PriceTask10:\n",
    "    test_start: str = '07/20/2013'\n",
    "    test_end: str = '07/21/2013'\n",
    "        \n",
    "@dataclass\n",
    "class PriceTask11:\n",
    "    test_start: str = '07/24/2013'\n",
    "    test_end: str = '07/25/2013'\n",
    "        \n",
    "@dataclass\n",
    "class PriceTask12:\n",
    "    test_start: str = '07/25/2013'\n",
    "    test_end: str = '07/26/2013'\n",
    "        \n",
    "@dataclass\n",
    "class PriceTask13:\n",
    "    test_start: str = '12/07/2013'\n",
    "    test_end: str = '12/08/2013'\n",
    "        \n",
    "@dataclass\n",
    "class PriceTask14:\n",
    "    test_start: str = '12/08/2013'\n",
    "    test_end: str = '12/09/2013'\n",
    "        \n",
    "@dataclass\n",
    "class PriceTask15:\n",
    "    test_start: str = '12/17/2013'\n",
    "    test_end: str = '12/18/2013'\n",
    "\n",
    "\n",
    "PRICE_START = '01/01/2011'\n",
    "PRICE_TASKS = ['Task '+str(k) for k in range(1, 16)]\n",
    "GEFCom2014_P_Info = Info(groups=PRICE_TASKS,\n",
    "                         class_groups=[PriceTask1, PriceTask2, PriceTask3, PriceTask4,\n",
    "                                       PriceTask5, PriceTask6, PriceTask7, PriceTask8,\n",
    "                                       PriceTask9, PriceTask10, PriceTask11, PriceTask12,\n",
    "                                       PriceTask13, PriceTask14, PriceTask15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GEFCom2014_P:\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_train_df(directory: str, group: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Load train dataset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'Task1', 'Task2', ..., 'Task14', 'Task15'.\n",
    " \n",
    "        Returns\n",
    "        -------\n",
    "        Y_df: pd.DataFrame\n",
    "            Target time series with columns ['unique_id', 'ds', 'y'].  \n",
    "        X_df: pd.DataFrame\n",
    "            Exogenous time series with columns ['unique_id', 'ds', 'y'].       \n",
    "        \"\"\"\n",
    "\n",
    "        # Meta data\n",
    "        path = f'{directory}/gefcom2014'\n",
    "        group_info = GEFCom2014_P_Info.get_group(group)\n",
    "        task_number = re.findall(\"\\d+\", group)[0]\n",
    "        filepath = f'{path}/Price/Task {task_number}/Task{task_number}_P.csv'\n",
    "        \n",
    "        # Train data\n",
    "        train_df = pd.read_csv(filepath, index_col=None, header=0)\n",
    "        train_df.reset_index(drop=True, inplace=True)\n",
    "        train_df = train_df.rename(columns={'ZONEID': 'unique_id', 'Zonal Price': 'y'})    \n",
    "        train_df['ds'] = pd.date_range(start=PRICE_START,\n",
    "                                       end=group_info.test_end, freq='H', closed='right')\n",
    "        \n",
    "        Y_df = train_df[['unique_id', 'ds', 'y']].copy()\n",
    "        X_df = train_df.drop(['y', 'timestamp'], axis=1)\n",
    "        X_df = create_calendar_variables(X_df=X_df)\n",
    "        X_df = create_us_holiday_distance_variables(X_df=X_df)\n",
    "        return Y_df, X_df\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_benchmark_df(directory: str, group: str) -> pd.DataFrame:\n",
    "        \"\"\"Load benchmark time series.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'Task1', 'Task2', ..., 'Task14', 'Task15'.\n",
    " \n",
    "        Returns\n",
    "        -------\n",
    "        benchmark_df: pd.DataFrame\n",
    "            Benchmark time series form gefcom2012 dataset.   \n",
    "        \"\"\"\n",
    "\n",
    "        # Meta data\n",
    "        path = f'{directory}/gefcom2014'\n",
    "        group_info = GEFCom2014_P_Info.get_group(group)\n",
    "        task_number = re.findall(\"\\d+\", group)[0]\n",
    "        filepath = f'{path}/Price/Task {task_number}/Benchmark{task_number}_P.csv'\n",
    "        \n",
    "        if group=='Task 7':\n",
    "            filepath = f'{path}/Price/Task {task_number}/Benchmark{task_number}_P_new3.csv'\n",
    "        \n",
    "        benchmark_df = pd.read_csv(filepath, index_col=None, header=0)\n",
    "        benchmark_df['ds'] = pd.date_range(start=group_info.test_start,\n",
    "                                           end=group_info.test_end, freq='H', closed='right')\n",
    "\n",
    "        benchmark_df = benchmark_df.drop('timestamp', axis=1)\n",
    "        benchmark_df = benchmark_df.rename(columns={'ZONEID': 'unique_id'})\n",
    "        \n",
    "        # complete benchmark data with the target variable for task evaluation\n",
    "        if group!='Task 15':\n",
    "            next_task_number = int(re.findall(\"\\d+\", group)[0])+1\n",
    "            next_group = 'Task ' + str(next_task_number)\n",
    "            \n",
    "            Y_true_df, _ = GEFCom2014_P.read_train_df(directory, next_group)\n",
    "            ds_filter = (Y_true_df['ds'] >= benchmark_df.ds.min()) & (Y_true_df['ds'] <= benchmark_df.ds.max())\n",
    "            benchmark_df['y'] = Y_true_df[ds_filter].y.values\n",
    "        return benchmark_df\n",
    "\n",
    "    @staticmethod\n",
    "    def load(directory: str,\n",
    "             group: str) -> Tuple[pd.DataFrame, \n",
    "                                  pd.DataFrame, \n",
    "                                  pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Downloads and loads GEFCom2014-P task data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'Task1', 'Task2', ..., 'Task14', 'Task15'.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Y_df: pd.DataFrame\n",
    "            Target time series with columns ['unique_id', 'ds', 'y']. \n",
    "        X_df: pd.DataFrame\n",
    "            Exogenous time series with columns ['unique_id', 'ds', 'y']. \n",
    "        benchmark_df: pd.DataFrame\n",
    "            Benchmark time series form gefcom2014 dataset.\n",
    "        \"\"\"        \n",
    "        GEFCom2014.download(directory)\n",
    "        \n",
    "        Y_df, X_df = GEFCom2014_P.read_train_df(directory, group)\n",
    "        benchmark_df = GEFCom2014_P.read_benchmark_df(directory, group)\n",
    "        return Y_df, X_df, benchmark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df, X_df, benchmark_df = GEFCom2014_P.load(directory='data', group='Task 15')\n",
    "\n",
    "ds = Y_df.ds.values\n",
    "y_true = Y_df.y.values\n",
    "\n",
    "x_plot = Y_df.ds.values\n",
    "x_plot_min = pd.to_datetime(x_plot.min()).strftime('%B %d, %Y')\n",
    "x_plot_max = pd.to_datetime(x_plot.max()).strftime('%B %d, %Y')\n",
    "x_axis_str = f'Hours [{x_plot_min}  to  {x_plot_max}]'\n",
    "y_axis_str = 'Price [USD/MWh]'\n",
    "\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "fig.tight_layout()\n",
    "ax0 = plt.subplot2grid((1,1),(0, 0))\n",
    "axs = [ax0]\n",
    "\n",
    "axs[0].plot(ds, y_true, color='#628793', linewidth=0.4, label='true')\n",
    "axs[0].tick_params(labelsize=FONTSIZE-5)\n",
    "axs[0].set_xlabel(x_axis_str, fontsize=FONTSIZE)\n",
    "axs[0].set_ylabel(y_axis_str, fontsize=FONTSIZE)\n",
    "plt.title('GEFCom2014-P', fontsize=FONTSIZE)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-darwin",
   "metadata": {},
   "source": [
    "# GEFCOM2014-W: Wind Power Generation Task Datasets\n",
    "- Y: 10 target wind power series, for 10 different Australian wind farms.\n",
    "- X: Wind forecasts at 10m and 100m height for the zonal (u) and meridional (v) wind components (winning submission used external data).\n",
    "- Tasks: Fifteen one-month-ahead hourly wind power generation for 10 farms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fd697f",
   "metadata": {},
   "source": [
    ">GEFcom2014-W meta information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class WindTask1:\n",
    "    test_start: str = '10/01/2012'\n",
    "    test_end: str = '11/01/2012'\n",
    "\n",
    "@dataclass\n",
    "class WindTask2:\n",
    "    test_start: str = '11/01/2012'\n",
    "    test_end: str = '12/01/2012'\n",
    "\n",
    "@dataclass\n",
    "class WindTask3:\n",
    "    test_start: str = '12/01/2012'\n",
    "    test_end: str = '01/01/2013'\n",
    "        \n",
    "@dataclass\n",
    "class WindTask4:\n",
    "    test_start: str = '01/01/2013'\n",
    "    test_end: str = '02/01/2013'\n",
    "        \n",
    "@dataclass\n",
    "class WindTask5:\n",
    "    test_start: str = '02/01/2013'\n",
    "    test_end: str = '03/01/2013'\n",
    "\n",
    "@dataclass\n",
    "class WindTask6:\n",
    "    test_start: str = '03/01/2013'\n",
    "    test_end: str = '04/01/2013'\n",
    "        \n",
    "@dataclass\n",
    "class WindTask7:\n",
    "    test_start: str = '04/01/2013'\n",
    "    test_end: str = '05/01/2013'\n",
    "    \n",
    "@dataclass\n",
    "class WindTask8:\n",
    "    test_start: str = '05/01/2013'\n",
    "    test_end: str = '06/01/2013'\n",
    "\n",
    "@dataclass\n",
    "class WindTask9:\n",
    "    test_start: str = '06/01/2013'\n",
    "    test_end: str = '07/01/2013'\n",
    "        \n",
    "@dataclass\n",
    "class WindTask10:\n",
    "    test_start: str = '07/01/2013'\n",
    "    test_end: str = '08/01/2013'\n",
    "        \n",
    "@dataclass\n",
    "class WindTask11:\n",
    "    test_start: str = '08/01/2013'\n",
    "    test_end: str = '09/01/2013'\n",
    "        \n",
    "@dataclass\n",
    "class WindTask12:\n",
    "    test_start: str = '09/01/2013'\n",
    "    test_end: str = '10/01/2013'\n",
    "        \n",
    "@dataclass\n",
    "class WindTask13:\n",
    "    test_start: str = '10/01/2013'\n",
    "    test_end: str = '11/01/2013'\n",
    "        \n",
    "@dataclass\n",
    "class WindTask14:\n",
    "    test_start: str = '11/01/2013'\n",
    "    test_end: str = '12/01/2013'\n",
    "        \n",
    "@dataclass\n",
    "class WindTask15:\n",
    "    test_start: str = '12/01/2013'\n",
    "    test_end: str = '01/01/2014'\n",
    "\n",
    "\n",
    "WIND_START = '01/01/2012'\n",
    "WIND_TASKS = ['Task '+str(k) for k in range(1, 16)]\n",
    "GEFCom2014_W_Info = Info(groups=WIND_TASKS,\n",
    "                         class_groups=[WindTask1, WindTask2, WindTask3, WindTask4,\n",
    "                                       WindTask5, WindTask6, WindTask7, WindTask8,\n",
    "                                       WindTask9, WindTask10, WindTask11, WindTask12,\n",
    "                                       WindTask13, WindTask14, WindTask15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GEFCom2014_W:\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_train_df(directory: str, group: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Load train dataset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'Task1', 'Task2', ..., 'Task14', 'Task15'.\n",
    " \n",
    "        Returns\n",
    "        -------\n",
    "        Y_df: pd.DataFrame\n",
    "            Target time series with columns ['unique_id', 'ds', 'y'].  \n",
    "        X_df: pd.DataFrame\n",
    "            Exogenous time series with columns ['unique_id', 'ds', 'y'].       \n",
    "        \"\"\"\n",
    "\n",
    "        # Meta data\n",
    "        path = f'{directory}/gefcom2014'\n",
    "        task_number = int(re.findall(\"\\d+\", group)[0])\n",
    "        group_info = GEFCom2014_W_Info.get_group(group)\n",
    "        path = f'{directory}/gefcom2014'\n",
    "        ydir = f'{path}/Wind/Task {task_number}/Task{task_number}_W_Zone1_10'\n",
    "        xdir = f'{path}/Wind/Task {task_number}/TaskExpVars{task_number}_W_Zone1_10'\n",
    "        \n",
    "        # Train data\n",
    "        train_dfs = []\n",
    "        for zone in range(1, 11):\n",
    "            yfilepath = f'{ydir}/Task{task_number}_W_Zone{zone}.csv'\n",
    "            xfilepath = f'{xdir}/TaskExpVars{task_number}_W_Zone{zone}.csv'\n",
    "\n",
    "            train_df = pd.read_csv(yfilepath, index_col=None, header=0)\n",
    "            train_df.reset_index(drop=True, inplace=True)\n",
    "            x_df = pd.read_csv(xfilepath, index_col=None, header=0)\n",
    "            x_df['TARGETVAR'] = np.nan\n",
    "            train_df = train_df.append(x_df)\n",
    "            train_df['ds'] = pd.date_range(start=WIND_START,\n",
    "                                           end=group_info.test_end, freq='H', closed='right')\n",
    "\n",
    "            train_dfs.append(train_df)\n",
    "\n",
    "        train_df = pd.concat(train_dfs, axis=0, ignore_index=True)\n",
    "        train_df = train_df.rename(columns={'ZONEID': 'unique_id', 'TARGETVAR': 'y'})\n",
    "\n",
    "        Y_df = train_df[['unique_id', 'ds', 'y']].copy()\n",
    "        X_df = train_df.drop(['y', 'TIMESTAMP'], axis=1)\n",
    "        return Y_df, X_df\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_benchmark_df(directory: str, group: str) -> pd.DataFrame:\n",
    "        \"\"\"Load benchmark time series.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'Task1', 'Task2', ..., 'Task14', 'Task15'.\n",
    " \n",
    "        Returns\n",
    "        -------\n",
    "        benchmark_df: pd.DataFrame\n",
    "            Benchmark time series form gefcom2012 dataset.   \n",
    "        \"\"\"\n",
    "\n",
    "        # Meta data\n",
    "        path = f'{directory}/gefcom2014'\n",
    "        task_number = int(re.findall(\"\\d+\", group)[0])\n",
    "        group_info = GEFCom2014_W_Info.get_group(group)\n",
    "        benchmarkfilepath = f'{path}/Wind/Task {task_number}/benchmark{task_number}_W.csv'\n",
    "        \n",
    "        # Benchmark data\n",
    "        benchmark_df = pd.read_csv(benchmarkfilepath, index_col=None, header=0)\n",
    "        benchmark_df.reset_index(drop=True, inplace=True)\n",
    "        benchmark_df = benchmark_df.rename(columns={'ZONEID': 'unique_id'})        \n",
    "        return benchmark_df\n",
    "    \n",
    "    @staticmethod\n",
    "    def load(directory: str,\n",
    "             group: str) -> Tuple[pd.DataFrame, \n",
    "                                  pd.DataFrame, \n",
    "                                  pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Downloads and loads GEFCom2014-W task data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'Task1', 'Task2', ..., 'Task14', 'Task15'.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Y_df: pd.DataFrame\n",
    "            Target time series with columns ['unique_id', 'ds', 'y']. \n",
    "        X_df: pd.DataFrame\n",
    "            Exogenous time series with columns ['unique_id', 'ds', 'y']. \n",
    "        benchmark_df: pd.DataFrame\n",
    "            Benchmark time series form gefcom2014 dataset.\n",
    "        \"\"\"  \n",
    "\n",
    "        GEFCom2014.download(directory)\n",
    "        GEFCom2014.unzip_wind(directory)\n",
    "\n",
    "        Y_df, X_df = GEFCom2014_W.read_train_df(directory, group)\n",
    "        benchmark_df = GEFCom2014_W.read_benchmark_df(directory, group)\n",
    "        return Y_df, X_df, benchmark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df, X_df, benchmark_df = GEFCom2014_W.load(directory='data', group='Task 15')\n",
    "\n",
    "Y_df = Y_df[Y_df.unique_id==2]\n",
    "\n",
    "ds = Y_df.ds.values\n",
    "y_true = Y_df.y.values\n",
    "\n",
    "x_plot = Y_df.ds.values\n",
    "x_plot_min = pd.to_datetime(x_plot.min()).strftime('%B %d, %Y')\n",
    "x_plot_max = pd.to_datetime(x_plot.max()).strftime('%B %d, %Y')\n",
    "x_axis_str = f'Hours [{x_plot_min}  to  {x_plot_max}]'\n",
    "y_axis_str = 'Power'\n",
    "\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "fig.tight_layout()\n",
    "ax0 = plt.subplot2grid((1,1),(0, 0))\n",
    "axs = [ax0]\n",
    "\n",
    "axs[0].plot(ds, y_true, color='#628793', linewidth=0.4, label='true')\n",
    "axs[0].tick_params(labelsize=FONTSIZE-5)\n",
    "axs[0].set_xlabel(x_axis_str, fontsize=FONTSIZE)\n",
    "axs[0].set_ylabel(y_axis_str, fontsize=FONTSIZE)\n",
    "plt.title('GEFCom2014-W', fontsize=FONTSIZE)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-indonesia",
   "metadata": {},
   "source": [
    "# GEFCom2014-S: Solar Power Generation Task Datasets\n",
    "- Y: 3 target solar power series, for 3 different solar power plants.\n",
    "- X: 12 weather variables associated to the solar power plants.\n",
    "- Tasks: Fifteen one-month-ahead hourly solar power generation for 3 power platns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243a448c",
   "metadata": {},
   "source": [
    ">GEFcom2014-S meta information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class SolarTask1:\n",
    "    test_start: str = '04/01/2013'\n",
    "    test_end: str = '05/01/2013'\n",
    "\n",
    "@dataclass\n",
    "class SolarTask2:\n",
    "    test_start: str = '05/01/2013'\n",
    "    test_end: str = '06/01/2013'\n",
    "\n",
    "@dataclass\n",
    "class SolarTask3:\n",
    "    test_start: str = '06/01/2013'\n",
    "    test_end: str = '07/01/2013'\n",
    "        \n",
    "@dataclass\n",
    "class SolarTask4:\n",
    "    test_start: str = '07/01/2013'\n",
    "    test_end: str = '08/01/2013'\n",
    "        \n",
    "@dataclass\n",
    "class SolarTask5:\n",
    "    test_start: str = '08/01/2013'\n",
    "    test_end: str = '09/01/2013'\n",
    "\n",
    "@dataclass\n",
    "class SolarTask6:\n",
    "    test_start: str = '09/01/2013'\n",
    "    test_end: str = '10/01/2013'\n",
    "        \n",
    "@dataclass\n",
    "class SolarTask7:\n",
    "    test_start: str = '10/01/2013'\n",
    "    test_end: str = '11/01/2013'\n",
    "    \n",
    "@dataclass\n",
    "class SolarTask8:\n",
    "    test_start: str = '11/01/2013'\n",
    "    test_end: str = '12/01/2013'\n",
    "\n",
    "@dataclass\n",
    "class SolarTask9:\n",
    "    test_start: str = '12/01/2013'\n",
    "    test_end: str = '01/01/2014'\n",
    "        \n",
    "@dataclass\n",
    "class SolarTask10:\n",
    "    test_start: str = '01/01/2014'\n",
    "    test_end: str = '02/01/2014'\n",
    "        \n",
    "@dataclass\n",
    "class SolarTask11:\n",
    "    test_start: str = '02/01/2014'\n",
    "    test_end: str = '03/01/2014'\n",
    "        \n",
    "@dataclass\n",
    "class SolarTask12:\n",
    "    test_start: str = '03/01/2014'\n",
    "    test_end: str = '04/01/2014'\n",
    "        \n",
    "@dataclass\n",
    "class SolarTask13:\n",
    "    test_start: str = '04/01/2014'\n",
    "    test_end: str = '05/01/2014'\n",
    "        \n",
    "@dataclass\n",
    "class SolarTask14:\n",
    "    test_start: str = '05/01/2014'\n",
    "    test_end: str = '06/01/2014'\n",
    "        \n",
    "@dataclass\n",
    "class SolarTask15:\n",
    "    test_start: str = '06/01/2014'\n",
    "    test_end: str = '07/01/2014'\n",
    "\n",
    "\n",
    "SOLAR_START = '04/01/2012'\n",
    "SOLAR_TASKS = ['Task '+str(k) for k in range(1, 16)]\n",
    "GEFCom2014_S_Info = Info(groups=SOLAR_TASKS,\n",
    "                         class_groups=[SolarTask1, SolarTask2, SolarTask3, SolarTask4,\n",
    "                                       SolarTask5, SolarTask6, SolarTask7, SolarTask8,\n",
    "                                       SolarTask9, SolarTask10, SolarTask11, SolarTask12,\n",
    "                                       SolarTask13, SolarTask14, SolarTask15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GEFCom2014_S:\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_train_df(directory: str, group: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Load train dataset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'Task1', 'Task2', ..., 'Task14', 'Task15'.\n",
    " \n",
    "        Returns\n",
    "        -------\n",
    "        Y_df: pd.DataFrame\n",
    "            Target time series with columns ['unique_id', 'ds', 'y'].  \n",
    "        X_df: pd.DataFrame\n",
    "            Exogenous time series with columns ['unique_id', 'ds', 'y'].       \n",
    "        \"\"\"\n",
    "\n",
    "        # Meta data\n",
    "        path = f'{directory}/gefcom2014'\n",
    "        task_number = int(re.findall(\"\\d+\", group)[0])\n",
    "        group_info = GEFCom2014_S_Info.get_group(group)\n",
    "        yfilepath = f'{path}/Solar/Task {task_number}/train{task_number}.csv'\n",
    "        xfilepath = f'{path}/Solar/Task {task_number}/predictors{task_number}.csv'\n",
    "        \n",
    "        # Train data\n",
    "        ds = pd.date_range(start=SOLAR_START,\n",
    "                           end=group_info.test_start, freq='H', closed='right').values\n",
    "        ds = np.tile(ds, 3)\n",
    "        Y_df = pd.read_csv(yfilepath, index_col=None, header=0)\n",
    "        Y_df.reset_index(drop=True, inplace=True)\n",
    "        Y_df['ds'] = ds\n",
    "        Y_df = Y_df.drop(['TIMESTAMP'], axis=1)\n",
    "        Y_df = Y_df.rename(columns={'ZONEID': 'unique_id', 'POWER': 'y'})\n",
    "\n",
    "        ds = pd.date_range(start=SOLAR_START,\n",
    "                           end=group_info.test_end, freq='H', closed='right').values\n",
    "        ds = np.tile(ds, 3)\n",
    "        X_df = pd.read_csv(xfilepath, index_col=None, header=0)\n",
    "        X_df.reset_index(drop=True, inplace=True)\n",
    "        X_df['ds'] = ds\n",
    "        X_df = X_df.drop(['TIMESTAMP'], axis=1)\n",
    "        X_df = X_df.rename(columns={'ZONEID': 'unique_id'})\n",
    "        return Y_df, X_df\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_benchmark_df(directory: str, group: str) -> pd.DataFrame:\n",
    "        \"\"\"Load benchmark time series.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'Task1', 'Task2', ..., 'Task14', 'Task15'.\n",
    " \n",
    "        Returns\n",
    "        -------\n",
    "        benchmark_df: pd.DataFrame\n",
    "            Benchmark time series form gefcom2012 dataset.   \n",
    "        \"\"\"\n",
    "\n",
    "        # Meta data\n",
    "        group_info = GEFCom2014_S_Info.get_group(group)\n",
    "        \n",
    "        path = f'{directory}/gefcom2014'\n",
    "        task_number = int(re.findall(\"\\d+\", group)[0])\n",
    "        \n",
    "        if task_number<10:\n",
    "            task_number2 = '0'+str(task_number)\n",
    "        else:\n",
    "            task_number2 = task_number\n",
    "        \n",
    "        benchmarkfilepath = f'{path}/Solar/Task {task_number}/benchmark{task_number2}.csv'\n",
    "        \n",
    "        ds = pd.date_range(start=group_info.test_start,\n",
    "                           end=group_info.test_end, freq='H', closed='right').values\n",
    "        ds = np.tile(ds, 3)\n",
    "        benchmark_df = pd.read_csv(benchmarkfilepath, index_col=None, header=0)\n",
    "        benchmark_df.reset_index(drop=True, inplace=True)\n",
    "        benchmark_df['ds'] = ds\n",
    "        benchmark_df = benchmark_df.drop(['TIMESTAMP'], axis=1)\n",
    "        return benchmark_df\n",
    "    \n",
    "    @staticmethod\n",
    "    def load(directory: str,\n",
    "             group: str) -> Tuple[pd.DataFrame, \n",
    "                                  pd.DataFrame, \n",
    "                                  pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Downloads and loads GEFCom2014-W task data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'Task1', 'Task2', ..., 'Task14', 'Task15'.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Y_df: pd.DataFrame\n",
    "            Target time series with columns ['unique_id', 'ds', 'y']. \n",
    "        X_df: pd.DataFrame\n",
    "            Exogenous time series with columns ['unique_id', 'ds', 'y']. \n",
    "        benchmark_df: pd.DataFrame\n",
    "            Benchmark time series form gefcom2014 dataset.\n",
    "        \"\"\" \n",
    "\n",
    "        GEFCom2014.download(directory)\n",
    "\n",
    "        Y_df, X_df = GEFCom2014_S.read_train_df(directory, group)\n",
    "        benchmark_df = GEFCom2014_S.read_benchmark_df(directory, group)\n",
    "        return Y_df, X_df, benchmark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df, X_df, benchmark_df = GEFCom2014_S.load(directory='data', group='Task 15')\n",
    "\n",
    "Y_df = Y_df[Y_df.unique_id==2]\n",
    "\n",
    "ds = Y_df.ds.values\n",
    "y_true = Y_df.y.values\n",
    "\n",
    "x_plot = Y_df.ds.values\n",
    "x_plot_min = pd.to_datetime(x_plot.min()).strftime('%B %d, %Y')\n",
    "x_plot_max = pd.to_datetime(x_plot.max()).strftime('%B %d, %Y')\n",
    "x_axis_str = f'Hours [{x_plot_min}  to  {x_plot_max}]'\n",
    "y_axis_str = 'Power'\n",
    "\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "fig.tight_layout()\n",
    "ax0 = plt.subplot2grid((1,1),(0, 0))\n",
    "axs = [ax0]\n",
    "\n",
    "axs[0].plot(ds, y_true, color='#628793', linewidth=0.4, label='true')\n",
    "axs[0].tick_params(labelsize=FONTSIZE-5)\n",
    "axs[0].set_xlabel(x_axis_str, fontsize=FONTSIZE)\n",
    "axs[0].set_ylabel(y_axis_str, fontsize=FONTSIZE)\n",
    "plt.title('GEFCom2014-S', fontsize=FONTSIZE)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-egyptian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
