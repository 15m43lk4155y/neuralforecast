{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.datasets.m4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M4 dataset\n",
    "\n",
    "> API details.\n",
    "\n",
    "The M4 competition extended on the previous three M competitions. The dataset of the contest included 100,000 time series 95,000 of which on yearly, quarterly and monthly frequencies, and the rest in weekly, daily and hourly higher frequencies. This competition received 61 different forecasting methods, notably a neural network model outperformed the rest of the competitors, for the first time in contrast with the previous M forecasting competitions.\n",
    "\n",
    "[Spyros  Makridakis,  Evangelos  Spiliotis, and  Vassilios Assimakopoulos. The  M4  competition: 100,000  time  series and 61 forecasting methods. International Journal of Forecasting, 36(1):54â€“74, 2020. ISSN  0169-2070.](https://www.sciencedirect.com/science/article/pii/S0169207019301128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nixtla.data.datasets.utils import download_file, Info, TimeSeriesDataclass\n",
    "from nixtla.data.tsdataset import TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M4 meta information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Yearly:\n",
    "    seasonality: int = 1\n",
    "    horizon: int = 6\n",
    "    freq: str = 'Y'\n",
    "    name: str = 'Yearly'\n",
    "    n_ts: int = 23_000\n",
    "\n",
    "@dataclass\n",
    "class Quarterly:\n",
    "    seasonality: int = 4\n",
    "    horizon: int = 8\n",
    "    freq: str = 'Q'\n",
    "    name: str = 'Quarterly'\n",
    "    n_ts: int = 24_000\n",
    "\n",
    "@dataclass\n",
    "class Monthly:\n",
    "    seasonality: int = 12\n",
    "    horizon: int = 18\n",
    "    freq: str = 'M'\n",
    "    name: str = 'Monthly'\n",
    "    n_ts: int = 48_000\n",
    "\n",
    "@dataclass\n",
    "class Weekly:\n",
    "    seasonality: int = 52\n",
    "    horizon: int = 13\n",
    "    freq: str = 'W'\n",
    "    name: str = 'Weekly'\n",
    "    n_ts: int = 359\n",
    "        \n",
    "@dataclass\n",
    "class Daily:\n",
    "    seasonality: int = 7\n",
    "    horizon: int = 14\n",
    "    freq: str = 'D'\n",
    "    name: str = 'Daily'\n",
    "    n_ts: int = 4_227\n",
    "\n",
    "@dataclass\n",
    "class Hourly:\n",
    "    seasonality: int = 24\n",
    "    horizon: int = 48\n",
    "    freq: str = 'H'\n",
    "    name: str = 'Hourly'\n",
    "    n_ts: int = 414\n",
    "\n",
    "        \n",
    "@dataclass\n",
    "class Other:\n",
    "    seasonality: int = 1\n",
    "    horizon: int = 8\n",
    "    freq: str = 'D'\n",
    "    name: str = 'Other'\n",
    "    n_ts: int = 5_000\n",
    "    included_groups: Tuple = ('Weekly', 'Daily', 'Hourly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "M4Info = Info(groups=('Yearly', 'Quarterly', 'Monthly', 'Weekly', 'Daily', 'Hourly', 'Other'),\n",
    "              class_groups=(Yearly, Quarterly, Monthly, Weekly, Daily, Hourly, Other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class M4(TimeSeriesDataclass):\n",
    "    \n",
    "    source_url = 'https://raw.githubusercontent.com/Mcompetitions/M4-methods/master/Dataset/'\n",
    "\n",
    "    @staticmethod\n",
    "    def load(directory: str,\n",
    "             group: str) -> Tuple[pd.DataFrame, \n",
    "                                  Optional[pd.DataFrame], \n",
    "                                  Optional[pd.DataFrame]]:\n",
    "        \"\"\"\n",
    "        Downloads and loads M4 data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'Yearly', 'Quarterly', 'Monthly', \n",
    "                            'Weekly', 'Daily', 'Hourly'.\n",
    "            \n",
    "        Notes\n",
    "        -----\n",
    "        [1] Returns train+test sets.\n",
    "        \"\"\"\n",
    "        if group == 'Other':\n",
    "            #Special case.\n",
    "            included_dfs = [M4.load(directory, gr) \\\n",
    "                            for gr in M4Info['Other'].included_groups]\n",
    "            df, *_ = zip(*included_dfs)\n",
    "            df = pd.concat(df)\n",
    "        else:\n",
    "            \n",
    "            M4.download(directory)\n",
    "            path = f'{directory}/m4/datasets'\n",
    "            class_group = M4Info[group]\n",
    "\n",
    "            def read_and_melt(file):\n",
    "                df = pd.read_csv(file)\n",
    "                df.columns = ['unique_id'] + list(range(1, df.shape[1]))\n",
    "                df = pd.melt(df, id_vars=['unique_id'], var_name='ds', value_name='y')\n",
    "                df = df.dropna()\n",
    "\n",
    "                return df\n",
    "\n",
    "            df_train = read_and_melt(file=f'{path}/{group}-train.csv')\n",
    "            df_test = read_and_melt(file=f'{path}/{group}-test.csv')\n",
    "\n",
    "            len_train = df_train.groupby('unique_id').agg({'ds': 'max'}).reset_index()\n",
    "            len_train.columns = ['unique_id', 'len_serie']\n",
    "            df_test = df_test.merge(len_train, on=['unique_id'])\n",
    "            df_test['ds'] = df_test['ds'] + df_test['len_serie']\n",
    "            df_test.drop('len_serie', axis=1, inplace=True)\n",
    "\n",
    "            df = pd.concat([df_train, df_test])\n",
    "            df = df.sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "            \n",
    "        return df, None, None\n",
    "\n",
    "    @staticmethod\n",
    "    def download(directory: str) -> None:\n",
    "        \"\"\"Download M4 Dataset.\"\"\"\n",
    "        path = f'{directory}/m4/datasets/'\n",
    "        if not os.path.exists(path):\n",
    "            for group in M4Info.groups:\n",
    "                download_file(path, f'{M4.source_url}/Train/{group}-train.csv')\n",
    "                download_file(path, f'{M4.source_url}/Test/{group}-test.csv')\n",
    "            download_file(path, f'{M4.source_url}/M4-info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25.4MiB [00:00, 44.0MiB/s]                  \n",
      "ERROR:nixtla.data.datasets.utils:ERROR, something went wrong downloading data\n",
      "INFO:nixtla.data.datasets.utils:Successfully downloaded Yearly-train.csv, 25355736, bytes.\n",
      "1.49MiB [00:00, 5.62MiB/s]                         \n",
      "ERROR:nixtla.data.datasets.utils:ERROR, something went wrong downloading data\n",
      "INFO:nixtla.data.datasets.utils:Successfully downloaded Yearly-test.csv, 1486434, bytes.\n",
      "38.8MiB [00:01, 37.3MiB/s]                           \n",
      "ERROR:nixtla.data.datasets.utils:ERROR, something went wrong downloading data\n",
      "INFO:nixtla.data.datasets.utils:Successfully downloaded Quarterly-train.csv, 38788547, bytes.\n",
      "1.97MiB [00:00, 10.8MiB/s]                 \n",
      "ERROR:nixtla.data.datasets.utils:ERROR, something went wrong downloading data\n",
      "INFO:nixtla.data.datasets.utils:Successfully downloaded Quarterly-test.csv, 1971754, bytes.\n",
      "91.7MiB [00:02, 34.3MiB/s]                           \n",
      "ERROR:nixtla.data.datasets.utils:ERROR, something went wrong downloading data\n",
      "INFO:nixtla.data.datasets.utils:Successfully downloaded Monthly-train.csv, 91655432, bytes.\n",
      "7.94MiB [00:00, 21.2MiB/s]                           \n",
      "ERROR:nixtla.data.datasets.utils:ERROR, something went wrong downloading data\n",
      "INFO:nixtla.data.datasets.utils:Successfully downloaded Monthly-test.csv, 7942698, bytes.\n",
      "4.02MiB [00:00, 17.3MiB/s]                  \n",
      "ERROR:nixtla.data.datasets.utils:ERROR, something went wrong downloading data\n",
      "INFO:nixtla.data.datasets.utils:Successfully downloaded Weekly-train.csv, 4015067, bytes.\n",
      "44.2kiB [00:00, 1.29MiB/s]                  \n",
      "ERROR:nixtla.data.datasets.utils:ERROR, something went wrong downloading data\n",
      "INFO:nixtla.data.datasets.utils:Successfully downloaded Weekly-test.csv, 44247, bytes.\n",
      "95.8MiB [00:02, 34.7MiB/s]                           \n",
      "ERROR:nixtla.data.datasets.utils:ERROR, something went wrong downloading data\n",
      "INFO:nixtla.data.datasets.utils:Successfully downloaded Daily-train.csv, 95765153, bytes.\n",
      "576kiB [00:00, 9.50MiB/s]                  \n",
      "ERROR:nixtla.data.datasets.utils:ERROR, something went wrong downloading data\n",
      "INFO:nixtla.data.datasets.utils:Successfully downloaded Daily-test.csv, 576459, bytes.\n",
      "2.35MiB [00:00, 19.3MiB/s]                 \n",
      "ERROR:nixtla.data.datasets.utils:ERROR, something went wrong downloading data\n",
      "INFO:nixtla.data.datasets.utils:Successfully downloaded Hourly-train.csv, 2347115, bytes.\n",
      "133kiB [00:00, 5.58MiB/s]                   \n",
      "ERROR:nixtla.data.datasets.utils:ERROR, something went wrong downloading data\n",
      "INFO:nixtla.data.datasets.utils:Successfully downloaded Hourly-test.csv, 132820, bytes.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.0/14.0 [00:00<00:00, 942iB/s]\n",
      "INFO:nixtla.data.datasets.utils:Successfully downloaded Other-train.csv, 14, bytes.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.0/14.0 [00:00<00:00, 891iB/s]\n",
      "INFO:nixtla.data.datasets.utils:Successfully downloaded Other-test.csv, 14, bytes.\n",
      "4.34MiB [00:00, 37.2MiB/s]                 \n",
      "ERROR:nixtla.data.datasets.utils:ERROR, something went wrong downloading data\n",
      "INFO:nixtla.data.datasets.utils:Successfully downloaded M4-info.csv, 4335598, bytes.\n"
     ]
    }
   ],
   "source": [
    "df, *_ = M4.load(directory='data', group='Hourly')\n",
    "\n",
    "# for group, meta in M4Info:\n",
    "#     df, *_ = M4.load(directory='data', group=group)\n",
    "#     n_series = len(np.unique(df.unique_id.values))\n",
    "    \n",
    "#     display_str  = f'Group: {group} '\n",
    "#     display_str += f'n_series: {n_series}'\n",
    "#     print(display_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nixtla",
   "language": "python",
   "name": "nixtla"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
