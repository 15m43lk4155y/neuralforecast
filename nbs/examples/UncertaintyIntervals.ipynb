{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14f5686c-449b-4376-8c58-fc8141f4b0f8",
   "metadata": {},
   "source": [
    "# Prediction Intervals\n",
    "\n",
    "> In this example we show how produce prediction intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e529c3-51a1-47b6-9260-fe0eca6403a5",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Nixtla/neuralforecast/blob/main/nbs/examples/UncertaintyIntervals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4191d2e-70a7-4045-a54f-3d3c1a5e303b",
   "metadata": {},
   "source": [
    "## Installing NeuralForecast Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267e20f4-d8c9-427b-a9de-794300aea841",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install neuralforecast matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf133494-b901-4537-a526-b03bd3cc523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS, NHITS\n",
    "from neuralforecast.losses.pytorch import MQLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3160b22b-c2ac-4320-9baa-8ea6fd207ea2",
   "metadata": {},
   "source": [
    "#### Useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed49d7d-d7e7-4828-bdd7-658ac351edb4",
   "metadata": {},
   "source": [
    "The `plot_grid` function defined below will be useful to plot different time series, and different models' forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66090288-ebc3-40c6-a235-919f4fcaeb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid(df_train, df_test=None, plot_random=True, model=None, level=None):\n",
    "    fig, axes = plt.subplots(4, 2, figsize = (24, 14))\n",
    "\n",
    "    unique_ids = df_train['unique_id'].unique()\n",
    "\n",
    "    assert len(unique_ids) >= 8, \"Must provide at least 8 ts\"\n",
    "    \n",
    "    if plot_random:\n",
    "        unique_ids = random.sample(list(unique_ids), k=8)\n",
    "    else:\n",
    "        unique_uids = unique_ids[:8]\n",
    "\n",
    "    for uid, (idx, idy) in zip(unique_ids, product(range(4), range(2))):\n",
    "        train_uid = df_train.query('unique_id == @uid')\n",
    "        axes[idx, idy].plot(train_uid['ds'], train_uid['y'], label = 'y_train')\n",
    "        if df_test is not None:\n",
    "            max_ds = train_uid['ds'].max()\n",
    "            test_uid = df_test.query('unique_id == @uid')\n",
    "            for col in ['y', f'{model}-median', 'y_test']:\n",
    "                if col in test_uid:\n",
    "                    axes[idx, idy].plot(test_uid['ds'], test_uid[col], label=col)\n",
    "            if level is not None:\n",
    "                for l, alpha in zip(sorted(level), [0.5, .4, .35, .2]):\n",
    "                    axes[idx, idy].fill_between(\n",
    "                        test_uid['ds'], \n",
    "                        test_uid[f'{model}-lo-{l}'], \n",
    "                        test_uid[f'{model}-hi-{l}'],\n",
    "                        alpha=alpha,\n",
    "                        color='orange',\n",
    "                        label=f'{model}_level_{l}',\n",
    "                    )\n",
    "        axes[idx, idy].set_title(f'M4 Hourly: {uid}')\n",
    "        axes[idx, idy].set_xlabel('Timestamp [t]')\n",
    "        axes[idx, idy].set_ylabel('Target')\n",
    "        axes[idx, idy].legend(loc='upper left')\n",
    "        axes[idx, idy].xaxis.set_major_locator(plt.MaxNLocator(20))\n",
    "        axes[idx, idy].grid()\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5074b19-d1d6-4fe8-9004-209eeecdb0fe",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467dadd2-8465-41ad-a37c-27c1b2e5eb3a",
   "metadata": {},
   "source": [
    "For testing purposes, we will use the Hourly dataset from the M4 competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e69ada-72dd-4212-a490-8af1fac2cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://auto-arima-results.s3.amazonaws.com/M4-Hourly.csv\n",
    "!wget https://auto-arima-results.s3.amazonaws.com/M4-Hourly-test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d247576-d44f-4753-b269-4e1a71d76806",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('M4-Hourly.csv')\n",
    "test = pd.read_csv('M4-Hourly-test.csv').rename(columns={'y': 'y_test'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2314de4f-4b9a-4578-992f-e279c9fed90c",
   "metadata": {},
   "source": [
    "In this example we will use a subset of the data to avoid waiting too long. You can modify the number of series if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373cbfab-3d43-4cd0-9aac-5f502b538123",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_series = 8\n",
    "uids = train['unique_id'].unique()[:n_series]\n",
    "train = train.query('unique_id in @uids')\n",
    "test = test.query('unique_id in @uids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5dd785-c3b8-42e4-9f51-ad5ba8e22ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a276a735-ff95-4aaf-9548-ef7848cfadcd",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd26217-cac6-4460-a1c6-43da680ce25f",
   "metadata": {},
   "source": [
    "`NeuralForecast` receives a list of models to fit each time series. We can define the level of the forecast intervals we want to produce using the multiquantile loss (`MQLoss`). `NeuralForecast` will produce these levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d83fada-203f-41e9-88ad-ddcf7608ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 48\n",
    "levels = [80, 90, 95, 99]\n",
    "models = [\n",
    "    NBEATS(input_size=3 * horizon, h=horizon, loss=MQLoss(level=levels), max_epochs=100),\n",
    "    NHITS(input_size=3 * horizon, h=horizon, loss=MQLoss(level=levels), max_epochs=100),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c491f988-9c50-435f-ba1c-1c3887821f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = NeuralForecast(models=models, freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54734ee3-0020-45a1-9dec-29d004fadf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fcst.fit(df=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fcfafa-93d6-4f6f-accd-57c1f84317b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = fcst.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39add83-4b8d-4c9d-a053-6656999d33e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = forecasts.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1022ecc7-97e7-4d31-9175-a8d7a1a06d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f24fabf-3700-484c-8ac4-03f1353529cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(forecasts, how='left', on=['unique_id', 'ds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ef378e-9ead-4959-895f-a7e7e14c0d6a",
   "metadata": {},
   "source": [
    "## Plot prediction intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcdd82a-0122-4d33-b589-23722fde70ba",
   "metadata": {},
   "source": [
    "Then we can plot the prediction intervals for each model as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2ebbe0-36f9-47bd-a6d9-6e48f9fae9c4",
   "metadata": {},
   "source": [
    "### NBEATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8155b2c0-f411-421f-afeb-a54aa53d81e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(train, test, level=levels, model='NBEATS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405e24f7-4bb7-4645-ad10-ce8f6b0c8fd2",
   "metadata": {},
   "source": [
    "### NHITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e60a00f-3b1c-438a-a961-07a63c667732",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(train, test, level=levels, model='NHITS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb637d8d-2823-4a03-85f8-221636861d2e",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Nixtla/statsforecast/blob/main/nbs/examples/UncertaintyIntervals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782c5212-447e-4b93-980a-472494db59e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
