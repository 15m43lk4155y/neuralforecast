{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp losses.gw_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Giacomini-White Test\n",
    "\n",
    "Test on out-of-sample conditional predictive ability.\n",
    "\n",
    "References:\n",
    "- Giacomini, R., & White, H. (2006). Tests of conditional predictive ability. Econometrica, 74(6), 1545-1578.\n",
    "- https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0262.2006.00718.x\n",
    "- http://www.runmycode.org/companion/view/88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "from scipy.stats.distributions import chi2\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from matplotlib import rcParams\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "FONTSIZE = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _Newey_West(Z: np.ndarray, n_lags: int) -> np.ndarray:\n",
    "    \"\"\" \n",
    "    \n",
    "    Estimator of the Newey-West Heteroskedasticity and \n",
    "    Autocorrelation Consistent Covariance Matrix (Newey-West HAC) \n",
    "    to calculate robust error estimations.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        Z: (n, k) ndarray\n",
    "        n_lags: int\n",
    "            number of lags to consider as available information.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        omega_hat: Newey-West HAC estimator of the covariance matrix\n",
    "    \"\"\"\n",
    "\n",
    "    assert n_lags > 0\n",
    "\n",
    "    n, k = Z.shape\n",
    "\n",
    "    Z = Z - np.ones((n, 1)) * np.mean(Z, axis=0)\n",
    "    gamma = -999 * np.ones((n_lags, k))\n",
    "    omega_hat = (1/n) * np.matmul(np.transpose(Z), Z)\n",
    "\n",
    "    Zlag = np.array([np.pad(Z, ((i,0), (0,0)), mode='constant', \n",
    "                            constant_values = 0)[:n] \n",
    "                     for i in range(1, n_lags + 1)])\n",
    "    gamma = (1/n) * (np.matmul(np.transpose(Z), Zlag) + \n",
    "            np.matmul(np.einsum('ijk -> ikj', Zlag), Z))\n",
    "    weights = 1 - np.array(range(1,n_lags + 1))/(n_lags + 1)\n",
    "    omega_hat = omega_hat + \\\n",
    "                np.sum(gamma * np.expand_dims(weights, \n",
    "                                              axis = (1,2)), \n",
    "                                              axis = 0)\n",
    "    return omega_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giacomini-White Conditional Predictive Ability Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def GW_CPA_test(loss1: np.ndarray, \n",
    "                loss2: np.ndarray, \n",
    "                tau: int,\n",
    "                alpha: float=0.05,\n",
    "                conditional: bool=False,\n",
    "                verbose: bool=True) -> Tuple[np.ndarray, np.float64, np.ndarray]:\n",
    "    \"\"\" \n",
    "    \n",
    "    The one-sided Giacomini-White Conditional Predictive Ability Test (GW),\n",
    "    allows to assess which model provides better predictions.\n",
    "    \n",
    "    The GW test examines the null hypothesis of equal forecast errors\n",
    "    for a pair of models's predictions $\\hat{\\mathbf{y}}^{A}_{\\\\tau}$ and \n",
    "    $\\hat{\\mathbf{y}}^{B}_{\\\\tau}$ measured by the MAE or L1 norm,\n",
    "    conditioned on the available information to that moment $\\mathcal{F}_{\\\\tau-1}$.\n",
    "\n",
    "    \n",
    "    $$ \\Delta^{A,B}_{\\\\tau} = ||\\mathbf{y}_{\\\\tau} - \\hat{\\mathbf{y}}^{A}_{\\\\tau}||_{1} \n",
    "        - ||\\mathbf{y}_{\\\\tau} - \\hat{\\mathbf{y}}^{B}_{\\\\tau}||_{1} $$\n",
    "        \n",
    "    In practice, the $ \\mathcal{F}_{\\\\tau-1} $ is replaced with a constant and \n",
    "    lags of the error difference \n",
    "    $ \\mathcal{F}_{\\\\tau-1} = [\\\\mathbb{1} \\;|\\; \\Delta^{A,B}_{\\\\tau - 1} ] $ \n",
    "    and the test is performed using a linear regression with a Wald-like test.        \n",
    "    \n",
    "    $$ \\Delta^{A,B}_{\\\\tau} = \n",
    "       \\\\boldsymbol{\\\\beta}^{\\intercal} \\mathcal{F}_{\\\\tau-1} + \\\\epsilon_{\\\\tau} $$\n",
    "       \n",
    "    $$ H_{0}: \\\\mathbb{E} \\\\left[ \\Delta^{A,B}_{\\\\tau} \\;|\\; \\mathcal{F}_{\\\\tau-1} \\\\right] \n",
    "       \\equiv \\\\mathbb{E} \\\\left[ \\\\boldsymbol{\\\\beta} \\;|\\; \\mathcal{F}_{\\\\tau-1} \\\\right] = \\\\mathbb{0}  $$       \n",
    "    \n",
    "    The Diebold-Mariano test widely used in the forecasting literature,\n",
    "    can be easily recovered by setting, when the conditional information considered \n",
    "    is only the constant variable, one recovers the original DB test.\n",
    "    Compared with the DM or other unconditional tests, \n",
    "    the GW test is valid under general assumptions such as heterogeneity \n",
    "    rather than stationarity of data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        loss1: \n",
    "            numpy array. losses of model 1\n",
    "        loss2: \n",
    "            numpy array. losses of model 2\n",
    "        tau: int\n",
    "            the past information treated as 'available' for the test.\n",
    "        alpha: float \n",
    "            level of significance for the test.\n",
    "        conditional: boolean. \n",
    "            True if conditional (DM test), False if unconditional (GW test).\n",
    "        verbose: boolean. \n",
    "            True if prints of test are needed.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        test_stat: test statistic of the conditional predictive ability test\n",
    "        crit_val: critical value of the chi-square test for a 5% confidence level\n",
    "        p-vals: (k,) p-value of the test\n",
    "        \n",
    "        References\n",
    "        ----------\n",
    "        [1] Giacomini, R., & White, H., Tests of conditional predictive ability. Econometrica, 74 \n",
    "        URL: https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0262.2006.00718.\n",
    "        \n",
    "        [2] Diebold, F., & Mariano, R. (2002). Comparing predictive accuracy. \n",
    "        Journal of Business & Economic Statistics, 20 , 134â€“44. \n",
    "        URL: https://www.sas.upenn.edu/~fdiebold/papers/paper68/pa.dm.pdf.\n",
    "    \n",
    "    \"\"\"   \n",
    "\n",
    "    assert len(loss1) == len(loss2)\n",
    "\n",
    "    lossdiff = loss1 - loss2\n",
    "    t = len(loss1)\n",
    "    instruments = np.ones_like(loss1)\n",
    "\n",
    "    if conditional:\n",
    "        instruments = np.hstack((instruments[:t-tau], \n",
    "                                 lossdiff[:-tau]))\n",
    "        lossdiff = lossdiff[tau:]\n",
    "        t = t - tau\n",
    "\n",
    "    reg = instruments * lossdiff\n",
    "    \n",
    "    if tau == 1:\n",
    "\n",
    "        res_beta = np.linalg.lstsq(reg, np.ones((t)), rcond=None)[0]\n",
    "\n",
    "        err = np.ones((t,1)) - reg.dot(res_beta)\n",
    "        r2 = 1 - np.mean(err**2)\n",
    "        test_stat = t * r2\n",
    "    \n",
    "    else:\n",
    "\n",
    "        zbar = np.mean(reg, axis=0)\n",
    "        n_lags = tau - 1\n",
    "        omega = _Newey_West(Z=reg, n_lags=n_lags)\n",
    "        test_stat = np.expand_dims(t*zbar, \n",
    "                                   axis=0).dot(np.linalg.inv(omega)).\\\n",
    "                                   dot(zbar)\n",
    "    \n",
    "    test_stat *= np.sign(np.mean(lossdiff))\n",
    "    \n",
    "    q = reg.shape[1]\n",
    "    crit_val = chi2.ppf(1-alpha, df=q)\n",
    "    p_val = 1 - chi2.cdf(test_stat, q)\n",
    "\n",
    "    av_diff_loss = np.mean(loss1-loss2)\n",
    "    s = '+' if np.mean(loss1-loss2) > 0 else '-'\n",
    "    \n",
    "    if verbose:\n",
    "        if conditional: print('\\nGW Conditional test:\\n')\n",
    "        if not conditional: print('\\nUnconditional test:\\n')\n",
    "        print(f'Forecast horizon: {tau}, Nominal Risk Level: {alpha}')\n",
    "        print(f'Test-statistic: {test_stat} ({s})')\n",
    "        print(f'Critical value: {crit_val}')\n",
    "        print(f'p-value: {p_val}\\n')\n",
    "    \n",
    "    return test_stat, crit_val, p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_input\n",
    "from scipy.stats import chi2\n",
    "\n",
    "fig = plt.figure(figsize=[8, 4])\n",
    "\n",
    "#plot Chi-square distribution with 4 degrees of freedom\n",
    "x = np.arange(0, 20, 0.001)\n",
    "alpha = float=0.05\n",
    "crit_val = chi2.ppf(1-alpha, df=4)\n",
    "plt.plot(x, chi2.pdf(x, df=4), color=\"#78ACA8\", linewidth=2.)\n",
    "\n",
    "plt.rc('axes', labelsize=14)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=14)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=14)    # fontsize of the tick labels\n",
    "plt.rc('axes', titlesize=16)  # fontsize of the figure title\n",
    "\n",
    "# Plot rejection area\n",
    "plt.vlines(crit_val, ymin=-0.001, ymax=0.15, color=\"#20425B\", alpha=0.8)\n",
    "plt.text(x=9.8, y=0.14, s=\"Critical Value\", fontsize=14)\n",
    "\n",
    "section = np.arange(crit_val, 20, 0.001)\n",
    "plt.fill_between(section, chi2.pdf(section, df=4), \n",
    "                 color=\"#9C9DB2\", alpha=0.5)\n",
    "\n",
    "# Test statistic, missing p-value\n",
    "plt.vlines(crit_val+2, ymin=-0.001, ymax=0.10, color=\"#20425B\", alpha=0.8)\n",
    "plt.text(x=11.8, y=0.09, s=\"Test Statistic\", fontsize=14)\n",
    "\n",
    "section = np.arange(crit_val+2, 20, 0.001)\n",
    "plt.fill_between(section, chi2.pdf(section, df=4),\n",
    "                 color=\"#7b3841\", alpha=0.5, label='p-value')\n",
    "\n",
    "plt.ylabel(\"Null Distribution\", fontsize=21)\n",
    "plt.xlabel(\"Giacomini-White Test\", fontsize=21)\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giacomini-White Conditional p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_GW_test_pvals(y: np.ndarray,\n",
    "                  y_hat: np.ndarray,\n",
    "                  horizon: int,\n",
    "                  tau: int,                \n",
    "                  conditional: bool,\n",
    "                  alpha: float =0.05,\n",
    "                  verbose: bool=False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    \n",
    "    Function to calculate model-pair-wise GW-Test p-values.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        y: numpy array\n",
    "            flat array with actual test values\n",
    "        y_hat: numpy array\n",
    "            matrix with predicted values\n",
    "        horizon: int\n",
    "            the multi horizon for which the predictions were created, \n",
    "            the test is performed against over the mean differences \n",
    "            in said multi horizon losses.\n",
    "        tau: int\n",
    "            the past information treated as 'available' for the test.\n",
    "        conditional: boolean, \n",
    "            True if conditional (DM test), False if unconditional (GW test).\n",
    "        alpha: float \n",
    "            level of significance for the test.\n",
    "        verbose: boolean.\n",
    "            True for partial test results.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        p_vals: (n_models, n_models) \n",
    "                symmetric numpy array with the model-pair-wise p-values.\n",
    "    \n",
    "    \"\"\"\n",
    "    # number of date stamps and de facto forecast creation dates\n",
    "    y_hat = y_hat.T # transpose for good reshape indexes\n",
    "    n_models, n_ds = y_hat.shape\n",
    "    n_fcds = n_ds // horizon\n",
    "\n",
    "    # multi horizon losses\n",
    "    losses = np.abs(y - y_hat)\n",
    "    losses = losses.reshape(n_models, n_fcds, horizon)\n",
    "    losses = np.mean(losses, axis=2)\n",
    "\n",
    "    pvals = np.zeros((n_models, n_models))\n",
    "\n",
    "    for i in range(n_models):\n",
    "        for j in range(n_models):\n",
    "            loss1 = losses[[i], :]\n",
    "            loss2 = losses[[j], :]\n",
    "            _, _, p_val = GW_CPA_test(loss1=loss1.reshape(n_fcds, -1),\n",
    "                                      loss2=loss2.reshape(n_fcds, -1),\n",
    "                                      tau=1,\n",
    "                                      alpha=alpha,\n",
    "                                      conditional=conditional,\n",
    "                                      verbose=verbose)\n",
    "\n",
    "            pvals[i,j] = p_val\n",
    "\n",
    "    return pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_nbeatsx_cmap() -> ListedColormap:\n",
    "    cmap = cm.get_cmap('pink', 512)\n",
    "    yellows = cmap(np.linspace(0.5, 0.95, 256))\n",
    "\n",
    "    cmap = cm.get_cmap('Blues', 256)\n",
    "    blues = cmap(np.linspace(0.45, 0.75, 256))\n",
    "\n",
    "    newcolors = np.concatenate([yellows, blues])\n",
    "\n",
    "    #extra = np.array([116/256, 142/256, 157/256, 1])\n",
    "    extra = np.array([66/256, 75/256, 98/256, 1])\n",
    "    #extra = np.array([3/256, 34/256, 71/256, 1])\n",
    "    newcolors[-10:, :] = extra\n",
    "    newcmap = ListedColormap(newcolors)\n",
    "    return newcmap\n",
    "\n",
    "def _get_epftoolbox_cmap() -> ListedColormap:\n",
    "    cmap = cm.get_cmap('YlGn_r', 512)\n",
    "    yellows = cmap(np.linspace(0.6, 1.0, 256))\n",
    "\n",
    "    cmap = cm.get_cmap('gist_heat_r', 256)\n",
    "    reds = cmap(np.linspace(0.39, 0.66, 256))\n",
    "\n",
    "    newcolors = np.concatenate([yellows, reds])\n",
    "\n",
    "    #extra = np.array([116/256, 142/256, 157/256, 1])\n",
    "    #extra = np.array([66/256, 75/256, 98/256, 1])\n",
    "    #extra = np.array([3/256, 34/256, 71/256, 1])\n",
    "    extra = np.array([0, 0, 0, 1])\n",
    "    newcolors[-10:, :] = extra\n",
    "    newcmap = ListedColormap(newcolors)\n",
    "    return newcmap\n",
    "\n",
    "def plot_GW_test_pvals(pvals: np.ndarray, labels: List[str], title: str) -> None:\n",
    "    \"\"\"\n",
    "    \n",
    "    Function to plot model-pair-wise GW-Test p-values.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        p_vals: (n_models, n_models) \n",
    "            symmetric numpy array with the model-pair-wise p-values.\n",
    "        labels: string list\n",
    "            list of model names\n",
    "        title: string\n",
    "            title of the plot\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(pvals)==len(labels), 'Wrong pvals and labels dimensions.'\n",
    "\n",
    "    #plt.rc('text', usetex=True)\n",
    "    plt.rc('axes', labelsize=14)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=14)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=14)    # fontsize of the tick labels\n",
    "    plt.rc('axes', titlesize=16)  # fontsize of the figure title\n",
    "\n",
    "    fig = plt.figure(figsize=[6, 6])\n",
    "    ax = plt.axes([.27, .22, .7, .7])\n",
    "\n",
    "    data = np.float32(pvals)\n",
    "\n",
    "    # Colormap with discontinuous limit\n",
    "    #cmap = cm.get_cmap('GnBu', 256)\n",
    "    #cmap = _get_nbeatsx_cmap()\n",
    "    cmap = _get_epftoolbox_cmap()\n",
    "    mappable = plt.imshow(data, cmap=cmap, vmin=0, vmax=0.1)\n",
    "\n",
    "    ticklabels = labels #[r'$\\textrm{' + e + '}$' for e in labels]\n",
    "    plt.xticks(range(len(labels)), ticklabels, rotation=90., fontsize=FONTSIZE)\n",
    "    plt.yticks(range(len(labels)), ticklabels, fontsize=FONTSIZE)\n",
    "\n",
    "    plt.plot(list(range(len(labels))), \n",
    "             list(range(len(labels))), 'wx', markersize=FONTSIZE)\n",
    "    plt.title(f'{title}', fontweight='bold', fontsize=FONTSIZE)\n",
    "\n",
    "    # Turn spines off and create black grid.\n",
    "    for edge, spine in ax.spines.items():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"k\", linestyle='-', linewidth=1.5)\n",
    "\n",
    "    # Colorbar\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    plt.colorbar(mappable, cax=cax)\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    title = title.replace(\" \", \"_\")\n",
    "    title = title.replace(\",\", \"\")\n",
    "    title = title.replace(\"(\", \"\")\n",
    "    title = title.replace(\")\", \"\")\n",
    "    plt.savefig(f'./results/pvals_{title}.pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. GW with ModelB prefered to ModelA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossA = np.random.randint(low=1, high=10, size=(11,1))\n",
    "lossB = lossA.copy() - lossA/10\n",
    "\n",
    "plt.plot(lossA, label='Model A', color=\"#78ACA8\")\n",
    "plt.plot(lossB, label='Model B', color=\"#E3A39A\")\n",
    "plt.ylabel('Errors')\n",
    "plt.xlabel('Time')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "test_stat, crit_val, p_val = GW_CPA_test(loss1=lossA, loss2=lossB, tau=2, conditional=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. GW with ModelA prefered to ModelB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossA = np.random.randint(low=1, high=10, size=(11,1))\n",
    "lossB = lossA.copy() + lossA/10\n",
    "\n",
    "plt.plot(lossA, label='Model A', color=\"#78ACA8\")\n",
    "plt.plot(lossB, label='Model B', color=\"#E3A39A\")\n",
    "plt.ylabel('Errors')\n",
    "plt.xlabel('Time')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "test_stat, crit_val, p_val = GW_CPA_test(loss1=lossA, loss2=lossB, tau=2, conditional=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. GW pairwise models' comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_input\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed values for 3 different days\n",
    "y = np.random.randint(low=1, high=10, size=(100*24)) \n",
    "\n",
    "# Five different models with augmenting error variance\n",
    "eps0 = np.random.normal(loc=0.0, scale=1, size=(100*24,))\n",
    "eps1 = np.random.normal(loc=0.0, scale=2, size=(100*24,))\n",
    "eps2 = np.random.normal(loc=0.0, scale=3, size=(100*24,))\n",
    "eps3 = np.random.normal(loc=0.0, scale=3, size=(100*24,))\n",
    "eps4 = np.random.normal(loc=0.0, scale=3, size=(100*24,))\n",
    "\n",
    "y_hat = np.repeat(y[:,None], repeats=5, axis=1)\n",
    "y_hat[:,0] = y_hat[:,0] + eps0\n",
    "y_hat[:,1] = y_hat[:,1] + eps1\n",
    "y_hat[:,2] = y_hat[:,2] + eps2\n",
    "y_hat[:,3] = y_hat[:,3] + eps3\n",
    "y_hat[:,4] = y_hat[:,4] + eps4\n",
    "\n",
    "model_names = ['Model1', 'Model2', 'Model3', 'Model4', 'Model5']\n",
    "pvals = get_GW_test_pvals(y=y, y_hat=y_hat, horizon=24, tau=1,\n",
    "                          conditional=True, alpha=0.05, verbose=False)\n",
    "\n",
    "print(\"Model 1 is prefered over all the other models\")\n",
    "print(\"Model 5 is non-significantly prefered over Model 4\")\n",
    "plot_GW_test_pvals(pvals=pvals, labels=model_names, title='GW_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
