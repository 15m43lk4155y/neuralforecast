{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.tft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Fusion Transformers\n",
    "\n",
    "> In summary Temporal Fusion Transformer (TFT) combines gating layers, an LSTM recurrent encoder, with multi-head attention layers for a multi-step forecasting strategy decoder.<br>TFT's inputs are static exogenous $\\mathbf{x}^{(s)}$, historic exogenous $\\mathbf{x}^{(h)}_{[:t]}$, exogenous available at the time of the prediction $\\mathbf{x}^{(f)}_{[:t+H]}$ and autorregresive features $\\mathbf{y}_{[:t]}$, each of these inputs is further decomposed into categorical and continuous. The network uses a multi-quantile regression to model the following conditional probability:$$\\mathbb{P}(\\mathbf{y}_{[t+1:t+H]}|\\;\\mathbf{y}_{[:t]},\\; \\mathbf{x}^{(h)}_{[:t]},\\; \\mathbf{x}^{(f)}_{[:t+H]},\\; \\mathbf{x}^{(s)})$$<br><br>**References**<br>- [Jan Golda, Krzysztof Kudrynski. \"NVIDIA, Deep Learning Forecasting Examples\"](https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Forecasting/TFT)<br>- [Bryan Lim, Sercan O. Arik, Nicolas Loeff, Tomas Pfister, \"Temporal Fusion Transformers for interpretable multi-horizon time series forecasting\"](https://www.sciencedirect.com/science/article/pii/S0169207021000637)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 1. Temporal Fusion Transformer Architecture.](imgs_models/tft_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn import LayerNorm\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from typing import Tuple, Optional, Iterable, Any\n",
    "\n",
    "from neuralforecast.losses.pytorch import MAE\n",
    "from neuralforecast.common._base_windows import BaseWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_eq\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Auxiliary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Gating Mechanisms\n",
    "\n",
    "The Gated Residual Network (GRN) provides adaptive depth and network complexity capable of accommodating different size datasets. As residual connections allow for the network to skip the non-linear transformation of input $\\mathbf{a}$ and context $\\mathbf{c}$.\n",
    "\n",
    "\\begin{align}\n",
    "\\eta_{1} &= \\mathrm{ELU}(\\mathbf{W}_{1}\\mathbf{a}+\\mathbf{W}_{2}\\mathbf{c}+\\mathbf{b}_{1}) \\\\\n",
    "\\eta_{2} &= \\mathbf{W}_{2}\\eta_{1}+b_{2} \\\\\n",
    "\\mathrm{GRN}(\\mathbf{a}, \\mathbf{c}) &= \\mathrm{LayerNorm}(a + \\textrm{GLU}(\\eta_{2}))\n",
    "\\end{align}\n",
    "\n",
    "The Gated Linear Unit (GLU) provides the flexibility of supressing unnecesary parts of the GRN. Consider GRN's output $\\gamma$ then GLU transformation is defined by:\n",
    "\n",
    "$$\\mathrm{GLU}(\\gamma) = \\sigma(\\mathbf{W}_{4}\\gamma +b_{4}) \\odot (\\mathbf{W}_{5}\\gamma +b_{5})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 2. Gated Residual Network.](imgs_models/tft_grn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class MaybeLayerNorm(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size, eps):\n",
    "        super().__init__()\n",
    "        if output_size and output_size == 1:\n",
    "            self.ln = nn.Identity()\n",
    "        else:\n",
    "            self.ln = LayerNorm(output_size if output_size else hidden_size,\n",
    "                                eps=eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ln(x)\n",
    "\n",
    "class GLU(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(hidden_size, output_size * 2)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.lin(x)\n",
    "        x = F.glu(x)\n",
    "        return x\n",
    "\n",
    "class GRN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size, \n",
    "                 output_size=None,\n",
    "                 context_hidden_size=None,\n",
    "                 dropout=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_norm = MaybeLayerNorm(output_size, hidden_size, eps=1e-3)\n",
    "        self.lin_a = nn.Linear(input_size, hidden_size)\n",
    "        if context_hidden_size is not None:\n",
    "            self.lin_c = nn.Linear(context_hidden_size, hidden_size, bias=False)\n",
    "        self.lin_i = nn.Linear(hidden_size, hidden_size)\n",
    "        self.glu = GLU(hidden_size, output_size if output_size else hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out_proj = nn.Linear(input_size, output_size) if output_size else None\n",
    "\n",
    "    def forward(self, a: Tensor, c: Optional[Tensor] = None):\n",
    "        x = self.lin_a(a)\n",
    "        if c is not None:\n",
    "            x = x + self.lin_c(c).unsqueeze(1)\n",
    "        x = F.elu(x)\n",
    "        x = self.lin_i(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.glu(x)\n",
    "        y = a if not self.out_proj else self.out_proj(a)\n",
    "        x = x + y\n",
    "        x = self.layer_norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Variable Selection Networks\n",
    "\n",
    "TFT includes automated variable selection capabilities, through its variable selection network (VSN) components. The VSN takes the original input $\\{\\mathbf{x}^{(s)}, \\mathbf{x}^{(h)}_{[:t]}, \\mathbf{x}^{(f)}_{[:t]}\\}$ and transforms it through categorical embeddings or linear transformations into a high dimensional space\n",
    "$\\{\\mathbf{E}^{(s)}, \\mathbf{E}^{(h)}_{[:t]}, \\mathbf{E}^{(f)}_{[:t+H]}\\}$. \n",
    "\n",
    "For the observed historic data, the embedding matrix $\\mathbf{E}^{(h)}_{t}$ at time $t$ is a concatenation of $j$ variable $e^{(h)}_{t,j}$ embeddings:\n",
    "\\begin{align}\n",
    "\\mathbf{E}^{(h)}_{t} &= [e^{(h)}_{t,1},\\dots,e^{(h)}_{t,j},\\dots,e^{(h)}_{t,n_{h}}] \\\\\n",
    "\\mathbf{\\tilde{e}}^{(h)}_{t,j} &= \\mathrm{GRN}(e^{(h)}_{t,j})\n",
    "\\end{align}\n",
    "\n",
    "The variable selection weights are given by:\n",
    "$$s^{(h)}_{t}=\\mathrm{SoftMax}(\\mathrm{GRN}(\\mathbf{E}^{(h)}_{t},\\mathbf{E}^{(s)}))$$\n",
    "\n",
    "The VSN processed features are then:\n",
    "$$\\tilde{\\mathbf{E}}^{(h)}_{t}= \\sum_{j} s^{(h)}_{j} \\tilde{e}^{(h)}_{t,j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 3. Variable Selection Network.](imgs_models/tft_vsn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class TFTEmbedding(nn.Module):\n",
    "    def __init__(self, hidden_size,\n",
    "                 s_cat_inp_lens, s_cont_inp_size,\n",
    "                 k_cat_inp_lens, k_cont_inp_size,\n",
    "                 o_cat_inp_lens, o_cont_inp_size,\n",
    "                 tgt_size):\n",
    "        super().__init__()\n",
    "        # There are 7 types of input:\n",
    "        # 1. Static categorical\n",
    "        # 2. Static continuous\n",
    "        # 3. Temporal known a priori categorical\n",
    "        # 4. Temporal known a priori continuous\n",
    "        # 5. Temporal observed categorical\n",
    "        # 6. Temporal observed continuous\n",
    "        # 7. Temporal observed targets (time series obseved so far)\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.s_cat_inp_lens  = s_cat_inp_lens\n",
    "        self.s_cont_inp_size = s_cont_inp_size\n",
    "        self.k_cat_inp_lens  = k_cat_inp_lens\n",
    "        self.k_cont_inp_size = k_cont_inp_size\n",
    "        self.o_cat_inp_lens  = o_cat_inp_lens\n",
    "        self.o_cont_inp_size = o_cont_inp_size\n",
    "        self.tgt_size        = tgt_size\n",
    "\n",
    "        # Instantiate Categorical Embeddings if lens is not None\n",
    "        for attr, lens in [('s_cat_embed', s_cat_inp_lens), \n",
    "                           ('k_cat_embed', k_cat_inp_lens),\n",
    "                           ('o_cat_embed', o_cat_inp_lens)]:\n",
    "            if lens:\n",
    "                embed = nn.ModuleList([nn.Embedding(n, hidden_size) for n in lens])\n",
    "                setattr(self, attr, embed)\n",
    "            else:\n",
    "                setattr(self, attr, None)\n",
    "\n",
    "        # Instantiate Continuous Embeddings if size is not None\n",
    "        for attr, size in [('s_cont_embedding', s_cont_inp_size), \n",
    "                           ('k_cont_embedding', k_cont_inp_size),\n",
    "                           ('o_cont_embedding', o_cont_inp_size),\n",
    "                           ('tgt_embedding', tgt_size)]:\n",
    "            if size:\n",
    "                vectors = nn.Parameter(torch.Tensor(size, hidden_size))\n",
    "                bias = nn.Parameter(torch.zeros(size, hidden_size))\n",
    "                torch.nn.init.xavier_normal_(vectors)\n",
    "                setattr(self, attr+'_vectors', vectors)\n",
    "                setattr(self, attr+'_bias', bias)\n",
    "            else:\n",
    "                setattr(self, attr+'_vectors', None)\n",
    "                setattr(self, attr+'_bias', None)\n",
    "\n",
    "    def _apply_embedding(self,\n",
    "                         cat: Optional[Tensor],\n",
    "                         cont: Optional[Tensor],\n",
    "                         cat_emb: Iterable[Any], \n",
    "                         cont_emb: Tensor,\n",
    "                         cont_bias: Tensor,\n",
    "                         ):\n",
    "\n",
    "        if (cat is None) and (cont is None):\n",
    "            return None\n",
    "\n",
    "        if (cat is not None):\n",
    "            e_cat = torch.stack([embed(cat[...,i]) \\\n",
    "                               for i, embed in enumerate(cat_emb)], dim=-2)\n",
    "        if (cont is not None):\n",
    "            #the line below is equivalent to following einsums\n",
    "            #e_cont = torch.einsum('btf,fh->bthf', cont, cont_emb)\n",
    "            #e_cont = torch.einsum('bf,fh->bhf', cont, cont_emb)          \n",
    "            e_cont = torch.mul(cont.unsqueeze(-1), cont_emb)\n",
    "            e_cont = e_cont + cont_bias\n",
    "\n",
    "        if (cat is not None) and (cont is None):\n",
    "            return e_cat\n",
    "\n",
    "        if (cat is None) and (cont is not None):\n",
    "            return e_cont\n",
    "\n",
    "        if (cat is not None) and (cont is not None):\n",
    "            return torch.cat([e_cat, e_cont], dim=-2)\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def forward(self, target_inp, s_cat_inp=None, s_cont_inp=None, k_cat_inp=None, k_cont_inp=None, o_cat_inp=None, o_cont_inp=None):\n",
    "        # temporal/static categorical/continuous known/observed input \n",
    "        # tries to get input, if fails returns None\n",
    "\n",
    "        # Static inputs are expected to be equal for all timesteps\n",
    "        # For memory efficiency there is no assert statement\n",
    "        s_cat_inp = s_cat_inp[:,0,:] if s_cat_inp is not None else None\n",
    "        s_cont_inp = s_cont_inp[:,0,:] if s_cont_inp is not None else None\n",
    "\n",
    "        s_inp = self._apply_embedding(s_cat_inp, s_cont_inp,\n",
    "                                      cat_emb=self.s_cat_embed,\n",
    "                                      cont_emb=self.s_cont_embedding_vectors,\n",
    "                                      cont_bias=self.s_cont_embedding_bias)\n",
    "        k_inp = self._apply_embedding(k_cat_inp, k_cont_inp,\n",
    "                                      cat_emb=self.k_cat_embed,\n",
    "                                      cont_emb=self.k_cont_embedding_vectors,\n",
    "                                      cont_bias=self.k_cont_embedding_bias)\n",
    "        o_inp = self._apply_embedding(o_cat_inp, o_cont_inp,\n",
    "                                      cat_emb=self.o_cat_embed,\n",
    "                                      cont_emb=self.o_cont_embedding_vectors,\n",
    "                                      cont_bias=self.o_cont_embedding_bias)\n",
    "\n",
    "        # Temporal observed targets\n",
    "        # t_observed_tgt = torch.einsum('btf,fh->btfh', \n",
    "        #                               target_inp, self.tgt_embedding_vectors)        \n",
    "        target_inp = torch.matmul(target_inp.unsqueeze(3).unsqueeze(4),\n",
    "                          self.tgt_embedding_vectors.unsqueeze(1)).squeeze(3)\n",
    "        target_inp = target_inp + self.tgt_embedding_bias\n",
    "\n",
    "        return s_inp, k_inp, o_inp, target_inp\n",
    "\n",
    "class VariableSelectionNetwork(nn.Module):\n",
    "    def __init__(self, hidden_size, num_inputs, dropout):\n",
    "        super().__init__()\n",
    "        self.joint_grn = GRN(input_size=hidden_size*num_inputs, \n",
    "                             hidden_size=hidden_size, \n",
    "                             output_size=num_inputs, \n",
    "                             context_hidden_size=hidden_size)\n",
    "        self.var_grns = nn.ModuleList(\n",
    "                        [GRN(input_size=hidden_size, \n",
    "                             hidden_size=hidden_size, dropout=dropout)\n",
    "                         for _ in range(num_inputs)])\n",
    "\n",
    "    def forward(self, x: Tensor, context: Optional[Tensor] = None):\n",
    "        Xi = x.reshape(*x.shape[:-2], -1)\n",
    "        grn_outputs = self.joint_grn(Xi, c=context)\n",
    "        sparse_weights = F.softmax(grn_outputs, dim=-1)\n",
    "        transformed_embed_list = [m(x[...,i,:])\n",
    "                                     for i, m in enumerate(self.var_grns)]\n",
    "        transformed_embed = torch.stack(transformed_embed_list, dim=-1)\n",
    "        #the line below performs batched matrix vector multiplication\n",
    "        #for temporal features it's bthf,btf->bth\n",
    "        #for static features it's bhf,bf->bh\n",
    "        variable_ctx = torch.matmul(transformed_embed, \n",
    "                                    sparse_weights.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        return variable_ctx, sparse_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Multi-Head Attention\n",
    "\n",
    "To avoid information bottlenecks from the classic Seq2Seq architecture, TFT \n",
    "incorporates a decoder-encoder attention mechanism inherited transformer architectures ([Li et. al 2019](https://arxiv.org/abs/1907.00235), [Vaswani et. al 2017](https://arxiv.org/abs/1706.03762)). It transform the the outputs of the LSTM encoded temporal features, and helps the decoder better capture long-term relationships.\n",
    "\n",
    "The original multihead attention for each component $H_{m}$ and its query, key, and value representations are denoted by $Q_{m}, K_{m}, V_{m}$, its transformation is given by:\n",
    "\n",
    "\\begin{align}\n",
    "Q_{m} = Q W_{Q,m} \\quad K_{m} = K W_{K,h} \\quad V_{m} = V W_{V,m} \\\\\n",
    "H_{m}=\\mathrm{Attention}(Q_{m}, K_{m}, V_{m}) = \\mathrm{SoftMax}(Q_{m} K^{\\intercal}_{m}/\\mathrm{scale}) \\; V_{m} \\\\\n",
    "\\mathrm{MultiHead}(Q, K, V) = [H_{1},\\dots,H_{M}] W_{M}\n",
    "\\end{align}\n",
    "\n",
    "TFT modifies the original multihead attention to improve its interpretability. To do it it uses shared values $\\tilde{V}$ across heads and employs additive aggregation, $\\mathrm{InterpretableMultiHead}(Q,K,V) = \\tilde{H} W_{M}$. The mechanism has a great resemblence to a single attention layer, but it allows for $M$ multiple attention weights, and can be therefore be interpreted as the average ensemble of $M$ single attention layers.\n",
    "\n",
    "\\begin{align}\n",
    "\\tilde{H} &= \\left(\\frac{1}{M} \\sum_{m} \\mathrm{SoftMax}(Q_{m} K^{\\intercal}_{m}/\\mathrm{scale}) \\right) \\tilde{V} \n",
    "          = \\frac{1}{M} \\sum_{m} \\mathrm{Attention}(Q_{m}, K_{m}, \\tilde{V}) \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class InterpretableMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_head, hidden_size, example_length,\n",
    "                 attn_dropout, dropout):\n",
    "        super().__init__()\n",
    "        self.n_head = n_head\n",
    "        assert hidden_size % n_head == 0\n",
    "        self.d_head = hidden_size // n_head\n",
    "        self.qkv_linears = nn.Linear(hidden_size, \n",
    "                                     (2 * self.n_head + 1) * self.d_head,\n",
    "                                     bias=False)\n",
    "        self.out_proj = nn.Linear(self.d_head, hidden_size, bias=False)\n",
    "\n",
    "        self.attn_dropout = nn.Dropout(attn_dropout)\n",
    "        self.out_dropout = nn.Dropout(dropout)\n",
    "        self.scale = self.d_head**-0.5\n",
    "        self.register_buffer(\"_mask\",\n",
    "          torch.triu(torch.full((example_length, example_length), \n",
    "                                float('-inf')), 1).unsqueeze(0))\n",
    "\n",
    "    def forward(self, x: Tensor, \n",
    "                mask_future_timesteps: bool = True) -> Tuple[Tensor, Tensor]:\n",
    "        # [Batch,Time,MultiHead,AttDim] := [N,T,M,AD]\n",
    "        bs, t, h_size = x.shape\n",
    "        qkv = self.qkv_linears(x)\n",
    "        q, k, v = qkv.split((self.n_head * self.d_head, \n",
    "                             self.n_head * self.d_head, self.d_head), dim=-1)\n",
    "        q = q.view(bs, t, self.n_head, self.d_head)\n",
    "        k = k.view(bs, t, self.n_head, self.d_head)\n",
    "        v = v.view(bs, t, self.d_head)\n",
    "        \n",
    "        # [N,T1,M,Ad] x [N,T2,M,Ad] -> [N,M,T1,T2]\n",
    "        # attn_score = torch.einsum('bind,bjnd->bnij', q, k)\n",
    "        attn_score = torch.matmul(q.permute((0, 2, 1, 3)), \n",
    "                                  k.permute((0, 2, 3, 1)))\n",
    "        attn_score.mul_(self.scale)\n",
    "\n",
    "        if mask_future_timesteps:\n",
    "            attn_score = attn_score + self._mask\n",
    "\n",
    "        attn_prob = F.softmax(attn_score, dim=3)\n",
    "        attn_prob = self.attn_dropout(attn_prob)\n",
    "\n",
    "        # [N,M,T1,T2] x [N,M,T1,Ad] -> [N,M,T1,Ad]\n",
    "        # attn_vec = torch.einsum('bnij,bjd->bnid', attn_prob, v)\n",
    "        attn_vec = torch.matmul(attn_prob, v.unsqueeze(1))\n",
    "        m_attn_vec = torch.mean(attn_vec, dim=1)\n",
    "        out = self.out_proj(m_attn_vec)\n",
    "        out = self.out_dropout(out)\n",
    "\n",
    "        return out, attn_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TFT Architecture\n",
    "\n",
    "The first TFT's step is embed the original input $\\{\\mathbf{x}^{(s)}, \\mathbf{x}^{(h)}, \\mathbf{x}^{(f)}\\}$ into a high dimensional space $\\{\\mathbf{E}^{(s)}, \\mathbf{E}^{(h)}, \\mathbf{E}^{(f)}\\}$, after which each embedding is gated by a variable selection network (VSN). The static embedding $\\mathbf{E}^{(s)}$ is used as context for variable selection and as initial condition to the LSTM. Finally the encoded variables are fed into the multi-head attention decoder.\n",
    "\n",
    "\\begin{align}\n",
    " c_{s}, c_{e}, (c_{h}, c_{c}) &=\\textrm{StaticCovariateEncoder}(\\mathbf{E}^{(s)}) \\\\ \n",
    "      h_{[:t]}, h_{[t+1:t+H]}  &=\\textrm{TemporalCovariateEncoder}(\\mathbf{E}^{(h)}, \\mathbf{E}^{(f)}, c_{h}, c_{c}) \\\\\n",
    "\\hat{\\mathbf{y}}^{(q)}_{[t+1:t+H]} &=\\textrm{TemporalFusionDecoder}(h_{[t+1:t+H]}, c_{e})\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Static Covariate Encoder\n",
    "\n",
    "The static embedding $\\mathbf{E}^{(s)}$ is transformed by the StaticCovariateEncoder into contexts $c_{s}, c_{e}, c_{h}, c_{c}$. Where $c_{s}$ are temporal variable selection contexts, $c_{e}$ are TemporalFusionDecoder enriching contexts, and $c_{h}, c_{c}$ are LSTM's hidden/contexts for the TemporalCovariateEncoder.\n",
    "\n",
    "\\begin{align}\n",
    "c_{s}, c_{e}, (c_{h}, c_{c}) & = \\textrm{GRN}(\\textrm{VSN}(\\mathbf{E}^{(s)}))\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class StaticCovariateEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size, num_static_vars, dropout):\n",
    "        super().__init__()\n",
    "        self.vsn = VariableSelectionNetwork(hidden_size=hidden_size,\n",
    "                                            num_inputs=num_static_vars,\n",
    "                                            dropout=dropout)\n",
    "        self.context_grns = nn.ModuleList(\n",
    "                              [GRN(input_size=hidden_size,\n",
    "                                   hidden_size=hidden_size,\n",
    "                                   dropout=dropout) for _ in range(4)])\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tuple[Tensor, Tensor, Tensor, Tensor]:\n",
    "        variable_ctx, sparse_weights = self.vsn(x)\n",
    "\n",
    "        # Context vectors:\n",
    "        # variable selection context\n",
    "        # enrichment context\n",
    "        # state_c context\n",
    "        # state_h context\n",
    "        cs, ce, ch, cc = tuple(m(variable_ctx) for m in self.context_grns)\n",
    "\n",
    "        return cs, ce, ch, cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Temporal Covariate Encoder\n",
    "\n",
    "TemporalCovariateEncoder encodes the embeddings $\\mathbf{E}^{(h)}, \\mathbf{E}^{(f)}$ and contexts  $(c_{h}, c_{c})$ with an LSTM.\n",
    "\n",
    "\\begin{align}\n",
    "\\tilde{\\mathbf{E}}^{(h)}_{[:t]} & = \\textrm{VSN}(\\mathbf{E}^{(h)}_{[:t]}, c_{s}) \\\\\n",
    "\\tilde{\\mathbf{E}}^{(h)}_{[:t]} &= \\mathrm{LSTM}(\\tilde{\\mathbf{E}}^{(h)}_{[:t]}, (c_{h}, c_{c})) \\\\\n",
    "h_{[:t]} &= \\mathrm{Gate}(\\mathrm{LayerNorm}(\\tilde{\\mathbf{E}}^{(h)}_{[:t]}))\n",
    "\\end{align}\n",
    "\n",
    "An analogous process is repeated for the future data, with the main difference that $\\mathbf{E}^{(f)}$ contains the future available information.\n",
    "\n",
    "\\begin{align}\n",
    "\\tilde{\\mathbf{E}}^{(f)}_{[t+1:t+h]} & = \\textrm{VSN}(\\mathbf{E}^{(h)}_{t+1:t+H}, \\mathbf{E}^{(f)}_{t+1:t+H}, c_{s}) \\\\\n",
    "\\tilde{\\mathbf{E}}^{(f)}_{[t+1:t+h]} &= \\mathrm{LSTM}(\\tilde{\\mathbf{E}}^{(h)}_{[t+1:t+h]}, (c_{h}, c_{c})) \\\\\n",
    "h_{[t+1:t+H]} &= \\mathrm{Gate}(\\mathrm{LayerNorm}(\\tilde{\\mathbf{E}}^{(f)}_{[t+1:t+h]}))\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class TemporalCovariateEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size, \n",
    "                 num_historic_vars, num_future_vars, dropout):\n",
    "        super(TemporalCovariateEncoder, self).__init__()\n",
    "\n",
    "        self.history_vsn = VariableSelectionNetwork(\n",
    "                                       hidden_size=hidden_size,\n",
    "                                       num_inputs=num_historic_vars,\n",
    "                                       dropout=dropout)\n",
    "        self.history_encoder = nn.LSTM(input_size=hidden_size,\n",
    "                                       hidden_size=hidden_size,\n",
    "                                       batch_first=True)\n",
    "        \n",
    "        self.future_vsn = VariableSelectionNetwork(hidden_size=hidden_size,\n",
    "                                                   num_inputs=num_future_vars,\n",
    "                                                   dropout=dropout)\n",
    "        self.future_encoder = nn.LSTM(input_size=hidden_size,\n",
    "                                      hidden_size=hidden_size,\n",
    "                                      batch_first=True)\n",
    "        \n",
    "        # Shared Gated-Skip Connection\n",
    "        self.input_gate = GLU(hidden_size, hidden_size)\n",
    "        self.input_gate_ln = LayerNorm(hidden_size, eps=1e-3)\n",
    "    \n",
    "    def forward(self, historical_inputs, future_inputs, cs, ch, cc):\n",
    "        # [N,X_in,L] -> [N,hidden_size,L]\n",
    "        historical_features, _ = self.history_vsn(historical_inputs, cs)\n",
    "        history, state = self.history_encoder(historical_features, (ch, cc))\n",
    "\n",
    "        future_features, _ = self.future_vsn(future_inputs, cs)\n",
    "        future, _ = self.future_encoder(future_features, state)\n",
    "        #torch.cuda.synchronize() # this call gives prf boost for unknown reasons\n",
    "\n",
    "        input_embedding = torch.cat([historical_features, future_features], dim=1)\n",
    "        temporal_features = torch.cat([history, future], dim=1)\n",
    "        temporal_features = self.input_gate(temporal_features)\n",
    "        temporal_features = temporal_features + input_embedding\n",
    "        temporal_features = self.input_gate_ln(temporal_features)      \n",
    "        return temporal_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Temporal Fusion Decoder\n",
    "\n",
    "The TemporalFusionDecoder enriches the LSTM's outputs with $c_{e}$ and then uses an attention layer, and multi-step adapter.\n",
    "\\begin{align}\n",
    "h_{[t+1:t+H]} &= \\mathrm{MultiHeadAttention}(h_{[:t]}, h_{[t+1:t+H]}, c_{e}) \\\\\n",
    "h_{[t+1:t+H]} &= \\mathrm{Gate}(\\mathrm{LayerNorm}(h_{[t+1:t+H]}) \\\\\n",
    "h_{[t+1:t+H]} &= \\mathrm{Gate}(\\mathrm{LayerNorm}(\\mathrm{GRN}(h_{[t+1:t+H]})) \\\\\n",
    "\\hat{\\mathbf{y}}^{(q)}_{[t+1:t+H]} &= \\mathrm{MLP}(h_{[t+1:t+H]})\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class TemporalFusionDecoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 n_head, hidden_size, \n",
    "                 example_length, encoder_length,\n",
    "                 attn_dropout, dropout):\n",
    "        super(TemporalFusionDecoder, self).__init__()\n",
    "        self.encoder_length = encoder_length\n",
    "        \n",
    "        #------------- Encoder-Decoder Attention --------------#\n",
    "        self.enrichment_grn = GRN(input_size=hidden_size,\n",
    "                                  hidden_size=hidden_size,\n",
    "                                  context_hidden_size=hidden_size, \n",
    "                                  dropout=dropout)\n",
    "        self.attention = InterpretableMultiHeadAttention(\n",
    "                                       n_head=n_head,\n",
    "                                       hidden_size=hidden_size,\n",
    "                                       example_length=example_length,\n",
    "                                       attn_dropout=attn_dropout,\n",
    "                                       dropout=dropout)\n",
    "        self.attention_gate = GLU(hidden_size, hidden_size)\n",
    "        self.attention_ln = LayerNorm(normalized_shape=hidden_size, eps=1e-3)\n",
    "\n",
    "        self.positionwise_grn = GRN(input_size=hidden_size,\n",
    "                                    hidden_size=hidden_size,\n",
    "                                    dropout=dropout)\n",
    "        \n",
    "        #---------------------- Decoder -----------------------#\n",
    "        self.decoder_gate = GLU(hidden_size, hidden_size)\n",
    "        self.decoder_ln = LayerNorm(normalized_shape=hidden_size, eps=1e-3)\n",
    "        \n",
    "    \n",
    "    def forward(self, temporal_features, ce):\n",
    "        #------------- Encoder-Decoder Attention --------------#\n",
    "        # Static enrichment\n",
    "        enriched = self.enrichment_grn(temporal_features, c=ce)\n",
    "\n",
    "        # Temporal self attention\n",
    "        x, _ = self.attention(enriched, mask_future_timesteps=True)\n",
    "\n",
    "        # Don't compute hictorical quantiles\n",
    "        x = x[:, self.encoder_length:, :]\n",
    "        temporal_features = temporal_features[:, self.encoder_length:, :]\n",
    "        enriched = enriched[:, self.encoder_length:, :]\n",
    "\n",
    "        x = self.attention_gate(x)\n",
    "        x = x + enriched\n",
    "        x = self.attention_ln(x)\n",
    "\n",
    "        # Position-wise feed-forward\n",
    "        x = self.positionwise_grn(x)\n",
    "\n",
    "        #---------------------- Decoder ----------------------#\n",
    "        # Final skip connection\n",
    "        x = self.decoder_gate(x)\n",
    "        x = x + temporal_features\n",
    "        x = self.decoder_ln(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TFT methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TFT(BaseWindows):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 h,\n",
    "                 tgt_size=1,\n",
    "                 hidden_size=128,\n",
    "                 s_cont_cols=None,\n",
    "                 s_cat_cols=None,\n",
    "                 o_cont_cols=None,\n",
    "                 o_cat_cols=None,\n",
    "                 k_cont_cols=None,\n",
    "                 k_cat_cols=None,\n",
    "                 s_cat_inp_lens=None,\n",
    "                 s_cont_inp_size=0,\n",
    "                 k_cat_inp_lens=None,\n",
    "                 k_cont_inp_size=1,\n",
    "                 o_cat_inp_lens=None,\n",
    "                 o_cont_inp_size=0,\n",
    "                 n_head=4,\n",
    "                 attn_dropout=0.0,\n",
    "                 dropout=0.1,\n",
    "                 windows_batch_size=1024,\n",
    "                 step_size=1,\n",
    "                 learning_rate=1e-3,\n",
    "                 scaler_type='robust',\n",
    "                 loss=MAE(),\n",
    "                 batch_size=32, \n",
    "                 num_workers_loader=0,\n",
    "                 drop_last_loader=False,\n",
    "                 random_seed=1,\n",
    "                 **trainer_kwargs\n",
    "                 ):\n",
    "\n",
    "        # Inherit BaseWindows class\n",
    "        super(TFT, self).__init__(h=h,\n",
    "                                  loss=loss,\n",
    "                                  batch_size=batch_size,\n",
    "                                  scaler_type=scaler_type,\n",
    "                                  num_workers_loader=num_workers_loader,\n",
    "                                  drop_last_loader=drop_last_loader,\n",
    "                                  random_seed=random_seed,\n",
    "                                  **trainer_kwargs)\n",
    "\n",
    "        self.windows_batch_size = windows_batch_size\n",
    "        self.step_size = step_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.example_length = input_size + h\n",
    "\n",
    "        # Parse lists hyperparameters\n",
    "        self.s_cont_cols = [] if s_cont_cols is None else s_cont_cols\n",
    "        self.s_cat_cols = [] if s_cat_cols is None else s_cat_cols\n",
    "        self.o_cont_cols = [] if o_cont_cols is None else o_cont_cols\n",
    "        self.o_cat_cols = [] if o_cat_cols is None else o_cat_cols\n",
    "        self.k_cont_cols = [] if k_cont_cols is None else k_cont_cols\n",
    "        self.k_cat_cols = [] if k_cat_cols is None else k_cat_cols\n",
    "\n",
    "        s_cat_inp_lens = [] if s_cat_inp_lens is None else s_cat_inp_lens\n",
    "        k_cat_inp_lens = [] if k_cat_inp_lens is None else k_cat_inp_lens\n",
    "        o_cat_inp_lens = [] if o_cat_inp_lens is None else o_cat_inp_lens\n",
    "\n",
    "        num_static_vars = s_cont_inp_size + len(s_cat_inp_lens)\n",
    "        num_future_vars = k_cont_inp_size + len(k_cat_inp_lens)\n",
    "        num_observ_vars = o_cont_inp_size + len(o_cat_inp_lens)\n",
    "        num_historic_vars = num_future_vars + num_observ_vars + tgt_size\n",
    "\n",
    "        #------------------------------- Encoders -----------------------------#\n",
    "        self.embedding = TFTEmbedding(hidden_size=hidden_size,\n",
    "                                      s_cat_inp_lens=s_cat_inp_lens,\n",
    "                                      s_cont_inp_size=s_cont_inp_size,\n",
    "                                      k_cat_inp_lens=k_cat_inp_lens, \n",
    "                                      k_cont_inp_size=k_cont_inp_size,\n",
    "                                      o_cat_inp_lens=o_cat_inp_lens,\n",
    "                                      o_cont_inp_size=o_cont_inp_size,\n",
    "                                      tgt_size=tgt_size)\n",
    "        \n",
    "        self.static_encoder = StaticCovariateEncoder(\n",
    "                                      hidden_size=hidden_size,\n",
    "                                      num_static_vars=num_static_vars,\n",
    "                                      dropout=dropout)\n",
    "\n",
    "        self.temporal_encoder = TemporalCovariateEncoder(\n",
    "                                      hidden_size=hidden_size,\n",
    "                                      num_historic_vars=num_historic_vars,\n",
    "                                      num_future_vars=num_future_vars,\n",
    "                                      dropout=dropout)\n",
    "\n",
    "        #------------------------------ Decoders -----------------------------#\n",
    "        self.temporal_fusion_decoder = TemporalFusionDecoder(\n",
    "                                      n_head=n_head,\n",
    "                                      hidden_size=hidden_size,\n",
    "                                      example_length=self.example_length,\n",
    "                                      encoder_length=self.input_size,\n",
    "                                      attn_dropout=attn_dropout,\n",
    "                                      dropout=dropout)\n",
    "\n",
    "        # Adapter with Loss dependent dimensions\n",
    "        self.output_adapter = nn.Linear(in_features=hidden_size,\n",
    "                                 out_features=self.loss.outputsize_multiplier)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Extract static and temporal features\n",
    "        y_idx = x['temporal_cols'].get_loc('y')\n",
    "        target_inp = x['temporal'][:, :, y_idx, None]\n",
    "\n",
    "        if len(self.k_cont_cols) > 0:\n",
    "            k_cont_inp = x['temporal'][:, :, x['temporal_cols'].get_indexer(self.k_cont_cols)]\n",
    "        else:\n",
    "            k_cont_inp = x['temporal'][:, [-self.h-1], y_idx]\n",
    "            k_cont_inp = k_cont_inp[:,:,None].repeat(1, self.example_length, 1)\n",
    "\n",
    "        # TODO: improve dictionary unpacking\n",
    "        s_inp, k_inp, o_inp, t_observed_tgt = self.embedding(target_inp=target_inp,\n",
    "                                                             k_cont_inp=k_cont_inp)\n",
    "\n",
    "        #-------------------------------- Inputs ------------------------------#\n",
    "        # Static context\n",
    "        if s_inp is not None:\n",
    "            cs, ce, ch, cc = self.static_encoder(s_inp)\n",
    "            ch, cc = ch.unsqueeze(0), cc.unsqueeze(0) # LSTM initial states\n",
    "        else:\n",
    "            # If None add zeros\n",
    "            batch_size, example_length, target_size, hidden_size = t_observed_tgt.shape\n",
    "            cs = torch.zeros(size=(batch_size, hidden_size)).to(target_inp.device)\n",
    "            ce = torch.zeros(size=(batch_size, hidden_size)).to(target_inp.device)\n",
    "            ch = torch.zeros(size=(1, batch_size, hidden_size)).to(target_inp.device)\n",
    "            cc = torch.zeros(size=(1, batch_size, hidden_size)).to(target_inp.device)\n",
    "\n",
    "        # Historical inputs\n",
    "        _historical_inputs = [k_inp[:,:self.input_size,:],\n",
    "                              t_observed_tgt[:,:self.input_size,:]]\n",
    "        if o_inp is not None:\n",
    "            _historical_inputs.insert(0,o_inp[:,:self.input_size,:])\n",
    "        historical_inputs = torch.cat(_historical_inputs, dim=-2)\n",
    "\n",
    "        # Future inputs\n",
    "        future_inputs = k_inp[:, self.input_size:]\n",
    "\n",
    "        #---------------------------- Encode/Decode ---------------------------#\n",
    "        # Embeddings + VSN + LSTM encoders\n",
    "        temporal_features = self.temporal_encoder(historical_inputs,\n",
    "                                                  future_inputs,\n",
    "                                                  cs, ch, cc)\n",
    "\n",
    "        # Static enrichment, Attention and decoders\n",
    "        temporal_features = self.temporal_fusion_decoder(temporal_features, ce)\n",
    "\n",
    "        # Adapt output to loss\n",
    "        y_hat = self.output_adapter(temporal_features)\n",
    "        if self.loss.outputsize_multiplier==1:\n",
    "            y_hat = y_hat.squeeze(-1)\n",
    "\n",
    "        return y_hat\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Deviates from orignal `BaseWindows.training_step` to \n",
    "        # allow the model to receive future exogenous available\n",
    "        # at the time of the prediction.\n",
    "        \n",
    "        # Create windows [Ws, L+H, C]\n",
    "        windows = self._create_windows(batch, step='train')\n",
    "\n",
    "        # Normalize windows\n",
    "        if self.scaler is not None:\n",
    "            windows = self._normalization(windows=windows)\n",
    "\n",
    "        # outsample\n",
    "        y_idx = batch['temporal_cols'].get_loc('y')\n",
    "        mask_idx = batch['temporal_cols'].get_loc('available_mask')\n",
    "        outsample_y = windows['temporal'][:, -self.h:, y_idx]\n",
    "        outsample_mask = windows['temporal'][:, -self.h:, mask_idx]\n",
    "\n",
    "        #batch_size, input_size\n",
    "        y_hat = self(x=windows)\n",
    "\n",
    "        loss = self.loss(y=outsample_y, y_hat=y_hat, mask=outsample_mask)\n",
    "        self.log('train_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        # Deviates from orignal `BaseWindows.training_step` to \n",
    "        # allow the model to receive future exogenous available\n",
    "        # at the time of the prediction.        \n",
    "        \n",
    "        # Create windows [Ws, L+H, C]\n",
    "        windows = self._create_windows(batch, step='predict')\n",
    "\n",
    "        # Normalize windows\n",
    "        if self.scaler is not None:\n",
    "            windows = self._normalization(windows=windows)\n",
    "\n",
    "        y_hat = self(x=windows)\n",
    "\n",
    "        # Inv Normalize\n",
    "        if self.scaler is not None:\n",
    "            y_hat = self._inv_normalization(y_hat=y_hat,\n",
    "                                            temporal_cols=batch['temporal_cols'])\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/tree/main/blob/main/neuralforecast/models/tft.py#L397){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TFT\n",
       "\n",
       ">      TFT (input_size, h, tgt_size=1, hidden_size=128, s_cont_cols=None,\n",
       ">           s_cat_cols=None, o_cont_cols=None, o_cat_cols=None,\n",
       ">           k_cont_cols=None, k_cat_cols=None, s_cat_inp_lens=None,\n",
       ">           s_cont_inp_size=0, k_cat_inp_lens=None, k_cont_inp_size=1,\n",
       ">           o_cat_inp_lens=None, o_cont_inp_size=0, n_head=4, attn_dropout=0.0,\n",
       ">           dropout=0.1, windows_batch_size=1024, step_size=1,\n",
       ">           learning_rate=0.001, scaler_type='robust',\n",
       ">           loss=<neuralforecast.losses.pytorch.MAE object>,\n",
       ">           batch_size=32, num_workers_loader=0, drop_last_loader=False,\n",
       ">           random_seed=1, **trainer_kwargs)\n",
       "\n",
       "Hooks to be used in LightningModule."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/tree/main/blob/main/neuralforecast/models/tft.py#L397){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TFT\n",
       "\n",
       ">      TFT (input_size, h, tgt_size=1, hidden_size=128, s_cont_cols=None,\n",
       ">           s_cat_cols=None, o_cont_cols=None, o_cat_cols=None,\n",
       ">           k_cont_cols=None, k_cat_cols=None, s_cat_inp_lens=None,\n",
       ">           s_cont_inp_size=0, k_cat_inp_lens=None, k_cont_inp_size=1,\n",
       ">           o_cat_inp_lens=None, o_cont_inp_size=0, n_head=4, attn_dropout=0.0,\n",
       ">           dropout=0.1, windows_batch_size=1024, step_size=1,\n",
       ">           learning_rate=0.001, scaler_type='robust',\n",
       ">           loss=<neuralforecast.losses.pytorch.MAE object>,\n",
       ">           batch_size=32, num_workers_loader=0, drop_last_loader=False,\n",
       ">           random_seed=1, **trainer_kwargs)\n",
       "\n",
       "Hooks to be used in LightningModule."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(TFT, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### TFT.fit\n",
       "\n",
       ">      TFT.fit (dataset, val_size=0, test_size=0)\n",
       "\n",
       "Fits Model.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: TimeSeriesDataset.<br>\n",
       "`trainer`: pl.Trainer.<br>\n",
       "`val_size`: int, validation size.<br>\n",
       "`test_size`: int, test size.<br>\n",
       "`data_kwargs`: extra arguments to be passed to TimeSeriesDataModule."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### TFT.fit\n",
       "\n",
       ">      TFT.fit (dataset, val_size=0, test_size=0)\n",
       "\n",
       "Fits Model.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: TimeSeriesDataset.<br>\n",
       "`trainer`: pl.Trainer.<br>\n",
       "`val_size`: int, validation size.<br>\n",
       "`test_size`: int, test size.<br>\n",
       "`data_kwargs`: extra arguments to be passed to TimeSeriesDataModule."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(TFT.fit, name='TFT.fit', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### TFT.predict\n",
       "\n",
       ">      TFT.predict (dataset, test_size=None, step_size=1, **data_kwargs)\n",
       "\n",
       "Predicts Model.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: TimeSeriesDataset.<br>\n",
       "`trainer`: pl.Trainer.<br>\n",
       "`step_size`: int, Step size between each window.<br>\n",
       "`data_kwargs`: extra arguments to be passed to TimeSeriesDataModule."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### TFT.predict\n",
       "\n",
       ">      TFT.predict (dataset, test_size=None, step_size=1, **data_kwargs)\n",
       "\n",
       "Predicts Model.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: TimeSeriesDataset.<br>\n",
       "`trainer`: pl.Trainer.<br>\n",
       "`step_size`: int, Step size between each window.<br>\n",
       "`data_kwargs`: extra arguments to be passed to TimeSeriesDataModule."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(TFT.predict, name='TFT.predict', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_eq\n",
    "from nbdev.showdoc import show_doc\n",
    "from neuralforecast.utils import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import logging\n",
    "import warnings\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neuralforecast.utils import AirPassengers, AirPassengersPanel\n",
    "from neuralforecast.tsdataset import TimeSeriesDataset, TimeSeriesLoader\n",
    "\n",
    "from neuralforecast.losses.pytorch import MQLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c08a2440e2d458a8426c5c8db61157e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6c340ba38d45fcbe778dca37c90bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558e842cbf5e4e499298371117624628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e6ca206f56419f8a1db0733cef524e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_train_df = AirPassengersPanel[AirPassengersPanel.ds<AirPassengersPanel['ds'].values[-12]] # 132 train\n",
    "Y_test_df = AirPassengersPanel[AirPassengersPanel.ds>=AirPassengersPanel['ds'].values[-12]] # 12 test\n",
    "\n",
    "dataset, *_ = TimeSeriesDataset.from_df(df = AirPassengersPanel)\n",
    "model = TFT(input_size=48, h=12,\n",
    "            hidden_size=100,\n",
    "            k_cont_cols=['trend'], #['trend', 'y_[lag12]'],\n",
    "            k_cont_inp_size=2,\n",
    "            max_epochs=1,\n",
    "            learning_rate=0.01,\n",
    "            scaler_type='robust',\n",
    "            loss=MQLoss(level=[80, 90]),\n",
    "            windows_batch_size=None,\n",
    "            enable_progress_bar=True)\n",
    "\n",
    "model.fit(dataset=dataset, test_size=12)\n",
    "\n",
    "# Parse quantile predictions\n",
    "y_hat = model.predict(dataset=dataset)\n",
    "Y_hat_df = pd.DataFrame.from_records(data=y_hat,\n",
    "                columns=['TFT'+q for q in model.loss.output_names],\n",
    "                index=Y_test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot quantile predictions\n",
    "plot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\n",
    "plot_df = plot_df[plot_df.unique_id=='Airline2']\n",
    "plot_df = pd.concat([Y_train_df, plot_df])\n",
    "plot_df = plot_df[plot_df.unique_id=='Airline2'].drop('unique_id', axis=1)\n",
    "\n",
    "plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n",
    "# plt.plot(plot_df['ds'], plot_df['TFT'], c='blue', label='median')\n",
    "plt.plot(plot_df['ds'], plot_df['TFT-median'], c='blue', label='median')\n",
    "plt.fill_between(x=plot_df['ds'], \n",
    "                 y1=plot_df['TFT-lo-90'], y2=plot_df['TFT-hi-90'],\n",
    "                 alpha=0.4, label='level 90')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralforecast",
   "language": "python",
   "name": "neuralforecast"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
