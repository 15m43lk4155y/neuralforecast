# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/data_datasets__wth.ipynb (unless otherwise specified).

__all__ = ['WTH', 'WTHInfo', 'WTH']

# Cell
import os
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple, Union

import gdown
import numpy as np
import pandas as pd

from .utils import Info, time_features_from_frequency_str

# Cell
@dataclass
class WTH:
    freq: str = 'H'
    name: str = 'WTH'
    n_ts: int = 12

# Cell
WTHInfo = Info(groups=('WTH',),
              class_groups=(WTH,))

# Cell
@dataclass
class WTH:

    source_url: str = 'https://drive.google.com/uc?id=1UBRz-aM_57i_KCC-iaSWoKDPTGGv6EaG'

    @staticmethod
    def load(directory: str,
             cache: bool = True) -> Tuple[pd.DataFrame,
                                          Optional[pd.DataFrame],
                                          Optional[pd.DataFrame]]:
        """Downloads and loads ETT data.

        Parameters
        ----------
        directory: str
            Directory where data will be downloaded.
        cache: bool
            If `True` saves and loads

        Notes
        -----
        [1] Returns train+val+test sets.
        """
        path = f'{directory}/wth/datasets'
        file_cache = f'{path}/WTH.p'

        if os.path.exists(file_cache) and cache:
            df, X_df, S_df = pd.read_pickle(file_cache)

            return df, X_df, S_df


        WTH.download(directory)
        path = f'{directory}/wth/datasets'

        y_df = pd.read_csv(f'{path}/WTH.csv')
        y_df['date'] = pd.to_datetime(y_df['date'])
        y_df.rename(columns={'date': 'ds'}, inplace=True)
        u_ids = y_df.columns.to_list()
        u_ids.remove('ds')

        time_cls = time_features_from_frequency_str('h')
        for cls_ in time_cls:
            cls_name = cls_.__class__.__name__
            y_df[cls_name] = cls_(y_df['ds'].dt)

        X_df = y_df.drop(u_ids, axis=1)
        y_df = y_df.filter(items=['ds'] + u_ids)
        y_df = y_df.set_index('ds').stack()
        y_df = y_df.rename('y').rename_axis(['ds', 'unique_id']).reset_index()
        y_df['unique_id'] = pd.Categorical(y_df['unique_id'], u_ids)
        y_df = y_df[['unique_id', 'ds', 'y']].sort_values(['unique_id', 'ds'])

        X_df = y_df[['unique_id', 'ds']].merge(X_df, how='left', on=['ds'])

        S_df = None
        if cache:
            pd.to_pickle((y_df, X_df, S_df), file_cache)

        return y_df, X_df, S_df

    @staticmethod
    def download(directory: str) -> None:
        """Download WTH Dataset."""
        path = f'{directory}/wth/datasets/'
        if not os.path.exists(path):
            os.makedirs(path)
            gdown.download(WTH.source_url, f'{path}/WTH.csv')